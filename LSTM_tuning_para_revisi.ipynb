{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import date, datetime\n",
    "from multiprocessing.spawn import import_main_path\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Attributes</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Adj Close</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Close</th>\n",
       "      <th colspan=\"2\" halign=\"left\">High</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Low</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbols</th>\n",
       "      <th>ANTM.JK</th>\n",
       "      <th>ASII.JK</th>\n",
       "      <th>ICBP.JK</th>\n",
       "      <th>JSMR.JK</th>\n",
       "      <th>ANTM.JK</th>\n",
       "      <th>ASII.JK</th>\n",
       "      <th>ICBP.JK</th>\n",
       "      <th>JSMR.JK</th>\n",
       "      <th>ANTM.JK</th>\n",
       "      <th>ASII.JK</th>\n",
       "      <th>...</th>\n",
       "      <th>ICBP.JK</th>\n",
       "      <th>JSMR.JK</th>\n",
       "      <th>ANTM.JK</th>\n",
       "      <th>ASII.JK</th>\n",
       "      <th>ICBP.JK</th>\n",
       "      <th>JSMR.JK</th>\n",
       "      <th>ANTM.JK</th>\n",
       "      <th>ASII.JK</th>\n",
       "      <th>ICBP.JK</th>\n",
       "      <th>JSMR.JK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1576.277344</td>\n",
       "      <td>2454.149170</td>\n",
       "      <td>1408.559326</td>\n",
       "      <td>1530.938110</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>1837.5</td>\n",
       "      <td>1845.677368</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1762.5</td>\n",
       "      <td>1805.770874</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>1787.5</td>\n",
       "      <td>1845.677368</td>\n",
       "      <td>39619544.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26442000.0</td>\n",
       "      <td>6978806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1576.277344</td>\n",
       "      <td>2468.054199</td>\n",
       "      <td>1437.305176</td>\n",
       "      <td>1547.488403</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1865.630737</td>\n",
       "      <td>1994.945068</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1845.677368</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1865.630737</td>\n",
       "      <td>62041590.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42874000.0</td>\n",
       "      <td>7988164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1576.277344</td>\n",
       "      <td>2454.149170</td>\n",
       "      <td>1427.723145</td>\n",
       "      <td>1555.763916</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>1862.5</td>\n",
       "      <td>1875.607300</td>\n",
       "      <td>1994.945068</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1862.5</td>\n",
       "      <td>1855.654053</td>\n",
       "      <td>1931.946777</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1875.607300</td>\n",
       "      <td>30916328.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44946000.0</td>\n",
       "      <td>7538113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1610.544067</td>\n",
       "      <td>2377.674316</td>\n",
       "      <td>1437.305176</td>\n",
       "      <td>1547.488403</td>\n",
       "      <td>1973.945557</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1865.630737</td>\n",
       "      <td>1994.945068</td>\n",
       "      <td>3560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1862.5</td>\n",
       "      <td>1845.677368</td>\n",
       "      <td>1973.945557</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1865.630737</td>\n",
       "      <td>30624653.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24863000.0</td>\n",
       "      <td>2048787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>1610.544067</td>\n",
       "      <td>2391.578613</td>\n",
       "      <td>1446.887207</td>\n",
       "      <td>1539.213257</td>\n",
       "      <td>1973.945557</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>1887.5</td>\n",
       "      <td>1855.654053</td>\n",
       "      <td>1994.945068</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1862.5</td>\n",
       "      <td>1845.677368</td>\n",
       "      <td>1973.945557</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1855.654053</td>\n",
       "      <td>15857579.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19118000.0</td>\n",
       "      <td>2441705.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Attributes    Adj Close                                               Close  \\\n",
       "Symbols         ANTM.JK      ASII.JK      ICBP.JK      JSMR.JK      ANTM.JK   \n",
       "Date                                                                          \n",
       "2010-01-04  1576.277344  2454.149170  1408.559326  1530.938110  1931.946777   \n",
       "2010-01-05  1576.277344  2468.054199  1437.305176  1547.488403  1931.946777   \n",
       "2010-01-06  1576.277344  2454.149170  1427.723145  1555.763916  1931.946777   \n",
       "2010-01-07  1610.544067  2377.674316  1437.305176  1547.488403  1973.945557   \n",
       "2010-01-08  1610.544067  2391.578613  1446.887207  1539.213257  1973.945557   \n",
       "\n",
       "Attributes                                      High          ...     Low  \\\n",
       "Symbols    ASII.JK ICBP.JK      JSMR.JK      ANTM.JK ASII.JK  ... ICBP.JK   \n",
       "Date                                                          ...           \n",
       "2010-01-04  3530.0  1837.5  1845.677368  1931.946777  3550.0  ...  1762.5   \n",
       "2010-01-05  3550.0  1875.0  1865.630737  1994.945068  3570.0  ...  1825.0   \n",
       "2010-01-06  3530.0  1862.5  1875.607300  1994.945068  3580.0  ...  1862.5   \n",
       "2010-01-07  3420.0  1875.0  1865.630737  1994.945068  3560.0  ...  1862.5   \n",
       "2010-01-08  3440.0  1887.5  1855.654053  1994.945068  3450.0  ...  1862.5   \n",
       "\n",
       "Attributes                      Open                                   Volume  \\\n",
       "Symbols         JSMR.JK      ANTM.JK ASII.JK ICBP.JK      JSMR.JK     ANTM.JK   \n",
       "Date                                                                            \n",
       "2010-01-04  1805.770874  1931.946777  3530.0  1787.5  1845.677368  39619544.0   \n",
       "2010-01-05  1845.677368  1931.946777  3550.0  1875.0  1865.630737  62041590.0   \n",
       "2010-01-06  1855.654053  1931.946777  3530.0  1900.0  1875.607300  30916328.0   \n",
       "2010-01-07  1845.677368  1973.945557  3420.0  1875.0  1865.630737  30624653.0   \n",
       "2010-01-08  1845.677368  1973.945557  3440.0  1900.0  1855.654053  15857579.0   \n",
       "\n",
       "Attributes                                 \n",
       "Symbols    ASII.JK     ICBP.JK    JSMR.JK  \n",
       "Date                                       \n",
       "2010-01-04    40.0  26442000.0  6978806.0  \n",
       "2010-01-05    40.0  42874000.0  7988164.0  \n",
       "2010-01-06    40.0  44946000.0  7538113.0  \n",
       "2010-01-07    40.0  24863000.0  2048787.0  \n",
       "2010-01-08    40.0  19118000.0  2441705.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [\"ANTM.JK\",\"ASII.JK\",\"ICBP.JK\",\"JSMR.JK\"]\n",
    "\n",
    "today = date.today()\n",
    "# print(today)\n",
    "start_date = '2010-01-01'\n",
    "# end_date = '2022-08-02'\n",
    "\n",
    "panel_data = data.DataReader(tickers,'yahoo',start_date,today)\n",
    "panel_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Symbols</th>\n",
       "      <th>ANTM.JK</th>\n",
       "      <th>ASII.JK</th>\n",
       "      <th>ICBP.JK</th>\n",
       "      <th>JSMR.JK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1576.28</td>\n",
       "      <td>2454.15</td>\n",
       "      <td>1408.56</td>\n",
       "      <td>1530.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1576.28</td>\n",
       "      <td>2468.05</td>\n",
       "      <td>1437.31</td>\n",
       "      <td>1547.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1576.28</td>\n",
       "      <td>2454.15</td>\n",
       "      <td>1427.72</td>\n",
       "      <td>1555.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1610.54</td>\n",
       "      <td>2377.67</td>\n",
       "      <td>1437.31</td>\n",
       "      <td>1547.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>1610.54</td>\n",
       "      <td>2391.58</td>\n",
       "      <td>1446.89</td>\n",
       "      <td>1539.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Symbols     ANTM.JK  ASII.JK  ICBP.JK  JSMR.JK\n",
       "Date                                          \n",
       "2010-01-04  1576.28  2454.15  1408.56  1530.94\n",
       "2010-01-05  1576.28  2468.05  1437.31  1547.49\n",
       "2010-01-06  1576.28  2454.15  1427.72  1555.76\n",
       "2010-01-07  1610.54  2377.67  1437.31  1547.49\n",
       "2010-01-08  1610.54  2391.58  1446.89  1539.21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_close = panel_data[\"Adj Close\"]\n",
    "data_close.head(5).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c272666f70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot everything by leveraging the very powerful matplotlib package\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "for name in tickers:\n",
    "    ax.plot(data_close[name].index, data_close[name], label='Saham {}'.format(name))\n",
    "\n",
    "\n",
    "# Define the date format\n",
    "date_form = DateFormatter(\"%b-%y\")\n",
    "ax.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "ax.set_title('Harga saham ')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Closing price (Rp)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antm</th>\n",
       "      <th>asii</th>\n",
       "      <th>icbp</th>\n",
       "      <th>jsmr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1576.277344</td>\n",
       "      <td>2454.149170</td>\n",
       "      <td>1408.559326</td>\n",
       "      <td>1530.938110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1576.277344</td>\n",
       "      <td>2468.054199</td>\n",
       "      <td>1437.305176</td>\n",
       "      <td>1547.488403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1576.277344</td>\n",
       "      <td>2454.149170</td>\n",
       "      <td>1427.723145</td>\n",
       "      <td>1555.763916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1610.544067</td>\n",
       "      <td>2377.674316</td>\n",
       "      <td>1437.305176</td>\n",
       "      <td>1547.488403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>1610.544067</td>\n",
       "      <td>2391.578613</td>\n",
       "      <td>1446.887207</td>\n",
       "      <td>1539.213257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-28</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>6050.000000</td>\n",
       "      <td>8758.188477</td>\n",
       "      <td>3580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-29</th>\n",
       "      <td>1955.000000</td>\n",
       "      <td>6325.000000</td>\n",
       "      <td>8611.811523</td>\n",
       "      <td>3560.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>2080.000000</td>\n",
       "      <td>6475.000000</td>\n",
       "      <td>8685.000000</td>\n",
       "      <td>3520.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-02</th>\n",
       "      <td>1995.000000</td>\n",
       "      <td>6475.000000</td>\n",
       "      <td>8975.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-03</th>\n",
       "      <td>1980.000000</td>\n",
       "      <td>6425.000000</td>\n",
       "      <td>8825.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3118 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   antm         asii         icbp         jsmr\n",
       "Date                                                          \n",
       "2010-01-04  1576.277344  2454.149170  1408.559326  1530.938110\n",
       "2010-01-05  1576.277344  2468.054199  1437.305176  1547.488403\n",
       "2010-01-06  1576.277344  2454.149170  1427.723145  1555.763916\n",
       "2010-01-07  1610.544067  2377.674316  1437.305176  1547.488403\n",
       "2010-01-08  1610.544067  2391.578613  1446.887207  1539.213257\n",
       "...                 ...          ...          ...          ...\n",
       "2022-07-28  2000.000000  6050.000000  8758.188477  3580.000000\n",
       "2022-07-29  1955.000000  6325.000000  8611.811523  3560.000000\n",
       "2022-08-01  2080.000000  6475.000000  8685.000000  3520.000000\n",
       "2022-08-02  1995.000000  6475.000000  8975.000000  3450.000000\n",
       "2022-08-03  1980.000000  6425.000000  8825.000000  3480.000000\n",
       "\n",
       "[3118 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_close)\n",
    "data_close.columns = ['antm', 'asii', 'icbp', 'jsmr']\n",
    "data_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm = pd.DataFrame(data_close.antm)\n",
    "df_asii = pd.DataFrame(data_close.asii)\n",
    "df_icbp = pd.DataFrame(data_close.icbp)\n",
    "df_jsmr = pd.DataFrame(data_close.jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a min max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_antm = pd.DataFrame(scaler.fit_transform(df_antm), columns = ['antm'])\n",
    "df_asii = pd.DataFrame(scaler.fit_transform(df_asii), columns = ['asii'])\n",
    "df_icbp = pd.DataFrame(scaler.fit_transform(df_icbp), columns = ['icbp'])\n",
    "df_jsmr = pd.DataFrame(scaler.fit_transform(df_jsmr), columns = ['jsmr'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "def split_sequence(seq, n_steps):\n",
    "    X,y = list(), list()\n",
    "    for i in range(len(seq)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(seq)-1:\n",
    "            break\n",
    "        seq_x, seq_y =seq[i:end_ix],seq[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUNING PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import DataFrame\n",
    "# from pandas import Series\n",
    "# from pandas import concat\n",
    "# from pandas import read_csv\n",
    "# from pandas import datetime\n",
    "# from math import sqrt\n",
    "# import matplotlib\n",
    "# import numpy\n",
    "# from numpy import concatenate\n",
    "\n",
    "# # date-time parsing function for loading the dataset\n",
    "# def parser(x):\n",
    "# \treturn datetime.strptime('190'+x, '%Y-%m')\n",
    " \n",
    "\n",
    "# # frame a sequence as a supervised learning problem\n",
    "# def timeseries_to_supervised(data, lag=1):\n",
    "# \tdf = DataFrame(data)\n",
    "# \tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "# \tcolumns.append(df)\n",
    "# \tdf = concat(columns, axis=1)\n",
    "# \treturn df\n",
    " \n",
    "# # create a differenced series\n",
    "# def difference(dataset, interval=1):\n",
    "# \tdiff = list()\n",
    "# \tfor i in range(interval, len(dataset)):\n",
    "# \t\tvalue = dataset[i] - dataset[i - interval]\n",
    "# \t\tdiff.append(value)\n",
    "# \treturn Series(diff)\n",
    " \n",
    "# # invert differenced value\n",
    "# def inverse_difference(history, yhat, interval=1):\n",
    "# \treturn yhat + history[-interval]\n",
    " \n",
    "# # scale train and test data to [-1, 1]\n",
    "# def scale(train, test):\n",
    "# \t# fit scaler\n",
    "# \tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# \tscaler = scaler.fit(train)\n",
    "# \t# transform train\n",
    "# \ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "# \ttrain_scaled = scaler.transform(train)\n",
    "# \t# transform test\n",
    "# \ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "# \ttest_scaled = scaler.transform(test)\n",
    "# \treturn scaler, train_scaled, test_scaled\n",
    " \n",
    "# # inverse scaling for a forecasted value\n",
    "# def invert_scale(scaler, X, yhat):\n",
    "# \tnew_row = [x for x in X] + [yhat]\n",
    "# \tarray = numpy.array(new_row)\n",
    "# \tarray = array.reshape(1, len(array))\n",
    "# \tinverted = scaler.inverse_transform(array)\n",
    "# \treturn inverted[0, -1]\n",
    " \n",
    "# # fit an LSTM network to training data\n",
    "# def fit_lstm(train, batch_size, nb_epoch, neurons, timesteps):\n",
    "# \tX, y = train[:, 0:-1], train[:, -1]\n",
    "# \tX = X.reshape(X.shape[0], timesteps, 1)\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "# \tmodel.add(Dense(1))\n",
    "# \tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# \tfor i in range(nb_epoch):\n",
    "# \t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "# \t\tmodel.reset_states()\n",
    "# \treturn model\n",
    " \n",
    "# # make a one-step forecast\n",
    "# def forecast_lstm(model, batch_size, X):\n",
    "# \tX = X.reshape(1, len(X), 1)\n",
    "# \tyhat = model.predict(X, batch_size=batch_size)\n",
    "# \treturn yhat[0,0]\n",
    " \n",
    "# # run a repeated experiment\n",
    "# def experiment(repeats, series, timesteps):\n",
    "# \t# transform data to be stationary\n",
    "# \traw_values = series.values\n",
    "# \tdiff_values = difference(raw_values, 1)\n",
    "# \t# transform data to be supervised learning\n",
    "# \tsupervised = timeseries_to_supervised(diff_values, timesteps)\n",
    "# \tsupervised_values = supervised.values[timesteps:,:]\n",
    "# \t# split data into train and test-sets\n",
    "# \ttrain, test = supervised_values[0:-12, :], supervised_values[-12:, :]\n",
    "# \t# transform the scale of the data\n",
    "# \tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "# \t# run experiment\n",
    "# \terror_scores = list()\n",
    "# \tfor r in range(repeats):\n",
    "# \t\t# fit the base model\n",
    "# \t\tlstm_model = fit_lstm(train_scaled, 1, 100, 1, timesteps)\n",
    "# \t\t# forecast test dataset\n",
    "# \t\tpredictions = list()\n",
    "# \t\tfor i in range(len(test_scaled)):\n",
    "# \t\t\t# predict\n",
    "# \t\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "# \t\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "# \t\t\t# invert scaling\n",
    "# \t\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "# \t\t\t# invert differencing\n",
    "# \t\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "# \t\t\t# store forecast\n",
    "# \t\t\tpredictions.append(yhat)\n",
    "# \t\t# report performance\n",
    "# \t\trmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "# \t\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "# \t\terror_scores.append(rmse)\n",
    "# \treturn error_scores\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # execute the experiment\n",
    "# def run():\n",
    "# \t# load dataset\n",
    "# \t# experiment\n",
    "# \trepeats = 2\n",
    "# \tresults = DataFrame()\n",
    "# \t# run experiment\n",
    "# \ttimesteps = 1\n",
    "# \tresults['results'] = experiment(repeats, df_antm, timesteps)\n",
    "# \t# summarize results\n",
    "# \tprint(results.describe())\n",
    "# \t# save results\n",
    "# \tresults.to_csv('antm_experiment_timesteps_1.csv', index=False)\n",
    " \n",
    "#  # entry point\n",
    "# run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import DataFrame\n",
    "# from pandas import read_csv\n",
    "# from matplotlib import pyplot\n",
    "# # load results into a dataframe\n",
    "# filenames = ['experiment_timesteps_1.csv', 'experiment_timesteps_2.csv',\n",
    "# \t'experiment_timesteps_3.csv','experiment_timesteps_4.csv','experiment_timesteps_5.csv']\n",
    "# results = DataFrame()\n",
    "# for name in filenames:\n",
    "# \tresults[name[11:-4]] = read_csv(name, header=0)\n",
    "# # describe all results\n",
    "# print(results.describe())\n",
    "# # box and whisker plot\n",
    "# results.boxplot()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIMESTEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_1 = 1\n",
    "n_steps_2 = 2\n",
    "n_steps_3 = 3\n",
    "n_steps_4 = 4\n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm = df_antm.reset_index(drop=True)\n",
    "arr_antm = df_antm.to_numpy()\n",
    "flat_antm = arr_antm.flatten()\n",
    "antm_X_1, antm_y_1 = split_sequence(flat_antm, n_steps_1)\n",
    "antm_X_2, antm_y_2 = split_sequence(flat_antm, n_steps_2)\n",
    "antm_X_3, antm_y_3 = split_sequence(flat_antm, n_steps_3)\n",
    "antm_X_4, antm_y_4 = split_sequence(flat_antm, n_steps_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_antm_1, X_test_antm_1, y_train_antm_1, y_test_antm_1 = train_test_split(antm_X_1, antm_y_1, test_size=0.33, random_state=42)\n",
    "X_train_antm_2, X_test_antm_2, y_train_antm_2, y_test_antm_2 = train_test_split(antm_X_2, antm_y_2, test_size=0.33, random_state=42)\n",
    "X_train_antm_3, X_test_antm_3, y_train_antm_3, y_test_antm_3 = train_test_split(antm_X_3, antm_y_3, test_size=0.33, random_state=42)\n",
    "X_train_antm_4, X_test_antm_4, y_train_antm_4, y_test_antm_4 = train_test_split(antm_X_4, antm_y_4, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_antm_1 = X_train_antm_1.reshape(X_train_antm_1.shape[0],X_train_antm_1.shape[1],n_features)\n",
    "X_test_antm_1 = X_test_antm_1.reshape(X_test_antm_1.shape[0],X_test_antm_1.shape[1],n_features)\n",
    "X_train_antm_2 = X_train_antm_2.reshape(X_train_antm_2.shape[0],X_train_antm_2.shape[1],n_features)\n",
    "X_test_antm_2 = X_test_antm_2.reshape(X_test_antm_2.shape[0],X_test_antm_2.shape[1],n_features)\n",
    "X_train_antm_3 = X_train_antm_3.reshape(X_train_antm_3.shape[0],X_train_antm_3.shape[1],n_features)\n",
    "X_test_antm_3 = X_test_antm_3.reshape(X_test_antm_3.shape[0],X_test_antm_3.shape[1],n_features)\n",
    "X_train_antm_4 = X_train_antm_4.reshape(X_train_antm_4.shape[0],X_train_antm_4.shape[1],n_features)\n",
    "X_test_antm_4 = X_test_antm_4.reshape(X_test_antm_4.shape[0],X_test_antm_4.shape[1],n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_4 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_4, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_4.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 12ms/step - loss: 0.1469 - mae: 0.1469 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1293 - mae: 0.1293 - val_loss: 0.0810 - val_mae: 0.0810\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1278 - mae: 0.1278 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1275 - mae: 0.1275 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1278 - mae: 0.1278 - val_loss: 0.0539 - val_mae: 0.0539\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.0459 - val_mae: 0.0459\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1263 - mae: 0.1263 - val_loss: 0.0434 - val_mae: 0.0434\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1265 - mae: 0.1265 - val_loss: 0.0397 - val_mae: 0.0397\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1264 - mae: 0.126 - 0s 3ms/step - loss: 0.1260 - mae: 0.1260 - val_loss: 0.0430 - val_mae: 0.0430\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.0396 - val_mae: 0.0396\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1257 - mae: 0.1257 - val_loss: 0.0452 - val_mae: 0.0452\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1266 - mae: 0.1266 - val_loss: 0.0525 - val_mae: 0.0525\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1259 - mae: 0.1259 - val_loss: 0.0530 - val_mae: 0.0530\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1257 - mae: 0.1257 - val_loss: 0.0489 - val_mae: 0.0489\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1251 - mae: 0.1251 - val_loss: 0.0433 - val_mae: 0.0433\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1256 - mae: 0.1256 - val_loss: 0.0538 - val_mae: 0.0538\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1251 - mae: 0.1251 - val_loss: 0.0495 - val_mae: 0.0495\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1252 - mae: 0.1252 - val_loss: 0.0488 - val_mae: 0.0488\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1249 - mae: 0.1249 - val_loss: 0.0505 - val_mae: 0.0505\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.0453 - val_mae: 0.0453\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1248 - mae: 0.1248 - val_loss: 0.0452 - val_mae: 0.0452\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1239 - mae: 0.1239 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1247 - mae: 0.1247 - val_loss: 0.0519 - val_mae: 0.0519\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1243 - mae: 0.1243 - val_loss: 0.0483 - val_mae: 0.0483\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1244 - mae: 0.1244 - val_loss: 0.0470 - val_mae: 0.0470\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1241 - mae: 0.1241 - val_loss: 0.0583 - val_mae: 0.0583\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1243 - mae: 0.1243 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1239 - mae: 0.1239 - val_loss: 0.0553 - val_mae: 0.0553\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1238 - mae: 0.1238 - val_loss: 0.0555 - val_mae: 0.0555\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1229 - mae: 0.1229 - val_loss: 0.0560 - val_mae: 0.0560\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1246 - mae: 0.1246 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1250 - mae: 0.1250 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1247 - mae: 0.1247 - val_loss: 0.0654 - val_mae: 0.0654\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1228 - mae: 0.1228 - val_loss: 0.0523 - val_mae: 0.0523\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1228 - mae: 0.1228 - val_loss: 0.0537 - val_mae: 0.0537\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.0604 - val_mae: 0.0604\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1231 - mae: 0.1231 - val_loss: 0.0568 - val_mae: 0.0568\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1224 - mae: 0.1224 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0595 - val_mae: 0.0595\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.0625 - val_mae: 0.0625\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.0577 - val_mae: 0.0577\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1219 - mae: 0.1219 - val_loss: 0.0568 - val_mae: 0.0568\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1228 - mae: 0.1228 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1217 - mae: 0.1217 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1219 - mae: 0.1219 - val_loss: 0.0625 - val_mae: 0.0625\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1224 - mae: 0.1224 - val_loss: 0.0762 - val_mae: 0.0762\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1227 - mae: 0.1227 - val_loss: 0.0652 - val_mae: 0.0652\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1227 - mae: 0.1227 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.0589 - val_mae: 0.0589\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1226 - mae: 0.1226 - val_loss: 0.0703 - val_mae: 0.0703\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0682 - val_mae: 0.0682\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1223 - mae: 0.1223 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1217 - mae: 0.1217 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1217 - mae: 0.1217 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1224 - mae: 0.1224 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1230 - mae: 0.1230 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1223 - mae: 0.1223 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1234 - mae: 0.1234 - val_loss: 0.0720 - val_mae: 0.0720\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1233 - mae: 0.1233 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.0664 - val_mae: 0.0664\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.0686 - val_mae: 0.0686\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1234 - mae: 0.1234 - val_loss: 0.0752 - val_mae: 0.0752\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1225 - mae: 0.1225 - val_loss: 0.0713 - val_mae: 0.0713\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1216 - mae: 0.1216 - val_loss: 0.0633 - val_mae: 0.0633\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.0701 - val_mae: 0.0701\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1222 - mae: 0.1222 - val_loss: 0.0671 - val_mae: 0.0671\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1215 - mae: 0.1215 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1213 - mae: 0.1213 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1212 - mae: 0.1212 - val_loss: 0.0649 - val_mae: 0.0649\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1217 - mae: 0.1217 - val_loss: 0.0624 - val_mae: 0.0624\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1216 - mae: 0.1216 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.0625 - val_mae: 0.0625\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1213 - mae: 0.1213 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.0675 - val_mae: 0.0675\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1221 - mae: 0.1221 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1215 - mae: 0.1215 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.0674 - val_mae: 0.0674\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.0608 - val_mae: 0.0608\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1220 - mae: 0.1220 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.1218 - val_loss: 0.0590 - val_mae: 0.0590\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1210 - mae: 0.1210 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1210 - mae: 0.1210 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1216 - mae: 0.1216 - val_loss: 0.0601 - val_mae: 0.0601\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1212 - mae: 0.1212 - val_loss: 0.0588 - val_mae: 0.0588\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_1 = simple_model_antm_1.fit(X_train_antm_1, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "# time 19.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.0735 - mae: 0.0735 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0091 - mae: 0.009 - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0090 - mae: 0.009 - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.007 - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0080\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_2 = simple_model_antm_2.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "# time 21.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.1429 - mae: 0.1429 - val_loss: 0.0871 - val_mae: 0.0871\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0357 - mae: 0.0357 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0091 - val_mae: 0.0091\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_3 = simple_model_antm_3.fit(X_train_antm_3, y_train_antm_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 22.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 9ms/step - loss: 0.0524 - mae: 0.0524 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0088 - val_mae: 0.0088\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_4 = simple_model_antm_4.fit(X_train_antm_4, y_train_antm_4,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 24.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_antm_1 = simple_model_antm_1.predict(X_test_antm_1)\n",
    "preds_antm_2 = simple_model_antm_2.predict(X_test_antm_2)\n",
    "preds_antm_3 = simple_model_antm_3.predict(X_test_antm_3)\n",
    "preds_antm_4 = simple_model_antm_4.predict(X_test_antm_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps 1\n",
      "mae score antm_1: 0.05351210758470884\n",
      "r2 score antm_1: -0.012847259777391207\n",
      "mape score antm_1: 0.17672596212047678\n",
      "rmse score antm_1: 0.1109104112490807\n",
      "timesteps 2\n",
      "mae score antm_2: 0.008161751530795817\n",
      "r2 score antm_2: 0.9952483822666641\n",
      "mape score antm_2: 0.036884902423474634\n",
      "rmse score antm_2: 0.013446005459325163\n",
      "timesteps 3\n",
      "mae score antm_3: 0.009117184707894537\n",
      "r2 score antm_3: 0.9943208018711837\n",
      "mape score antm_3: 0.0415330433575899\n",
      "rmse score antm_3: 0.014982986270849675\n",
      "timesteps 4\n",
      "mae score antm_4: 0.008764602393161843\n",
      "r2 score antm_4: 0.9943954589232934\n",
      "mape score antm_4: 0.041414121470253945\n",
      "rmse score antm_4: 0.014978998319218338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 1\")\n",
    "print(\"mae score antm_1: \"+str(mean_absolute_error(preds_antm_1, y_test_antm_1)))\n",
    "print(\"r2 score antm_1: \"+str(r2_score(preds_antm_1, y_test_antm_1)))\n",
    "print(\"mape score antm_1: \"+str(mean_absolute_percentage_error(preds_antm_1, y_test_antm_1)))\n",
    "print(\"rmse score antm_1: \"+str(np.sqrt(mean_squared_error(preds_antm_1, y_test_antm_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 2\")\n",
    "print(\"mae score antm_2: \"+str(mean_absolute_error(preds_antm_2, y_test_antm_2)))\n",
    "print(\"r2 score antm_2: \"+str(r2_score(preds_antm_2, y_test_antm_2)))\n",
    "print(\"mape score antm_2: \"+str(mean_absolute_percentage_error(preds_antm_2, y_test_antm_2)))\n",
    "print(\"rmse score antm_2: \"+str(np.sqrt(mean_squared_error(preds_antm_2, y_test_antm_2))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 3\")\n",
    "print(\"mae score antm_3: \"+str(mean_absolute_error(preds_antm_3, y_test_antm_3)))\n",
    "print(\"r2 score antm_3: \"+str(r2_score(preds_antm_3, y_test_antm_3)))\n",
    "print(\"mape score antm_3: \"+str(mean_absolute_percentage_error(preds_antm_3, y_test_antm_3)))\n",
    "print(\"rmse score antm_3: \"+str(np.sqrt(mean_squared_error(preds_antm_3, y_test_antm_3))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 4\")\n",
    "print(\"mae score antm_4: \"+str(mean_absolute_error(preds_antm_4, y_test_antm_4)))\n",
    "print(\"r2 score antm_4: \"+str(r2_score(preds_antm_4, y_test_antm_4)))\n",
    "print(\"mape score antm_4: \"+str(mean_absolute_percentage_error(preds_antm_4, y_test_antm_4)))\n",
    "print(\"rmse score antm_4: \"+str(np.sqrt(mean_squared_error(preds_antm_4, y_test_antm_4))))\n",
    "\n",
    "mae_antm = {'timesteps_1':mean_absolute_error(preds_antm_1, y_test_antm_1),'timesteps_2':mean_absolute_error(preds_antm_2, y_test_antm_2),'timesteps_3':mean_absolute_error(preds_antm_3, y_test_antm_3),'timesteps_4':mean_absolute_error(preds_antm_4, y_test_antm_4)}\n",
    "\n",
    "mape_antm = {'timesteps_1':mean_absolute_percentage_error(preds_antm_1, y_test_antm_1),'timesteps_2':mean_absolute_percentage_error(preds_antm_2, y_test_antm_2),'timesteps_3':mean_absolute_percentage_error(preds_antm_3, y_test_antm_3),'timesteps_4':mean_absolute_percentage_error(preds_antm_4, y_test_antm_4)}\n",
    "\n",
    "rmse_antm = {'timesteps_1':np.sqrt(mean_squared_error(preds_antm_1, y_test_antm_1)),'timesteps_2':np.sqrt(mean_squared_error(preds_antm_2, y_test_antm_2)),'timesteps_3':np.sqrt(mean_squared_error(preds_antm_3, y_test_antm_3)),'timesteps_4':np.sqrt(mean_squared_error(preds_antm_4, y_test_antm_4))}\n",
    "\n",
    "r2_antm = {'timesteps_1':r2_score(preds_antm_1, y_test_antm_1),'timesteps_2':r2_score(preds_antm_2, y_test_antm_2),'timesteps_3':r2_score(preds_antm_3, y_test_antm_3),'timesteps_4':r2_score(preds_antm_4, y_test_antm_4)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps 1\n",
    "# mae score antm_1: 0.05351210758470884\n",
    "# r2 score antm_1: -0.012847259777391207\n",
    "# mape score antm_1: 0.17672596212047678\n",
    "# rmse score antm_1: 0.1109104112490807\n",
    "# timesteps 2\n",
    "# mae score antm_2: 0.008161751530795817\n",
    "# r2 score antm_2: 0.9952483822666641\n",
    "# mape score antm_2: 0.036884902423474634\n",
    "# rmse score antm_2: 0.013446005459325163\n",
    "# timesteps 3\n",
    "# mae score antm_3: 0.009117184707894537\n",
    "# r2 score antm_3: 0.9943208018711837\n",
    "# mape score antm_3: 0.0415330433575899\n",
    "# rmse score antm_3: 0.014982986270849675\n",
    "# timesteps 4\n",
    "# mae score antm_4: 0.008764602393161843\n",
    "# r2 score antm_4: 0.9943954589232934\n",
    "# mape score antm_4: 0.041414121470253945\n",
    "# rmse score antm_4: 0.014978998319218338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'timesteps_2': 0.008161751530795817, 'timesteps_4': 0.008764602393161843, 'timesteps_3': 0.009117184707894537, 'timesteps_1': 0.05351210758470884}\n",
      "sorted rmse\n",
      "{'timesteps_2': 0.013446005459325163, 'timesteps_4': 0.014978998319218338, 'timesteps_3': 0.014982986270849675, 'timesteps_1': 0.1109104112490807}\n",
      "sorted mape\n",
      "{'timesteps_2': 0.036884902423474634, 'timesteps_4': 0.041414121470253945, 'timesteps_3': 0.0415330433575899, 'timesteps_1': 0.17672596212047678}\n",
      "sorted r2\n",
      "{'timesteps_2': 0.9952483822666641, 'timesteps_4': 0.9943954589232934, 'timesteps_3': 0.9943208018711837, 'timesteps_1': -0.012847259777391207}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_antm_1_sorted = dict(sorted(mae_antm.items(),key=lambda item: item[1]))\n",
    "print(mae_antm_1_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_antm_sorted = dict(sorted(rmse_antm.items(),key=lambda item: item[1]))\n",
    "print(rmse_antm_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_antm_sorted = dict(sorted(mape_antm.items(),key=lambda item: item[1]))\n",
    "print(mape_antm_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_antm_sorted = dict(sorted(r2_antm.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_antm_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'timesteps_2': 0.008161751530795817, 'timesteps_4': 0.008764602393161843, 'timesteps_3': 0.009117184707894537, 'timesteps_1': 0.05351210758470884}\n",
    "# sorted rmse\n",
    "# {'timesteps_2': 0.013446005459325163, 'timesteps_4': 0.014978998319218338, 'timesteps_3': 0.014982986270849675, 'timesteps_1': 0.1109104112490807}\n",
    "# sorted mape\n",
    "# {'timesteps_2': 0.036884902423474634, 'timesteps_4': 0.041414121470253945, 'timesteps_3': 0.0415330433575899, 'timesteps_1': 0.17672596212047678}\n",
    "# sorted r2\n",
    "# {'timesteps_2': 0.9952483822666641, 'timesteps_4': 0.9943954589232934, 'timesteps_3': 0.9943208018711837, 'timesteps_1': -0.012847259777391207}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asii = df_asii.reset_index(drop=True)\n",
    "arr_asii = df_asii.to_numpy()\n",
    "flat_asii = arr_asii.flatten()\n",
    "asii_X_1, asii_y_1 = split_sequence(flat_asii, n_steps_1)\n",
    "asii_X_2, asii_y_2 = split_sequence(flat_asii, n_steps_2)\n",
    "asii_X_3, asii_y_3 = split_sequence(flat_asii, n_steps_3)\n",
    "asii_X_4, asii_y_4 = split_sequence(flat_asii, n_steps_4)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_asii_1, X_test_asii_1, y_train_asii_1, y_test_asii_1 = train_test_split(asii_X_1, asii_y_1, test_size=0.33, random_state=42)\n",
    "X_train_asii_2, X_test_asii_2, y_train_asii_2, y_test_asii_2 = train_test_split(asii_X_2, asii_y_2, test_size=0.33, random_state=42)\n",
    "X_train_asii_3, X_test_asii_3, y_train_asii_3, y_test_asii_3 = train_test_split(asii_X_3, asii_y_3, test_size=0.33, random_state=42)\n",
    "X_train_asii_4, X_test_asii_4, y_train_asii_4, y_test_asii_4 = train_test_split(asii_X_4, asii_y_4, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_asii_1 = X_train_asii_1.reshape(X_train_asii_1.shape[0],X_train_asii_1.shape[1],n_features)\n",
    "X_test_asii_1 = X_test_asii_1.reshape(X_test_asii_1.shape[0],X_test_asii_1.shape[1],n_features)\n",
    "X_train_asii_2 = X_train_asii_2.reshape(X_train_asii_2.shape[0],X_train_asii_2.shape[1],n_features)\n",
    "X_test_asii_2 = X_test_asii_2.reshape(X_test_asii_2.shape[0],X_test_asii_2.shape[1],n_features)\n",
    "X_train_asii_3 = X_train_asii_3.reshape(X_train_asii_3.shape[0],X_train_asii_3.shape[1],n_features)\n",
    "X_test_asii_3 = X_test_asii_3.reshape(X_test_asii_3.shape[0],X_test_asii_3.shape[1],n_features)\n",
    "X_train_asii_4 = X_train_asii_4.reshape(X_train_asii_4.shape[0],X_train_asii_4.shape[1],n_features)\n",
    "X_test_asii_4 = X_test_asii_4.reshape(X_test_asii_4.shape[0],X_test_asii_4.shape[1],n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_4 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_4, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_4.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 10ms/step - loss: 0.2262 - mae: 0.2262 - val_loss: 0.0950 - val_mae: 0.0950\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0697 - mae: 0.0697 - val_loss: 0.0380 - val_mae: 0.0380\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0239 - mae: 0.0239 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0151 - val_mae: 0.0151\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_1 = simple_model_asii_1.fit(X_train_asii_1, y_train_asii_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 19.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.1739 - mae: 0.1739 - val_loss: 0.0439 - val_mae: 0.0439\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0254 - mae: 0.0254 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0186 - mae: 0.018 - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0233 - val_mae: 0.0233\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0169 - mae: 0.016 - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0152 - val_mae: 0.0152\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_2 = simple_model_asii_2.fit(X_train_asii_2, y_train_asii_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 21.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 10ms/step - loss: 0.1505 - mae: 0.1505 - val_loss: 0.0292 - val_mae: 0.0292\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0244 - mae: 0.0244 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0268 - val_mae: 0.0268\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0258 - val_mae: 0.0258\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0258 - val_mae: 0.0258\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0229 - val_mae: 0.0229\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0244 - val_mae: 0.0244\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0146 - val_mae: 0.0146\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_3 = simple_model_asii_3.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 23.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 12ms/step - loss: 0.1645 - mae: 0.1645 - val_loss: 0.0434 - val_mae: 0.0434\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0256 - val_mae: 0.0256\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0260 - val_mae: 0.0260\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0313 - val_mae: 0.0313\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0230 - val_mae: 0.0230\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0244 - val_mae: 0.0244\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0152 - val_mae: 0.0152\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_4 = simple_model_asii_4.fit(X_train_asii_4, y_train_asii_4,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 24.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_asii_1 = simple_model_asii_1.predict(X_test_asii_1)\n",
    "preds_asii_2 = simple_model_asii_2.predict(X_test_asii_2)\n",
    "preds_asii_3 = simple_model_asii_3.predict(X_test_asii_3)\n",
    "preds_asii_4 = simple_model_asii_4.predict(X_test_asii_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps 1\n",
      "mae score asii_1: 0.015697579842078434\n",
      "r2 score asii_1: 0.9891798496508\n",
      "mape score asii_1: 0.03516537230185299\n",
      "rmse score asii_1: 0.02077293181651314\n",
      "timesteps 2\n",
      "mae score asii_2: 0.015313086808529379\n",
      "r2 score asii_2: 0.9900058330429263\n",
      "mape score asii_2: 0.05661475089706797\n",
      "rmse score asii_2: 0.020241523730058424\n",
      "timesteps 3\n",
      "mae score asii_3: 0.01468973459169929\n",
      "r2 score asii_3: 0.9901866526074022\n",
      "mape score asii_3: 0.0329870319926044\n",
      "rmse score asii_3: 0.019597623902703688\n",
      "timesteps 4\n",
      "mae score asii_4: 0.015275431236995839\n",
      "r2 score asii_4: 0.9896423031917067\n",
      "mape score asii_4: 0.04428520573595462\n",
      "rmse score asii_4: 0.020267971711778642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 1\")\n",
    "print(\"mae score asii_1: \"+str(mean_absolute_error(preds_asii_1, y_test_asii_1)))\n",
    "print(\"r2 score asii_1: \"+str(r2_score(preds_asii_1, y_test_asii_1)))\n",
    "print(\"mape score asii_1: \"+str(mean_absolute_percentage_error(preds_asii_1, y_test_asii_1)))\n",
    "print(\"rmse score asii_1: \"+str(np.sqrt(mean_squared_error(preds_asii_1, y_test_asii_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 2\")\n",
    "print(\"mae score asii_2: \"+str(mean_absolute_error(preds_asii_2, y_test_asii_2)))\n",
    "print(\"r2 score asii_2: \"+str(r2_score(preds_asii_2, y_test_asii_2)))\n",
    "print(\"mape score asii_2: \"+str(mean_absolute_percentage_error(preds_asii_2, y_test_asii_2)))\n",
    "print(\"rmse score asii_2: \"+str(np.sqrt(mean_squared_error(preds_asii_2, y_test_asii_2))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 3\")\n",
    "print(\"mae score asii_3: \"+str(mean_absolute_error(preds_asii_3, y_test_asii_3)))\n",
    "print(\"r2 score asii_3: \"+str(r2_score(preds_asii_3, y_test_asii_3)))\n",
    "print(\"mape score asii_3: \"+str(mean_absolute_percentage_error(preds_asii_3, y_test_asii_3)))\n",
    "print(\"rmse score asii_3: \"+str(np.sqrt(mean_squared_error(preds_asii_3, y_test_asii_3))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 4\")\n",
    "print(\"mae score asii_4: \"+str(mean_absolute_error(preds_asii_4, y_test_asii_4)))\n",
    "print(\"r2 score asii_4: \"+str(r2_score(preds_asii_4, y_test_asii_4)))\n",
    "print(\"mape score asii_4: \"+str(mean_absolute_percentage_error(preds_asii_4, y_test_asii_4)))\n",
    "print(\"rmse score asii_4: \"+str(np.sqrt(mean_squared_error(preds_asii_4, y_test_asii_4))))\n",
    "\n",
    "mae_asii = {'timesteps_1':mean_absolute_error(preds_asii_1, y_test_asii_1),'timesteps_2':mean_absolute_error(preds_asii_2, y_test_asii_2),'timesteps_3':mean_absolute_error(preds_asii_3, y_test_asii_3),'timesteps_4':mean_absolute_error(preds_asii_4, y_test_asii_4)}\n",
    "\n",
    "mape_asii = {'timesteps_1':mean_absolute_percentage_error(preds_asii_1, y_test_asii_1),'timesteps_2':mean_absolute_percentage_error(preds_asii_2, y_test_asii_2),'timesteps_3':mean_absolute_percentage_error(preds_asii_3, y_test_asii_3),'timesteps_4':mean_absolute_percentage_error(preds_asii_4, y_test_asii_4)}\n",
    "\n",
    "rmse_asii = {'timesteps_1':np.sqrt(mean_squared_error(preds_asii_1, y_test_asii_1)),'timesteps_2':np.sqrt(mean_squared_error(preds_asii_2, y_test_asii_2)),'timesteps_3':np.sqrt(mean_squared_error(preds_asii_3, y_test_asii_3)),'timesteps_4':np.sqrt(mean_squared_error(preds_asii_4, y_test_asii_4))}\n",
    "\n",
    "r2_asii = {'timesteps_1':r2_score(preds_asii_1, y_test_asii_1),'timesteps_2':r2_score(preds_asii_2, y_test_asii_2),'timesteps_3':r2_score(preds_asii_3, y_test_asii_3),'timesteps_4':r2_score(preds_asii_4, y_test_asii_4)} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps 1\n",
    "# mae score asii_1: 0.015697579842078434\n",
    "# r2 score asii_1: 0.9891798496508\n",
    "# mape score asii_1: 0.03516537230185299\n",
    "# rmse score asii_1: 0.02077293181651314\n",
    "# timesteps 2\n",
    "# mae score asii_2: 0.015313086808529379\n",
    "# r2 score asii_2: 0.9900058330429263\n",
    "# mape score asii_2: 0.05661475089706797\n",
    "# rmse score asii_2: 0.020241523730058424\n",
    "# timesteps 3\n",
    "# mae score asii_3: 0.01468973459169929\n",
    "# r2 score asii_3: 0.9901866526074022\n",
    "# mape score asii_3: 0.0329870319926044\n",
    "# rmse score asii_3: 0.019597623902703688\n",
    "# timesteps 4\n",
    "# mae score asii_4: 0.015275431236995839\n",
    "# r2 score asii_4: 0.9896423031917067\n",
    "# mape score asii_4: 0.04428520573595462\n",
    "# rmse score asii_4: 0.020267971711778642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'timesteps_3': 0.01468973459169929, 'timesteps_4': 0.015275431236995839, 'timesteps_2': 0.015313086808529379, 'timesteps_1': 0.015697579842078434}\n",
      "sorted rmse\n",
      "{'timesteps_3': 0.019597623902703688, 'timesteps_2': 0.020241523730058424, 'timesteps_4': 0.020267971711778642, 'timesteps_1': 0.02077293181651314}\n",
      "sorted mape\n",
      "{'timesteps_3': 0.0329870319926044, 'timesteps_1': 0.03516537230185299, 'timesteps_4': 0.04428520573595462, 'timesteps_2': 0.05661475089706797}\n",
      "sorted r2\n",
      "{'timesteps_3': 0.9901866526074022, 'timesteps_2': 0.9900058330429263, 'timesteps_4': 0.9896423031917067, 'timesteps_1': 0.9891798496508}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_asii_1_sorted = dict(sorted(mae_asii.items(),key=lambda item: item[1]))\n",
    "print(mae_asii_1_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_asii_sorted = dict(sorted(rmse_asii.items(),key=lambda item: item[1]))\n",
    "print(rmse_asii_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_asii_sorted = dict(sorted(mape_asii.items(),key=lambda item: item[1]))\n",
    "print(mape_asii_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_asii_sorted = dict(sorted(r2_asii.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_asii_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'timesteps_3': 0.01468973459169929, 'timesteps_4': 0.015275431236995839, 'timesteps_2': 0.015313086808529379, 'timesteps_1': 0.015697579842078434}\n",
    "# sorted rmse\n",
    "# {'timesteps_3': 0.019597623902703688, 'timesteps_2': 0.020241523730058424, 'timesteps_4': 0.020267971711778642, 'timesteps_1': 0.02077293181651314}\n",
    "# sorted mape\n",
    "# {'timesteps_3': 0.0329870319926044, 'timesteps_1': 0.03516537230185299, 'timesteps_4': 0.04428520573595462, 'timesteps_2': 0.05661475089706797}\n",
    "# sorted r2\n",
    "# {'timesteps_3': 0.9901866526074022, 'timesteps_2': 0.9900058330429263, 'timesteps_4': 0.9896423031917067, 'timesteps_1': 0.9891798496508}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icbp = df_icbp.reset_index(drop=True)\n",
    "arr_icbp = df_icbp.to_numpy()\n",
    "flat_icbp = arr_icbp.flatten()\n",
    "icbp_X_1, icbp_y_1 = split_sequence(flat_icbp, n_steps_1)\n",
    "icbp_X_2, icbp_y_2 = split_sequence(flat_icbp, n_steps_2)\n",
    "icbp_X_3, icbp_y_3 = split_sequence(flat_icbp, n_steps_3)\n",
    "icbp_X_4, icbp_y_4 = split_sequence(flat_icbp, n_steps_4)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_icbp_1, X_test_icbp_1, y_train_icbp_1, y_test_icbp_1 = train_test_split(icbp_X_1, icbp_y_1, test_size=0.33, random_state=42)\n",
    "X_train_icbp_2, X_test_icbp_2, y_train_icbp_2, y_test_icbp_2 = train_test_split(icbp_X_2, icbp_y_2, test_size=0.33, random_state=42)\n",
    "X_train_icbp_3, X_test_icbp_3, y_train_icbp_3, y_test_icbp_3 = train_test_split(icbp_X_3, icbp_y_3, test_size=0.33, random_state=42)\n",
    "X_train_icbp_4, X_test_icbp_4, y_train_icbp_4, y_test_icbp_4 = train_test_split(icbp_X_4, icbp_y_4, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_icbp_1 = X_train_icbp_1.reshape(X_train_icbp_1.shape[0],X_train_icbp_1.shape[1],n_features)\n",
    "X_test_icbp_1 = X_test_icbp_1.reshape(X_test_icbp_1.shape[0],X_test_icbp_1.shape[1],n_features)\n",
    "X_train_icbp_2 = X_train_icbp_2.reshape(X_train_icbp_2.shape[0],X_train_icbp_2.shape[1],n_features)\n",
    "X_test_icbp_2 = X_test_icbp_2.reshape(X_test_icbp_2.shape[0],X_test_icbp_2.shape[1],n_features)\n",
    "X_train_icbp_3 = X_train_icbp_3.reshape(X_train_icbp_3.shape[0],X_train_icbp_3.shape[1],n_features)\n",
    "X_test_icbp_3 = X_test_icbp_3.reshape(X_test_icbp_3.shape[0],X_test_icbp_3.shape[1],n_features)\n",
    "X_train_icbp_4 = X_train_icbp_4.reshape(X_train_icbp_4.shape[0],X_train_icbp_4.shape[1],n_features)\n",
    "X_test_icbp_4 = X_test_icbp_4.reshape(X_test_icbp_4.shape[0],X_test_icbp_4.shape[1],n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_4 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_4, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_4.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 3s 10ms/step - loss: 0.1810 - mae: 0.1810 - val_loss: 0.0728 - val_mae: 0.0728\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.0328 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0092 - mae: 0.009 - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0079 - mae: 0.007 - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0074 - val_mae: 0.0074\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_1 = simple_model_icbp_1.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 19.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.2130 - mae: 0.2130 - val_loss: 0.0298 - val_mae: 0.0298\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0226 - mae: 0.0226 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0092 - mae: 0.009 - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0071 - val_mae: 0.0071\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0071 - val_mae: 0.0071\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0071 - val_mae: 0.0071\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0071 - val_mae: 0.0071\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0071 - val_mae: 0.0071\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0071 - val_mae: 0.0071\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0071 - val_mae: 0.0071\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0070 - val_mae: 0.0070\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0070 - val_mae: 0.0070\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0084 - val_mae: 0.0084\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_2 = simple_model_icbp_2.fit(X_train_icbp_2, y_train_icbp_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 19.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_model_icbp_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\programming\\lstm\\LSTM_revisi.ipynb Cell 49\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_revisi.ipynb#ch0000048?line=0'>1</a>\u001b[0m smod_history_icbp_3 \u001b[39m=\u001b[39m simple_model_icbp_3\u001b[39m.\u001b[39mfit(X_train_icbp_3, y_train_icbp_3,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_revisi.ipynb#ch0000048?line=1'>2</a>\u001b[0m           validation_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_revisi.ipynb#ch0000048?line=2'>3</a>\u001b[0m           epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_revisi.ipynb#ch0000048?line=3'>4</a>\u001b[0m           batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_revisi.ipynb#ch0000048?line=4'>5</a>\u001b[0m           shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_revisi.ipynb#ch0000048?line=5'>6</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'simple_model_icbp_3' is not defined"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_3 = simple_model_icbp_3.fit(X_train_icbp_3, y_train_icbp_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 23.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 10ms/step - loss: 0.3389 - mae: 0.3389 - val_loss: 0.2400 - val_mae: 0.2400\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2422 - mae: 0.2422 - val_loss: 0.2267 - val_mae: 0.2267\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2246 - val_mae: 0.2246\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2262 - val_mae: 0.2262\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2401 - mae: 0.2401 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2244 - val_mae: 0.2244\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2247 - val_mae: 0.2247\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2247 - val_mae: 0.2247\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2247 - val_mae: 0.2247\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2401 - mae: 0.2401 - val_loss: 0.2260 - val_mae: 0.2260\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2260 - val_mae: 0.2260\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2262 - val_mae: 0.2262\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2402 - mae: 0.2402 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2408 - mae: 0.2408 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2404 - mae: 0.2404 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2401 - mae: 0.2401 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2246 - val_mae: 0.2246\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2401 - mae: 0.2401 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2404 - mae: 0.2404 - val_loss: 0.2249 - val_mae: 0.2249\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2404 - mae: 0.2404 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2403 - mae: 0.2403 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2409 - mae: 0.2409 - val_loss: 0.2247 - val_mae: 0.2247\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2401 - mae: 0.2401 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2249 - val_mae: 0.2249\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2248 - val_mae: 0.2248\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2248 - val_mae: 0.2248\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2262 - val_mae: 0.2262\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2248 - val_mae: 0.2248\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2248 - val_mae: 0.2248\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2249 - val_mae: 0.2249\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2262 - val_mae: 0.2262\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2404 - mae: 0.2404 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2400 - mae: 0.2400 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2253 - val_mae: 0.2253\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_4 = simple_model_icbp_4.fit(X_train_icbp_4, y_train_icbp_4,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 24.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_icbp_1 = simple_model_icbp_1.predict(X_test_icbp_1)\n",
    "preds_icbp_2 = simple_model_icbp_2.predict(X_test_icbp_2)\n",
    "preds_icbp_3 = simple_model_icbp_3.predict(X_test_icbp_3)\n",
    "preds_icbp_4 = simple_model_icbp_4.predict(X_test_icbp_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps 1\n",
      "mae score icbp_1: 0.0071951216005588505\n",
      "r2 score icbp_1: 0.9982912893287746\n",
      "mape score icbp_1: 0.02911766342732286\n",
      "rmse score icbp_1: 0.0115991115450196\n",
      "timesteps 2\n",
      "mae score icbp_2: 0.00874996393974662\n",
      "r2 score icbp_2: 0.998219167116058\n",
      "mape score icbp_2: 0.10803360291602122\n",
      "rmse score icbp_2: 0.011925892437280167\n",
      "timesteps 3\n",
      "mae score icbp_3: 0.009715755021447626\n",
      "r2 score icbp_3: 0.9975988977109971\n",
      "mape score icbp_3: 0.03398883492185345\n",
      "rmse score icbp_3: 0.013880861676693924\n",
      "timesteps 4\n",
      "mae score icbp_4: 0.24760012053707564\n",
      "r2 score icbp_4: 0.0\n",
      "mape score icbp_4: 0.46217821589569885\n",
      "rmse score icbp_4: 0.2913636094589231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 1\")\n",
    "print(\"mae score icbp_1: \"+str(mean_absolute_error(preds_icbp_1, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_1: \"+str(r2_score(preds_icbp_1, y_test_icbp_1)))\n",
    "print(\"mape score icbp_1: \"+str(mean_absolute_percentage_error(preds_icbp_1, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_1: \"+str(np.sqrt(mean_squared_error(preds_icbp_1, y_test_icbp_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 2\")\n",
    "print(\"mae score icbp_2: \"+str(mean_absolute_error(preds_icbp_2, y_test_icbp_2)))\n",
    "print(\"r2 score icbp_2: \"+str(r2_score(preds_icbp_2, y_test_icbp_2)))\n",
    "print(\"mape score icbp_2: \"+str(mean_absolute_percentage_error(preds_icbp_2, y_test_icbp_2)))\n",
    "print(\"rmse score icbp_2: \"+str(np.sqrt(mean_squared_error(preds_icbp_2, y_test_icbp_2))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 3\")\n",
    "print(\"mae score icbp_3: \"+str(mean_absolute_error(preds_icbp_3, y_test_icbp_3)))\n",
    "print(\"r2 score icbp_3: \"+str(r2_score(preds_icbp_3, y_test_icbp_3)))\n",
    "print(\"mape score icbp_3: \"+str(mean_absolute_percentage_error(preds_icbp_3, y_test_icbp_3)))\n",
    "print(\"rmse score icbp_3: \"+str(np.sqrt(mean_squared_error(preds_icbp_3, y_test_icbp_3))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 4\")\n",
    "print(\"mae score icbp_4: \"+str(mean_absolute_error(preds_icbp_4, y_test_icbp_4)))\n",
    "print(\"r2 score icbp_4: \"+str(r2_score(preds_icbp_4, y_test_icbp_4)))\n",
    "print(\"mape score icbp_4: \"+str(mean_absolute_percentage_error(preds_icbp_4, y_test_icbp_4)))\n",
    "print(\"rmse score icbp_4: \"+str(np.sqrt(mean_squared_error(preds_icbp_4, y_test_icbp_4))))\n",
    "\n",
    "mae_icbp = {'timesteps_1':mean_absolute_error(preds_icbp_1, y_test_icbp_1),'timesteps_2':mean_absolute_error(preds_icbp_2, y_test_icbp_2),'timesteps_3':mean_absolute_error(preds_icbp_3, y_test_icbp_3),'timesteps_4':mean_absolute_error(preds_icbp_4, y_test_icbp_4)}\n",
    "\n",
    "mape_icbp = {'timesteps_1':mean_absolute_percentage_error(preds_icbp_1, y_test_icbp_1),'timesteps_2':mean_absolute_percentage_error(preds_icbp_2, y_test_icbp_2),'timesteps_3':mean_absolute_percentage_error(preds_icbp_3, y_test_icbp_3),'timesteps_4':mean_absolute_percentage_error(preds_icbp_4, y_test_icbp_4)}\n",
    "\n",
    "rmse_icbp = {'timesteps_1':np.sqrt(mean_squared_error(preds_icbp_1, y_test_icbp_1)),'timesteps_2':np.sqrt(mean_squared_error(preds_icbp_2, y_test_icbp_2)),'timesteps_3':np.sqrt(mean_squared_error(preds_icbp_3, y_test_icbp_3)),'timesteps_4':np.sqrt(mean_squared_error(preds_icbp_4, y_test_icbp_4))}\n",
    "\n",
    "r2_icbp = {'timesteps_1':r2_score(preds_icbp_1, y_test_icbp_1),'timesteps_2':r2_score(preds_icbp_2, y_test_icbp_2),'timesteps_3':r2_score(preds_icbp_3, y_test_icbp_3),'timesteps_4':r2_score(preds_icbp_4, y_test_icbp_4)} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps 1\n",
    "# mae score icbp_1: 0.0071951216005588505\n",
    "# r2 score icbp_1: 0.9982912893287746\n",
    "# mape score icbp_1: 0.02911766342732286\n",
    "# rmse score icbp_1: 0.0115991115450196\n",
    "# timesteps 2\n",
    "# mae score icbp_2: 0.00874996393974662\n",
    "# r2 score icbp_2: 0.998219167116058\n",
    "# mape score icbp_2: 0.10803360291602122\n",
    "# rmse score icbp_2: 0.011925892437280167\n",
    "# timesteps 3\n",
    "# mae score icbp_3: 0.009715755021447626\n",
    "# r2 score icbp_3: 0.9975988977109971\n",
    "# mape score icbp_3: 0.03398883492185345\n",
    "# rmse score icbp_3: 0.013880861676693924\n",
    "# timesteps 4\n",
    "# mae score icbp_4: 0.24760012053707564\n",
    "# r2 score icbp_4: 0.0\n",
    "# mape score icbp_4: 0.46217821589569885\n",
    "# rmse score icbp_4: 0.2913636094589231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'timesteps_1': 0.0071951216005588505, 'timesteps_2': 0.00874996393974662, 'timesteps_3': 0.009715755021447626, 'timesteps_4': 0.24760012053707564}\n",
      "sorted rmse\n",
      "{'timesteps_1': 0.0115991115450196, 'timesteps_2': 0.011925892437280167, 'timesteps_3': 0.013880861676693924, 'timesteps_4': 0.2913636094589231}\n",
      "sorted mape\n",
      "{'timesteps_1': 0.02911766342732286, 'timesteps_3': 0.03398883492185345, 'timesteps_2': 0.10803360291602122, 'timesteps_4': 0.46217821589569885}\n",
      "sorted r2\n",
      "{'timesteps_1': 0.9982912893287746, 'timesteps_2': 0.998219167116058, 'timesteps_3': 0.9975988977109971, 'timesteps_4': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_icbp_1_sorted = dict(sorted(mae_icbp.items(),key=lambda item: item[1]))\n",
    "print(mae_icbp_1_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_icbp_sorted = dict(sorted(rmse_icbp.items(),key=lambda item: item[1]))\n",
    "print(rmse_icbp_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_icbp_sorted = dict(sorted(mape_icbp.items(),key=lambda item: item[1]))\n",
    "print(mape_icbp_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_icbp_sorted = dict(sorted(r2_icbp.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_icbp_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'timesteps_1': 0.0071951216005588505, 'timesteps_2': 0.00874996393974662, 'timesteps_3': 0.009715755021447626, 'timesteps_4': 0.24760012053707564}\n",
    "# sorted rmse\n",
    "# {'timesteps_1': 0.0115991115450196, 'timesteps_2': 0.011925892437280167, 'timesteps_3': 0.013880861676693924, 'timesteps_4': 0.2913636094589231}\n",
    "# sorted mape\n",
    "# {'timesteps_1': 0.02911766342732286, 'timesteps_3': 0.03398883492185345, 'timesteps_2': 0.10803360291602122, 'timesteps_4': 0.46217821589569885}\n",
    "# sorted r2\n",
    "# {'timesteps_1': 0.9982912893287746, 'timesteps_2': 0.998219167116058, 'timesteps_3': 0.9975988977109971, 'timesteps_4': 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jsmr = df_jsmr.reset_index(drop=True)\n",
    "arr_jsmr = df_jsmr.to_numpy()\n",
    "flat_jsmr = arr_jsmr.flatten()\n",
    "jsmr_X_1, jsmr_y_1 = split_sequence(flat_jsmr, n_steps_1)\n",
    "jsmr_X_2, jsmr_y_2 = split_sequence(flat_jsmr, n_steps_2)\n",
    "jsmr_X_3, jsmr_y_3 = split_sequence(flat_jsmr, n_steps_3)\n",
    "jsmr_X_4, jsmr_y_4 = split_sequence(flat_jsmr, n_steps_4)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_jsmr_1, X_test_jsmr_1, y_train_jsmr_1, y_test_jsmr_1 = train_test_split(jsmr_X_1, jsmr_y_1, test_size=0.33, random_state=42)\n",
    "X_train_jsmr_2, X_test_jsmr_2, y_train_jsmr_2, y_test_jsmr_2 = train_test_split(jsmr_X_2, jsmr_y_2, test_size=0.33, random_state=42)\n",
    "X_train_jsmr_3, X_test_jsmr_3, y_train_jsmr_3, y_test_jsmr_3 = train_test_split(jsmr_X_3, jsmr_y_3, test_size=0.33, random_state=42)\n",
    "X_train_jsmr_4, X_test_jsmr_4, y_train_jsmr_4, y_test_jsmr_4 = train_test_split(jsmr_X_4, jsmr_y_4, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_jsmr_1 = X_train_jsmr_1.reshape(X_train_jsmr_1.shape[0],X_train_jsmr_1.shape[1],n_features)\n",
    "X_test_jsmr_1 = X_test_jsmr_1.reshape(X_test_jsmr_1.shape[0],X_test_jsmr_1.shape[1],n_features)\n",
    "X_train_jsmr_2 = X_train_jsmr_2.reshape(X_train_jsmr_2.shape[0],X_train_jsmr_2.shape[1],n_features)\n",
    "X_test_jsmr_2 = X_test_jsmr_2.reshape(X_test_jsmr_2.shape[0],X_test_jsmr_2.shape[1],n_features)\n",
    "X_train_jsmr_3 = X_train_jsmr_3.reshape(X_train_jsmr_3.shape[0],X_train_jsmr_3.shape[1],n_features)\n",
    "X_test_jsmr_3 = X_test_jsmr_3.reshape(X_test_jsmr_3.shape[0],X_test_jsmr_3.shape[1],n_features)\n",
    "X_train_jsmr_4 = X_train_jsmr_4.reshape(X_train_jsmr_4.shape[0],X_train_jsmr_4.shape[1],n_features)\n",
    "X_test_jsmr_4 = X_test_jsmr_4.reshape(X_test_jsmr_4.shape[0],X_test_jsmr_4.shape[1],n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_4 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_4, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_4.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/59 [==============================] - 2s 10ms/step - loss: 0.2222 - mae: 0.2222 - val_loss: 0.0803 - val_mae: 0.0803\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.0613 - mae: 0.0613 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0234 - mae: 0.0234 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0205 - mae: 0.0205 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 70/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 71/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 72/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 73/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 74/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 75/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 76/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 77/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 78/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 79/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 80/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 81/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 82/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 83/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 84/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 85/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 86/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 87/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 88/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 89/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 90/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 91/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 92/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 93/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 94/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 95/100\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 96/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 97/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 98/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 99/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 100/100\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0132 - val_mae: 0.0132\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_1 = simple_model_jsmr_1.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.1,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 20.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 7ms/step - loss: 0.1468 - mae: 0.1468 - val_loss: 0.0530 - val_mae: 0.0530\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.0308 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0261 - val_mae: 0.0261\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0150 - val_mae: 0.0150\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_2 = simple_model_jsmr_2.fit(X_train_jsmr_2, y_train_jsmr_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 18.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.1130 - mae: 0.1130 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0224 - val_mae: 0.0224\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0131 - val_mae: 0.0131\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_3 = simple_model_jsmr_3.fit(X_train_jsmr_3, y_train_jsmr_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 20.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.2701 - mae: 0.2701 - val_loss: 0.1021 - val_mae: 0.1021\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0725 - mae: 0.0725 - val_loss: 0.0320 - val_mae: 0.0320\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0320 - mae: 0.0320 - val_loss: 0.0306 - val_mae: 0.0306\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0300 - mae: 0.0300 - val_loss: 0.0271 - val_mae: 0.0271\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0255 - mae: 0.0255 - val_loss: 0.0284 - val_mae: 0.0284\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0265 - val_mae: 0.0265\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0270 - val_mae: 0.0270\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0137 - mae: 0.013 - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0136 - val_mae: 0.0136\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_4 = simple_model_jsmr_4.fit(X_train_jsmr_4, y_train_jsmr_4,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 21.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_jsmr_1 = simple_model_jsmr_1.predict(X_test_jsmr_1)\n",
    "preds_jsmr_2 = simple_model_jsmr_2.predict(X_test_jsmr_2)\n",
    "preds_jsmr_3 = simple_model_jsmr_3.predict(X_test_jsmr_3)\n",
    "preds_jsmr_4 = simple_model_jsmr_4.predict(X_test_jsmr_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps 1\n",
      "mae score jsmr_1: 0.012709409360352766\n",
      "r2 score jsmr_1: 0.9935702374781473\n",
      "mape score jsmr_1: 0.030344619679000352\n",
      "rmse score jsmr_1: 0.017236430432879077\n",
      "timesteps 2\n",
      "mae score jsmr_2: 0.014326228000078446\n",
      "r2 score jsmr_2: 0.9923649299409023\n",
      "mape score jsmr_2: 0.03485906558726514\n",
      "rmse score jsmr_2: 0.018798476996323747\n",
      "timesteps 3\n",
      "mae score jsmr_3: 0.013212442520124074\n",
      "r2 score jsmr_3: 0.9929662622837995\n",
      "mape score jsmr_3: 0.04070394123414279\n",
      "rmse score jsmr_3: 0.017914216506633596\n",
      "timesteps 4\n",
      "mae score jsmr_4: 0.012534012823066423\n",
      "r2 score jsmr_4: 0.9933026921297792\n",
      "mape score jsmr_4: 0.029484858211290245\n",
      "rmse score jsmr_4: 0.01756805243763662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 1\")\n",
    "print(\"mae score jsmr_1: \"+str(mean_absolute_error(preds_jsmr_1, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_1: \"+str(r2_score(preds_jsmr_1, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_1: \"+str(mean_absolute_percentage_error(preds_jsmr_1, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_1: \"+str(np.sqrt(mean_squared_error(preds_jsmr_1, y_test_jsmr_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 2\")\n",
    "print(\"mae score jsmr_2: \"+str(mean_absolute_error(preds_jsmr_2, y_test_jsmr_2)))\n",
    "print(\"r2 score jsmr_2: \"+str(r2_score(preds_jsmr_2, y_test_jsmr_2)))\n",
    "print(\"mape score jsmr_2: \"+str(mean_absolute_percentage_error(preds_jsmr_2, y_test_jsmr_2)))\n",
    "print(\"rmse score jsmr_2: \"+str(np.sqrt(mean_squared_error(preds_jsmr_2, y_test_jsmr_2))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 3\")\n",
    "print(\"mae score jsmr_3: \"+str(mean_absolute_error(preds_jsmr_3, y_test_jsmr_3)))\n",
    "print(\"r2 score jsmr_3: \"+str(r2_score(preds_jsmr_3, y_test_jsmr_3)))\n",
    "print(\"mape score jsmr_3: \"+str(mean_absolute_percentage_error(preds_jsmr_3, y_test_jsmr_3)))\n",
    "print(\"rmse score jsmr_3: \"+str(np.sqrt(mean_squared_error(preds_jsmr_3, y_test_jsmr_3))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"timesteps 4\")\n",
    "print(\"mae score jsmr_4: \"+str(mean_absolute_error(preds_jsmr_4, y_test_jsmr_4)))\n",
    "print(\"r2 score jsmr_4: \"+str(r2_score(preds_jsmr_4, y_test_jsmr_4)))\n",
    "print(\"mape score jsmr_4: \"+str(mean_absolute_percentage_error(preds_jsmr_4, y_test_jsmr_4)))\n",
    "print(\"rmse score jsmr_4: \"+str(np.sqrt(mean_squared_error(preds_jsmr_4, y_test_jsmr_4))))\n",
    "\n",
    "mae_jsmr = {'timesteps_1':mean_absolute_error(preds_jsmr_1, y_test_jsmr_1),'timesteps_2':mean_absolute_error(preds_jsmr_2, y_test_jsmr_2),'timesteps_3':mean_absolute_error(preds_jsmr_3, y_test_jsmr_3),'timesteps_4':mean_absolute_error(preds_jsmr_4, y_test_jsmr_4)}\n",
    "\n",
    "mape_jsmr = {'timesteps_1':mean_absolute_percentage_error(preds_jsmr_1, y_test_jsmr_1),'timesteps_2':mean_absolute_percentage_error(preds_jsmr_2, y_test_jsmr_2),'timesteps_3':mean_absolute_percentage_error(preds_jsmr_3, y_test_jsmr_3),'timesteps_4':mean_absolute_percentage_error(preds_jsmr_4, y_test_jsmr_4)}\n",
    "\n",
    "rmse_jsmr = {'timesteps_1':np.sqrt(mean_squared_error(preds_jsmr_1, y_test_jsmr_1)),'timesteps_2':np.sqrt(mean_squared_error(preds_jsmr_2, y_test_jsmr_2)),'timesteps_3':np.sqrt(mean_squared_error(preds_jsmr_3, y_test_jsmr_3)),'timesteps_4':np.sqrt(mean_squared_error(preds_jsmr_4, y_test_jsmr_4))}\n",
    "\n",
    "r2_jsmr = {'timesteps_1':r2_score(preds_jsmr_1, y_test_jsmr_1),'timesteps_2':r2_score(preds_jsmr_2, y_test_jsmr_2),'timesteps_3':r2_score(preds_jsmr_3, y_test_jsmr_3),'timesteps_4':r2_score(preds_jsmr_4, y_test_jsmr_4)} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps 1\n",
    "# mae score jsmr_1: 0.012709409360352766\n",
    "# r2 score jsmr_1: 0.9935702374781473\n",
    "# mape score jsmr_1: 0.030344619679000352\n",
    "# rmse score jsmr_1: 0.017236430432879077\n",
    "# timesteps 2\n",
    "# mae score jsmr_2: 0.014326228000078446\n",
    "# r2 score jsmr_2: 0.9923649299409023\n",
    "# mape score jsmr_2: 0.03485906558726514\n",
    "# rmse score jsmr_2: 0.018798476996323747\n",
    "# timesteps 3\n",
    "# mae score jsmr_3: 0.013212442520124074\n",
    "# r2 score jsmr_3: 0.9929662622837995\n",
    "# mape score jsmr_3: 0.04070394123414279\n",
    "# rmse score jsmr_3: 0.017914216506633596\n",
    "# timesteps 4\n",
    "# mae score jsmr_4: 0.012534012823066423\n",
    "# r2 score jsmr_4: 0.9933026921297792\n",
    "# mape score jsmr_4: 0.029484858211290245\n",
    "# rmse score jsmr_4: 0.01756805243763662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'timesteps_4': 0.012534012823066423, 'timesteps_1': 0.012709409360352766, 'timesteps_3': 0.013212442520124074, 'timesteps_2': 0.014326228000078446}\n",
      "sorted rmse\n",
      "{'timesteps_1': 0.017236430432879077, 'timesteps_4': 0.01756805243763662, 'timesteps_3': 0.017914216506633596, 'timesteps_2': 0.018798476996323747}\n",
      "sorted mape\n",
      "{'timesteps_4': 0.029484858211290245, 'timesteps_1': 0.030344619679000352, 'timesteps_2': 0.03485906558726514, 'timesteps_3': 0.04070394123414279}\n",
      "sorted r2\n",
      "{'timesteps_1': 0.9935702374781473, 'timesteps_4': 0.9933026921297792, 'timesteps_3': 0.9929662622837995, 'timesteps_2': 0.9923649299409023}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_jsmr_1_sorted = dict(sorted(mae_jsmr.items(),key=lambda item: item[1]))\n",
    "print(mae_jsmr_1_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_jsmr_sorted = dict(sorted(rmse_jsmr.items(),key=lambda item: item[1]))\n",
    "print(rmse_jsmr_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_jsmr_sorted = dict(sorted(mape_jsmr.items(),key=lambda item: item[1]))\n",
    "print(mape_jsmr_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_jsmr_sorted = dict(sorted(r2_jsmr.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_jsmr_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'timesteps_4': 0.012534012823066423, 'timesteps_1': 0.012709409360352766, 'timesteps_3': 0.013212442520124074, 'timesteps_2': 0.014326228000078446}\n",
    "# sorted rmse\n",
    "# {'timesteps_1': 0.017236430432879077, 'timesteps_4': 0.01756805243763662, 'timesteps_3': 0.017914216506633596, 'timesteps_2': 0.018798476996323747}\n",
    "# sorted mape\n",
    "# {'timesteps_4': 0.029484858211290245, 'timesteps_1': 0.030344619679000352, 'timesteps_2': 0.03485906558726514, 'timesteps_3': 0.04070394123414279}\n",
    "# sorted r2\n",
    "# {'timesteps_1': 0.9935702374781473, 'timesteps_4': 0.9933026921297792, 'timesteps_3': 0.9929662622837995, 'timesteps_2': 0.9923649299409023}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kesimpulan hasil tuning timestep\n",
    "hasil tuning timestep diatas untuk keempat saham yang digunakan,\n",
    "ANTM 2 timestep\n",
    "ASII 3 timestep\n",
    "ICBP 1 timestep\n",
    "JSMR 1 atau 4 timestep\n",
    "\n",
    "keempat saham menunjukan hasil berbeda untuk tuning timesteps ini. untuk JSMR 1 timesteps memberikan hasil terbaik pada matriks RMSE dan R2 sedangkan 4 timestep memberikan hasil terbaik pada MAE dan MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIDDEN LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_37 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 2, 8)              320       \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 873\n",
      "Trainable params: 873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_40 (LSTM)              (None, 2, 8)              320       \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 2, 8)              544       \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,417\n",
      "Trainable params: 1,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_43 (LSTM)              (None, 2, 8)              320       \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 2, 8)              544       \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 2, 8)              544       \n",
      "                                                                 \n",
      " lstm_46 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,961\n",
      "Trainable params: 1,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h4 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h4.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.1521 - mae: 0.1521 - val_loss: 0.1064 - val_mae: 0.1064\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.0438 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0079 - val_mae: 0.0079\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1 = simple_model_antm_n2_h1.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 21.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 4s 11ms/step - loss: 0.0977 - mae: 0.0977 - val_loss: 0.0307 - val_mae: 0.0307\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0086 - mae: 0.008 - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0132 - val_mae: 0.0132\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h2 = simple_model_antm_n2_h2.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 28.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 4s 14ms/step - loss: 0.1490 - mae: 0.1490 - val_loss: 0.0780 - val_mae: 0.0780\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0523 - mae: 0.0523 - val_loss: 0.0498 - val_mae: 0.0498\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0376 - mae: 0.0376 - val_loss: 0.0294 - val_mae: 0.0294\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0260 - val_mae: 0.0260\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0103 - mae: 0.010 - 0s 6ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0230 - val_mae: 0.0230\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0099 - val_mae: 0.0099\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h3 = simple_model_antm_n2_h3.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 5s 18ms/step - loss: 0.1465 - mae: 0.1465 - val_loss: 0.0925 - val_mae: 0.0925\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0439 - mae: 0.0439 - val_loss: 0.0279 - val_mae: 0.0279\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0238 - val_mae: 0.0238\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0237 - val_mae: 0.0237\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0080 - val_mae: 0.0080\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h4 = simple_model_antm_n2_h4.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_antm_n2_h1 = simple_model_antm_n2_h1.predict(X_test_antm_2)\n",
    "preds_antm_n2_h2 = simple_model_antm_n2_h2.predict(X_test_antm_2)\n",
    "preds_antm_n2_h3= simple_model_antm_n2_h3.predict(X_test_antm_2)\n",
    "preds_antm_n2_h4= simple_model_antm_n2_h4.predict(X_test_antm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer 1\n",
      "mae score antm_n2_h1: 0.008152804872559106\n",
      "r2 score antm_n2_h1: 0.9949518577972858\n",
      "mape score antm_n2_h1: 0.03489248940375355\n",
      "rmse score antm_n2_h1: 0.013849466958302258\n",
      "hidden layer 2\n",
      "mae score antm_n2_h2: 0.013214672773774904\n",
      "r2 score antm_n2_h2: 0.9924275692637212\n",
      "mape score antm_n2_h2: 0.054800074878532695\n",
      "rmse score antm_n2_h2: 0.017459215173058307\n",
      "hidden layer 3\n",
      "mae score antm_n2_h3: 0.009998062981012124\n",
      "r2 score antm_n2_h3: 0.9940292328244711\n",
      "mape score antm_n2_h3: 0.04404339294199065\n",
      "rmse score antm_n2_h3: 0.015687598031636656\n",
      "hidden layer 4\n",
      "mae score antm_n2_h4: 0.008228418334623457\n",
      "r2 score antm_n2_h4: 0.9949234614902839\n",
      "mape score antm_n2_h4: 0.03492159235018264\n",
      "rmse score antm_n2_h4: 0.013806358248692464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 1\")\n",
    "print(\"mae score antm_n2_h1: \"+str(mean_absolute_error(preds_antm_n2_h1, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1: \"+str(r2_score(preds_antm_n2_h1, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1, y_test_antm_2))))\n",
    "\n",
    "print(\"hidden layer 2\")\n",
    "print(\"mae score antm_n2_h2: \"+str(mean_absolute_error(preds_antm_n2_h2, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h2: \"+str(r2_score(preds_antm_n2_h2, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h2: \"+str(mean_absolute_percentage_error(preds_antm_n2_h2, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h2: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h2, y_test_antm_2))))\n",
    "\n",
    "print(\"hidden layer 3\")\n",
    "print(\"mae score antm_n2_h3: \"+str(mean_absolute_error(preds_antm_n2_h3, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h3: \"+str(r2_score(preds_antm_n2_h3, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h3: \"+str(mean_absolute_percentage_error(preds_antm_n2_h3, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h3: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h3, y_test_antm_2))))\n",
    "\n",
    "print(\"hidden layer 4\")\n",
    "print(\"mae score antm_n2_h4: \"+str(mean_absolute_error(preds_antm_n2_h4, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h4: \"+str(r2_score(preds_antm_n2_h4, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h4: \"+str(mean_absolute_percentage_error(preds_antm_n2_h4, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h4: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h4, y_test_antm_2))))\n",
    "\n",
    "mae_antm_hl = {'hidden layer_n2_h1':mean_absolute_error(preds_antm_n2_h1, y_test_antm_2),'hidden layer_n2_h2':mean_absolute_error(preds_antm_n2_h2, y_test_antm_2),'hidden layer_n2_h3':mean_absolute_error(preds_antm_n2_h3, y_test_antm_2),'hidden layer_n2_h4':mean_absolute_error(preds_antm_n2_h4, y_test_antm_2)}\n",
    "\n",
    "mape_antm_hl = {'hidden layer_n2_h1':mean_absolute_percentage_error(preds_antm_n2_h1, y_test_antm_2),'hidden layer_n2_h2':mean_absolute_percentage_error(preds_antm_n2_h2, y_test_antm_2),'hidden layer_n2_h3':mean_absolute_percentage_error(preds_antm_n2_h3, y_test_antm_2),'hidden layer_n2_h4':mean_absolute_percentage_error(preds_antm_n2_h4, y_test_antm_2)}\n",
    "\n",
    "rmse_antm_hl = {'hidden layer_n2_h1':np.sqrt(mean_squared_error(preds_antm_n2_h1, y_test_antm_2)),'hidden layer_n2_h2':np.sqrt(mean_squared_error(preds_antm_n2_h2, y_test_antm_2)),'hidden layer_n2_h3':np.sqrt(mean_squared_error(preds_antm_n2_h3, y_test_antm_2)),'hidden layer_n2_h4':np.sqrt(mean_squared_error(preds_antm_n2_h4, y_test_antm_2))}\n",
    "\n",
    "r2_antm_hl = {'hidden layer_n2_h1':r2_score(preds_antm_n2_h1, y_test_antm_2),'hidden layer_n2_h2':r2_score(preds_antm_n2_h2, y_test_antm_2),'hidden layer_n2_h3':r2_score(preds_antm_n2_h3, y_test_antm_2),'hidden layer_n2_h4':r2_score(preds_antm_n2_h4, y_test_antm_2)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer 1\n",
    "# mae score antm_n2_h1: 0.008152804872559106\n",
    "# r2 score antm_n2_h1: 0.9949518577972858\n",
    "# mape score antm_n2_h1: 0.03489248940375355\n",
    "# rmse score antm_n2_h1: 0.013849466958302258\n",
    "# hidden layer 2\n",
    "# mae score antm_n2_h2: 0.013214672773774904\n",
    "# r2 score antm_n2_h2: 0.9924275692637212\n",
    "# mape score antm_n2_h2: 0.054800074878532695\n",
    "# rmse score antm_n2_h2: 0.017459215173058307\n",
    "# hidden layer 3\n",
    "# mae score antm_n2_h3: 0.009998062981012124\n",
    "# r2 score antm_n2_h3: 0.9940292328244711\n",
    "# mape score antm_n2_h3: 0.04404339294199065\n",
    "# rmse score antm_n2_h3: 0.015687598031636656\n",
    "# hidden layer 4\n",
    "# mae score antm_n2_h4: 0.008228418334623457\n",
    "# r2 score antm_n2_h4: 0.9949234614902839\n",
    "# mape score antm_n2_h4: 0.03492159235018264\n",
    "# rmse score antm_n2_h4: 0.013806358248692464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'hidden layer_n2_h1': 0.008152804872559106, 'hidden layer_n2_h4': 0.008228418334623457, 'hidden layer_n2_h3': 0.009998062981012124, 'hidden layer_n2_h2': 0.013214672773774904}\n",
      "sorted rmse\n",
      "{'hidden layer_n2_h4': 0.013806358248692464, 'hidden layer_n2_h1': 0.013849466958302258, 'hidden layer_n2_h3': 0.015687598031636656, 'hidden layer_n2_h2': 0.017459215173058307}\n",
      "sorted mape\n",
      "{'hidden layer_n2_h1': 0.03489248940375355, 'hidden layer_n2_h4': 0.03492159235018264, 'hidden layer_n2_h3': 0.04404339294199065, 'hidden layer_n2_h2': 0.054800074878532695}\n",
      "sorted r2\n",
      "{'hidden layer_n2_h1': 0.9949518577972858, 'hidden layer_n2_h4': 0.9949234614902839, 'hidden layer_n2_h3': 0.9940292328244711, 'hidden layer_n2_h2': 0.9924275692637212}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_antm_hl_sorted = dict(sorted(mae_antm_hl.items(),key=lambda item: item[1]))\n",
    "print(mae_antm_hl_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_antm_hl_sorted = dict(sorted(rmse_antm_hl.items(),key=lambda item: item[1]))\n",
    "print(rmse_antm_hl_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_antm_hl_sorted = dict(sorted(mape_antm_hl.items(),key=lambda item: item[1]))\n",
    "print(mape_antm_hl_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_antm_hl_sorted = dict(sorted(r2_antm_hl.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_antm_hl_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'hidden layer_n2_h1': 0.008152804872559106, 'hidden layer_n2_h4': 0.008228418334623457, 'hidden layer_n2_h3': 0.009998062981012124, 'hidden layer_n2_h2': 0.013214672773774904}\n",
    "# sorted rmse\n",
    "# {'hidden layer_n2_h4': 0.013806358248692464, 'hidden layer_n2_h1': 0.013849466958302258, 'hidden layer_n2_h3': 0.015687598031636656, 'hidden layer_n2_h2': 0.017459215173058307}\n",
    "# sorted mape\n",
    "# {'hidden layer_n2_h1': 0.03489248940375355, 'hidden layer_n2_h4': 0.03492159235018264, 'hidden layer_n2_h3': 0.04404339294199065, 'hidden layer_n2_h2': 0.054800074878532695}\n",
    "# sorted r2\n",
    "# {'hidden layer_n2_h1': 0.9949518577972858, 'hidden layer_n2_h4': 0.9949234614902839, 'hidden layer_n2_h3': 0.9940292328244711, 'hidden layer_n2_h2': 0.9924275692637212}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_104 (LSTM)             (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_107 (LSTM)             (None, 3, 8)              320       \n",
      "                                                                 \n",
      " lstm_108 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 873\n",
      "Trainable params: 873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_112 (LSTM)             (None, 3, 8)              320       \n",
      "                                                                 \n",
      " lstm_113 (LSTM)             (None, 3, 8)              544       \n",
      "                                                                 \n",
      " lstm_114 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,417\n",
      "Trainable params: 1,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_115 (LSTM)             (None, 3, 8)              320       \n",
      "                                                                 \n",
      " lstm_116 (LSTM)             (None, 3, 8)              544       \n",
      "                                                                 \n",
      " lstm_117 (LSTM)             (None, 3, 8)              544       \n",
      "                                                                 \n",
      " lstm_118 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,961\n",
      "Trainable params: 1,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h4 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h4.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.0516 - val_mae: 0.0516\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0258 - val_mae: 0.0258\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0238 - val_mae: 0.0238\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0212 - val_mae: 0.0212\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0238 - val_mae: 0.0238\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0246 - val_mae: 0.0246\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0290 - val_mae: 0.0290\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0230 - val_mae: 0.0230\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0146 - val_mae: 0.0146\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1 = simple_model_asii_n3_h1.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 21.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 3s 12ms/step - loss: 0.1849 - mae: 0.1849 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0322 - mae: 0.0322 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0297 - val_mae: 0.0297\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0251 - mae: 0.0251 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.0287 - val_mae: 0.0287\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0316 - val_mae: 0.0316\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0254 - mae: 0.0254 - val_loss: 0.0243 - val_mae: 0.0243\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.0238 - val_mae: 0.0238\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0270 - val_mae: 0.0270\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0234 - val_mae: 0.0234\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0405 - val_mae: 0.0405\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.0260 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0350 - val_mae: 0.0350\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0234 - mae: 0.0234 - val_loss: 0.0266 - val_mae: 0.0266\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0315 - val_mae: 0.0315\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0254 - val_mae: 0.0254\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0233 - val_mae: 0.0233\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0382 - val_mae: 0.0382\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0247 - val_mae: 0.0247\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0279 - val_mae: 0.0279\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0165 - val_mae: 0.0165\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h2 = simple_model_asii_n3_h2.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 28.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 6s 18ms/step - loss: 0.2144 - mae: 0.2144 - val_loss: 0.0672 - val_mae: 0.0672\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0406 - mae: 0.0406 - val_loss: 0.0252 - val_mae: 0.0252\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.0456 - val_mae: 0.0456\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0299 - mae: 0.0299 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0256 - mae: 0.0256 - val_loss: 0.0282 - val_mae: 0.0282\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0252 - mae: 0.0252 - val_loss: 0.0246 - val_mae: 0.0246\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0249 - mae: 0.0249 - val_loss: 0.0319 - val_mae: 0.0319\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0274 - val_mae: 0.0274\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0255 - val_mae: 0.0255\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0239 - mae: 0.0239 - val_loss: 0.0269 - val_mae: 0.0269\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0242 - mae: 0.0242 - val_loss: 0.0290 - val_mae: 0.0290\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0259 - mae: 0.0259 - val_loss: 0.0265 - val_mae: 0.0265\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0252 - val_mae: 0.0252\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0351 - val_mae: 0.0351\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0254 - mae: 0.0254 - val_loss: 0.0259 - val_mae: 0.0259\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0261 - mae: 0.0261 - val_loss: 0.0347 - val_mae: 0.0347\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0239 - mae: 0.0239 - val_loss: 0.0247 - val_mae: 0.0247\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0235 - mae: 0.023 - 0s 7ms/step - loss: 0.0234 - mae: 0.0234 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0248 - val_mae: 0.0248\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0255 - mae: 0.0255 - val_loss: 0.0275 - val_mae: 0.0275\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0276 - val_mae: 0.0276\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0314 - val_mae: 0.0314\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0253 - mae: 0.0253 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0240 - mae: 0.0240 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0304 - val_mae: 0.0304\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0571 - val_mae: 0.0571\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0233 - mae: 0.0233 - val_loss: 0.0379 - val_mae: 0.0379\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0323 - val_mae: 0.0323\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0237 - val_mae: 0.0237\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0224 - val_mae: 0.0224\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0226 - val_mae: 0.0226\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0237 - val_mae: 0.0237\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0260 - val_mae: 0.0260\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0237 - val_mae: 0.0237\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0299 - val_mae: 0.0299\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0241 - val_mae: 0.0241\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0265 - val_mae: 0.0265\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0286 - val_mae: 0.0286\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0275 - val_mae: 0.0275\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0212 - val_mae: 0.0212\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0234 - val_mae: 0.0234\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0286 - val_mae: 0.0286\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0238 - val_mae: 0.0238\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0296 - val_mae: 0.0296\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0184 - val_mae: 0.0184\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h3 = simple_model_asii_n3_h3.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 38.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 5s 20ms/step - loss: 0.2438 - mae: 0.2438 - val_loss: 0.1089 - val_mae: 0.1089\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0503 - mae: 0.0503 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0252 - mae: 0.0252 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0256 - mae: 0.0256 - val_loss: 0.0247 - val_mae: 0.0247\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.0422 - val_mae: 0.0422\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0332 - val_mae: 0.0332\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.0230 - val_mae: 0.0230\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0273 - mae: 0.0273 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0233 - mae: 0.0233 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0240 - mae: 0.0240 - val_loss: 0.0234 - val_mae: 0.0234\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0232 - mae: 0.0232 - val_loss: 0.0362 - val_mae: 0.0362\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0444 - val_mae: 0.0444\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0248 - mae: 0.0248 - val_loss: 0.0252 - val_mae: 0.0252\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0239 - val_mae: 0.0239\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0229 - val_mae: 0.0229\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0237 - mae: 0.0237 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0259 - val_mae: 0.0259\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0302 - val_mae: 0.0302\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0362 - val_mae: 0.0362\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0254 - val_mae: 0.0254\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0240 - val_mae: 0.0240\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0404 - val_mae: 0.0404\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0311 - val_mae: 0.0311\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0244 - val_mae: 0.0244\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0246 - val_mae: 0.0246\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0249 - val_mae: 0.0249\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0173 - mae: 0.017 - 0s 8ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0259 - val_mae: 0.0259\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0170 - val_mae: 0.0170\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h4 = simple_model_asii_n3_h4.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 43.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_asii_n3_h1 = simple_model_asii_n3_h1.predict(X_test_asii_3)\n",
    "preds_asii_n3_h2 = simple_model_asii_n3_h2.predict(X_test_asii_3)\n",
    "preds_asii_n3_h3= simple_model_asii_n3_h3.predict(X_test_asii_3)\n",
    "preds_asii_n3_h4= simple_model_asii_n3_h4.predict(X_test_asii_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer 1\n",
      "mae score asii_n3_h1: 0.014757829851888154\n",
      "r2 score asii_n3_h1: 0.9901460537730357\n",
      "mape score asii_n3_h1: 0.03297773155326224\n",
      "rmse score asii_n3_h1: 0.019715849938205837\n",
      "hidden layer 2\n",
      "mae score asii_n3_h2: 0.016830770740112168\n",
      "r2 score asii_n3_h2: 0.988113325668868\n",
      "mape score asii_n3_h2: 0.03642616801224726\n",
      "rmse score asii_n3_h2: 0.02168610640315832\n",
      "hidden layer 3\n",
      "mae score asii_n3_h3: 0.018521870427194456\n",
      "r2 score asii_n3_h3: 0.9867944354102721\n",
      "mape score asii_n3_h3: 0.03875453612873989\n",
      "rmse score asii_n3_h3: 0.023499048452511002\n",
      "hidden layer 4\n",
      "mae score asii_n3_h4: 0.016859120812902816\n",
      "r2 score asii_n3_h4: 0.9868324360049459\n",
      "mape score asii_n3_h4: 0.04349796703399346\n",
      "rmse score asii_n3_h4: 0.021919565859925376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 1\")\n",
    "print(\"mae score asii_n3_h1: \"+str(mean_absolute_error(preds_asii_n3_h1, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1: \"+str(r2_score(preds_asii_n3_h1, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1, y_test_asii_3))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 2\")\n",
    "print(\"mae score asii_n3_h2: \"+str(mean_absolute_error(preds_asii_n3_h2, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h2: \"+str(r2_score(preds_asii_n3_h2, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h2: \"+str(mean_absolute_percentage_error(preds_asii_n3_h2, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h2: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h2, y_test_asii_3))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 3\")\n",
    "print(\"mae score asii_n3_h3: \"+str(mean_absolute_error(preds_asii_n3_h3, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h3: \"+str(r2_score(preds_asii_n3_h3, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h3: \"+str(mean_absolute_percentage_error(preds_asii_n3_h3, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h3: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h3, y_test_asii_3))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 4\")\n",
    "print(\"mae score asii_n3_h4: \"+str(mean_absolute_error(preds_asii_n3_h4, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h4: \"+str(r2_score(preds_asii_n3_h4, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h4: \"+str(mean_absolute_percentage_error(preds_asii_n3_h4, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h4: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h4, y_test_asii_3))))\n",
    "\n",
    "mae_asii_hl = {'hidden layer_n3_h1':mean_absolute_error(preds_asii_n3_h1, y_test_asii_3),'hidden layer_n3_h2':mean_absolute_error(preds_asii_n3_h2, y_test_asii_3),'hidden layer_n3_h3':mean_absolute_error(preds_asii_n3_h3, y_test_asii_3),'hidden layer_n3_h4':mean_absolute_error(preds_asii_n3_h4, y_test_asii_3)}\n",
    "\n",
    "mape_asii_hl = {'hidden layer_n3_h1':mean_absolute_percentage_error(preds_asii_n3_h1, y_test_asii_3),'hidden layer_n3_h2':mean_absolute_percentage_error(preds_asii_n3_h2, y_test_asii_3),'hidden layer_n3_h3':mean_absolute_percentage_error(preds_asii_n3_h3, y_test_asii_3),'hidden layer_n3_h4':mean_absolute_percentage_error(preds_asii_n3_h4, y_test_asii_3)}\n",
    "\n",
    "rmse_asii_hl = {'hidden layer_n3_h1':np.sqrt(mean_squared_error(preds_asii_n3_h1, y_test_asii_3)),'hidden layer_n3_h2':np.sqrt(mean_squared_error(preds_asii_n3_h2, y_test_asii_3)),'hidden layer_n3_h3':np.sqrt(mean_squared_error(preds_asii_n3_h3, y_test_asii_3)),'hidden layer_n3_h4':np.sqrt(mean_squared_error(preds_asii_n3_h4, y_test_asii_3))}\n",
    "\n",
    "r2_asii_hl = {'hidden layer_n3_h1':r2_score(preds_asii_n3_h1, y_test_asii_3),'hidden layer_n3_h2':r2_score(preds_asii_n3_h2, y_test_asii_3),'hidden layer_n3_h3':r2_score(preds_asii_n3_h3, y_test_asii_3),'hidden layer_n3_h4':r2_score(preds_asii_n3_h4, y_test_asii_3)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer 1\n",
    "# mae score asii_n3_h1: 0.014757829851888154\n",
    "# r2 score asii_n3_h1: 0.9901460537730357\n",
    "# mape score asii_n3_h1: 0.03297773155326224\n",
    "# rmse score asii_n3_h1: 0.019715849938205837\n",
    "# hidden layer 2\n",
    "# mae score asii_n3_h2: 0.016830770740112168\n",
    "# r2 score asii_n3_h2: 0.988113325668868\n",
    "# mape score asii_n3_h2: 0.03642616801224726\n",
    "# rmse score asii_n3_h2: 0.02168610640315832\n",
    "# hidden layer 3\n",
    "# mae score asii_n3_h3: 0.018521870427194456\n",
    "# r2 score asii_n3_h3: 0.9867944354102721\n",
    "# mape score asii_n3_h3: 0.03875453612873989\n",
    "# rmse score asii_n3_h3: 0.023499048452511002\n",
    "# hidden layer 4\n",
    "# mae score asii_n3_h4: 0.016859120812902816\n",
    "# r2 score asii_n3_h4: 0.9868324360049459\n",
    "# mape score asii_n3_h4: 0.04349796703399346\n",
    "# rmse score asii_n3_h4: 0.021919565859925376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'hidden layer_n3_h1': 0.014757829851888154, 'hidden layer_n3_h2': 0.016830770740112168, 'hidden layer_n3_h4': 0.016859120812902816, 'hidden layer_n3_h3': 0.018521870427194456}\n",
      "sorted rmse\n",
      "{'hidden layer_n3_h1': 0.019715849938205837, 'hidden layer_n3_h2': 0.02168610640315832, 'hidden layer_n3_h4': 0.021919565859925376, 'hidden layer_n3_h3': 0.023499048452511002}\n",
      "sorted mape\n",
      "{'hidden layer_n3_h1': 0.03297773155326224, 'hidden layer_n3_h2': 0.03642616801224726, 'hidden layer_n3_h3': 0.03875453612873989, 'hidden layer_n3_h4': 0.04349796703399346}\n",
      "sorted r2\n",
      "{'hidden layer_n3_h1': 0.9901460537730357, 'hidden layer_n3_h2': 0.988113325668868, 'hidden layer_n3_h4': 0.9868324360049459, 'hidden layer_n3_h3': 0.9867944354102721}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_asii_hl_sorted = dict(sorted(mae_asii_hl.items(),key=lambda item: item[1]))\n",
    "print(mae_asii_hl_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_asii_hl_sorted = dict(sorted(rmse_asii_hl.items(),key=lambda item: item[1]))\n",
    "print(rmse_asii_hl_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_asii_hl_sorted = dict(sorted(mape_asii_hl.items(),key=lambda item: item[1]))\n",
    "print(mape_asii_hl_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_asii_hl_sorted = dict(sorted(r2_asii_hl.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_asii_hl_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'hidden layer_n3_h1': 0.014757829851888154, 'hidden layer_n3_h2': 0.016830770740112168, 'hidden layer_n3_h4': 0.016859120812902816, 'hidden layer_n3_h3': 0.018521870427194456}\n",
    "# sorted rmse\n",
    "# {'hidden layer_n3_h1': 0.019715849938205837, 'hidden layer_n3_h2': 0.02168610640315832, 'hidden layer_n3_h4': 0.021919565859925376, 'hidden layer_n3_h3': 0.023499048452511002}\n",
    "# sorted mape\n",
    "# {'hidden layer_n3_h1': 0.03297773155326224, 'hidden layer_n3_h2': 0.03642616801224726, 'hidden layer_n3_h3': 0.03875453612873989, 'hidden layer_n3_h4': 0.04349796703399346}\n",
    "# sorted r2\n",
    "# {'hidden layer_n3_h1': 0.9901460537730357, 'hidden layer_n3_h2': 0.988113325668868, 'hidden layer_n3_h4': 0.9868324360049459, 'hidden layer_n3_h3': 0.9867944354102721}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_119 (LSTM)             (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_120 (LSTM)             (None, 1, 8)              320       \n",
      "                                                                 \n",
      " lstm_121 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 873\n",
      "Trainable params: 873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_122 (LSTM)             (None, 1, 8)              320       \n",
      "                                                                 \n",
      " lstm_123 (LSTM)             (None, 1, 8)              544       \n",
      "                                                                 \n",
      " lstm_124 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,417\n",
      "Trainable params: 1,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_125 (LSTM)             (None, 1, 8)              320       \n",
      "                                                                 \n",
      " lstm_126 (LSTM)             (None, 1, 8)              544       \n",
      "                                                                 \n",
      " lstm_127 (LSTM)             (None, 1, 8)              544       \n",
      "                                                                 \n",
      " lstm_128 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,961\n",
      "Trainable params: 1,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h4 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h4.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.2424 - mae: 0.2424 - val_loss: 0.1269 - val_mae: 0.1269\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0775 - mae: 0.0775 - val_loss: 0.0245 - val_mae: 0.0245\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0083 - mae: 0.008 - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0086 - mae: 0.008 - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0073 - val_mae: 0.0073\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n3_h1 = simple_model_icbp_n1_h1.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 19.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 4s 14ms/step - loss: 0.2663 - mae: 0.2663 - val_loss: 0.1514 - val_mae: 0.1514\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0855 - mae: 0.0855 - val_loss: 0.0411 - val_mae: 0.0411\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0426 - mae: 0.0426 - val_loss: 0.0367 - val_mae: 0.0367\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0366 - mae: 0.0366 - val_loss: 0.0333 - val_mae: 0.0333\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0310 - mae: 0.0310 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0252 - mae: 0.0252 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0072 - val_mae: 0.0072\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0145 - val_mae: 0.0145\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n3_h2 = simple_model_icbp_n1_h2.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 28.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 5s 21ms/step - loss: 0.2701 - mae: 0.2701 - val_loss: 0.1240 - val_mae: 0.1240\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0737 - mae: 0.0737 - val_loss: 0.0502 - val_mae: 0.0502\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0499 - mae: 0.0499 - val_loss: 0.0381 - val_mae: 0.0381\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0383 - mae: 0.0383 - val_loss: 0.0293 - val_mae: 0.0293\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0073 - val_mae: 0.0073\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0119 - val_mae: 0.0119\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n3_h3 = simple_model_icbp_n1_h3.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 31.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 10s 26ms/step - loss: 0.3191 - mae: 0.3191 - val_loss: 0.2390 - val_mae: 0.2390\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2268 - val_mae: 0.2268\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2268 - val_mae: 0.2268\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2269 - val_mae: 0.2269\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2262 - val_mae: 0.2262\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2262 - val_mae: 0.2262\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2264 - val_mae: 0.2264\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2271 - val_mae: 0.2271\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2388 - mae: 0.2388 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2269 - val_mae: 0.2269\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2265 - val_mae: 0.2265\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2265 - val_mae: 0.2265\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2262 - val_mae: 0.2262\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2270 - val_mae: 0.2270\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2264 - val_mae: 0.2264\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2388 - mae: 0.2388 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2271 - val_mae: 0.2271\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2265 - val_mae: 0.2265\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2260 - val_mae: 0.2260\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2260 - val_mae: 0.2260\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2388 - mae: 0.2388 - val_loss: 0.2275 - val_mae: 0.2275\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2398 - mae: 0.2398 - val_loss: 0.2267 - val_mae: 0.2267\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2260 - val_mae: 0.2260\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2388 - mae: 0.2388 - val_loss: 0.2274 - val_mae: 0.2274\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2264 - val_mae: 0.2264\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2260 - val_mae: 0.2260\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2269 - val_mae: 0.2269\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2253 - val_mae: 0.2253\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2265 - val_mae: 0.2265\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2267 - val_mae: 0.2267\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2280 - val_mae: 0.2280\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2264 - val_mae: 0.2264\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2269 - val_mae: 0.2269\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2265 - val_mae: 0.2265\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2270 - val_mae: 0.2270\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2265 - val_mae: 0.2265\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2288 - val_mae: 0.2288\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2268 - val_mae: 0.2268\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2265 - val_mae: 0.2265\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2268 - val_mae: 0.2268\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2251 - val_mae: 0.2251\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2250 - val_mae: 0.2250\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2270 - val_mae: 0.2270\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2393 - mae: 0.2393 - val_loss: 0.2252 - val_mae: 0.2252\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2267 - val_mae: 0.2267\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2388 - mae: 0.2388 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2271 - val_mae: 0.2271\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2271 - val_mae: 0.2271\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2273 - val_mae: 0.2273\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2392 - mae: 0.2392 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2273 - val_mae: 0.2273\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2271 - val_mae: 0.2271\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2269 - val_mae: 0.2269\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2391 - mae: 0.2391 - val_loss: 0.2274 - val_mae: 0.2274\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2260 - val_mae: 0.2260\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.2390 - val_loss: 0.2261 - val_mae: 0.2261\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n3_h4 = simple_model_icbp_n1_h4.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 43.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_icbp_n1_h1 = simple_model_icbp_n1_h1.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h2 = simple_model_icbp_n1_h2.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h3= simple_model_icbp_n1_h3.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h4= simple_model_icbp_n1_h4.predict(X_test_icbp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer 1\n",
      "mae score icbp_n1_h1: 0.007086988590841109\n",
      "r2 score icbp_n1_h1: 0.9983233676202956\n",
      "mape score icbp_n1_h1: 0.03267820511245089\n",
      "rmse score icbp_n1_h1: 0.011508974319469607\n",
      "hidden layer 2\n",
      "mae score icbp_n1_h2: 0.014612323625379744\n",
      "r2 score icbp_n1_h2: 0.9958080907798392\n",
      "mape score icbp_n1_h2: 0.043830805202935724\n",
      "rmse score icbp_n1_h2: 0.018640083083157434\n",
      "hidden layer 3\n",
      "mae score icbp_n1_h3: 0.012223985095585319\n",
      "r2 score icbp_n1_h3: 0.9969796337720037\n",
      "mape score icbp_n1_h3: 0.04706924282926418\n",
      "rmse score icbp_n1_h3: 0.015606241078365998\n",
      "hidden layer 4\n",
      "mae score icbp_n1_h4: 0.24899680086672094\n",
      "r2 score icbp_n1_h4: -23672082351204.34\n",
      "mape score icbp_n1_h4: 0.47254809998808467\n",
      "rmse score icbp_n1_h4: 0.29000022547373844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 1\")\n",
    "print(\"mae score icbp_n1_h1: \"+str(mean_absolute_error(preds_icbp_n1_h1, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1: \"+str(r2_score(preds_icbp_n1_h1, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1, y_test_icbp_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 2\")\n",
    "print(\"mae score icbp_n1_h2: \"+str(mean_absolute_error(preds_icbp_n1_h2, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h2: \"+str(r2_score(preds_icbp_n1_h2, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h2: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h2, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h2: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h2, y_test_icbp_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 3\")\n",
    "print(\"mae score icbp_n1_h3: \"+str(mean_absolute_error(preds_icbp_n1_h3, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h3: \"+str(r2_score(preds_icbp_n1_h3, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h3: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h3, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h3: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h3, y_test_icbp_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 4\")\n",
    "print(\"mae score icbp_n1_h4: \"+str(mean_absolute_error(preds_icbp_n1_h4, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h4: \"+str(r2_score(preds_icbp_n1_h4, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h4: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h4, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h4: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h4, y_test_icbp_1))))\n",
    "\n",
    "mae_icbp_hl = {'hidden layer_n1_h1':mean_absolute_error(preds_icbp_n1_h1, y_test_icbp_1),'hidden layer_n1_h2':mean_absolute_error(preds_icbp_n1_h2, y_test_icbp_1),'hidden layer_n1_h3':mean_absolute_error(preds_icbp_n1_h3, y_test_icbp_1),'hidden layer_n1_h4':mean_absolute_error(preds_icbp_n1_h4, y_test_icbp_1)}\n",
    "\n",
    "mape_icbp_hl = {'hidden layer_n1_h1':mean_absolute_percentage_error(preds_icbp_n1_h1, y_test_icbp_1),'hidden layer_n1_h2':mean_absolute_percentage_error(preds_icbp_n1_h2, y_test_icbp_1),'hidden layer_n1_h3':mean_absolute_percentage_error(preds_icbp_n1_h3, y_test_icbp_1),'hidden layer_n1_h4':mean_absolute_percentage_error(preds_icbp_n1_h4, y_test_icbp_1)}\n",
    "\n",
    "rmse_icbp_hl = {'hidden layer_n1_h1':np.sqrt(mean_squared_error(preds_icbp_n1_h1, y_test_icbp_1)),'hidden layer_n1_h2':np.sqrt(mean_squared_error(preds_icbp_n1_h2, y_test_icbp_1)),'hidden layer_n1_h3':np.sqrt(mean_squared_error(preds_icbp_n1_h3, y_test_icbp_1)),'hidden layer_n1_h4':np.sqrt(mean_squared_error(preds_icbp_n1_h4, y_test_icbp_1))}\n",
    "\n",
    "r2_icbp_hl = {'hidden layer_n1_h1':r2_score(preds_icbp_n1_h1, y_test_icbp_1),'hidden layer_n1_h2':r2_score(preds_icbp_n1_h2, y_test_icbp_1),'hidden layer_n1_h3':r2_score(preds_icbp_n1_h3, y_test_icbp_1),'hidden layer_n1_h4':r2_score(preds_icbp_n1_h4, y_test_icbp_1)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer 1\n",
    "# mae score icbp_n1_h1: 0.007086988590841109\n",
    "# r2 score icbp_n1_h1: 0.9983233676202956\n",
    "# mape score icbp_n1_h1: 0.03267820511245089\n",
    "# rmse score icbp_n1_h1: 0.011508974319469607\n",
    "# hidden layer 2\n",
    "# mae score icbp_n1_h2: 0.014612323625379744\n",
    "# r2 score icbp_n1_h2: 0.9958080907798392\n",
    "# mape score icbp_n1_h2: 0.043830805202935724\n",
    "# rmse score icbp_n1_h2: 0.018640083083157434\n",
    "# hidden layer 3\n",
    "# mae score icbp_n1_h3: 0.012223985095585319\n",
    "# r2 score icbp_n1_h3: 0.9969796337720037\n",
    "# mape score icbp_n1_h3: 0.04706924282926418\n",
    "# rmse score icbp_n1_h3: 0.015606241078365998\n",
    "# hidden layer 4\n",
    "# mae score icbp_n1_h4: 0.24899680086672094\n",
    "# r2 score icbp_n1_h4: -23672082351204.34\n",
    "# mape score icbp_n1_h4: 0.47254809998808467\n",
    "# rmse score icbp_n1_h4: 0.29000022547373844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'hidden layer_n1_h1': 0.007086988590841109, 'hidden layer_n1_h3': 0.012223985095585319, 'hidden layer_n1_h2': 0.014612323625379744, 'hidden layer_n1_h4': 0.24899680086672094}\n",
      "sorted rmse\n",
      "{'hidden layer_n1_h1': 0.011508974319469607, 'hidden layer_n1_h3': 0.015606241078365998, 'hidden layer_n1_h2': 0.018640083083157434, 'hidden layer_n1_h4': 0.29000022547373844}\n",
      "sorted mape\n",
      "{'hidden layer_n1_h1': 0.03267820511245089, 'hidden layer_n1_h2': 0.043830805202935724, 'hidden layer_n1_h3': 0.04706924282926418, 'hidden layer_n1_h4': 0.47254809998808467}\n",
      "sorted r2\n",
      "{'hidden layer_n1_h1': 0.9983233676202956, 'hidden layer_n1_h3': 0.9969796337720037, 'hidden layer_n1_h2': 0.9958080907798392, 'hidden layer_n1_h4': -23672082351204.34}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_icbp_hl_sorted = dict(sorted(mae_icbp_hl.items(),key=lambda item: item[1]))\n",
    "print(mae_icbp_hl_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_icbp_hl_sorted = dict(sorted(rmse_icbp_hl.items(),key=lambda item: item[1]))\n",
    "print(rmse_icbp_hl_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_icbp_hl_sorted = dict(sorted(mape_icbp_hl.items(),key=lambda item: item[1]))\n",
    "print(mape_icbp_hl_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_icbp_hl_sorted = dict(sorted(r2_icbp_hl.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_icbp_hl_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'hidden layer_n1_h1': 0.007086988590841109, 'hidden layer_n1_h3': 0.012223985095585319, 'hidden layer_n1_h2': 0.014612323625379744, 'hidden layer_n1_h4': 0.24899680086672094}\n",
    "# sorted rmse\n",
    "# {'hidden layer_n1_h1': 0.011508974319469607, 'hidden layer_n1_h3': 0.015606241078365998, 'hidden layer_n1_h2': 0.018640083083157434, 'hidden layer_n1_h4': 0.29000022547373844}\n",
    "# sorted mape\n",
    "# {'hidden layer_n1_h1': 0.03267820511245089, 'hidden layer_n1_h2': 0.043830805202935724, 'hidden layer_n1_h3': 0.04706924282926418, 'hidden layer_n1_h4': 0.47254809998808467}\n",
    "# sorted r2\n",
    "# {'hidden layer_n1_h1': 0.9983233676202956, 'hidden layer_n1_h3': 0.9969796337720037, 'hidden layer_n1_h2': 0.9958080907798392, 'hidden layer_n1_h4': -23672082351204.34}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_129 (LSTM)             (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_130 (LSTM)             (None, 1, 8)              320       \n",
      "                                                                 \n",
      " lstm_131 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 873\n",
      "Trainable params: 873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_132 (LSTM)             (None, 1, 8)              320       \n",
      "                                                                 \n",
      " lstm_133 (LSTM)             (None, 1, 8)              544       \n",
      "                                                                 \n",
      " lstm_134 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,417\n",
      "Trainable params: 1,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_135 (LSTM)             (None, 1, 8)              320       \n",
      "                                                                 \n",
      " lstm_136 (LSTM)             (None, 1, 8)              544       \n",
      "                                                                 \n",
      " lstm_137 (LSTM)             (None, 1, 8)              544       \n",
      "                                                                 \n",
      " lstm_138 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,961\n",
      "Trainable params: 1,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h4 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu',return_sequences=True),\n",
    "  LSTM(8, activation='relu'),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h4.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 10ms/step - loss: 0.2940 - mae: 0.2940 - val_loss: 0.1198 - val_mae: 0.1198\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0997 - mae: 0.0997 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0226 - mae: 0.0226 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0147 - mae: 0.014 - 0s 5ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0119 - val_mae: 0.0119\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1 = simple_model_jsmr_n1_h1.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 27.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 6s 21ms/step - loss: 0.2988 - mae: 0.2988 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1139 - mae: 0.1139 - val_loss: 0.0566 - val_mae: 0.0566\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0399 - mae: 0.0399 - val_loss: 0.0305 - val_mae: 0.0305\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.0345 - val_mae: 0.0345\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0324 - mae: 0.0324 - val_loss: 0.0351 - val_mae: 0.0351\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0314 - mae: 0.0314 - val_loss: 0.0264 - val_mae: 0.0264\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0300 - mae: 0.0300 - val_loss: 0.0287 - val_mae: 0.0287\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0312 - mae: 0.0312 - val_loss: 0.0291 - val_mae: 0.0291\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0312 - mae: 0.0312 - val_loss: 0.0312 - val_mae: 0.0312\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.0260 - val_loss: 0.0234 - val_mae: 0.0234\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0250 - mae: 0.0250 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0239 - val_mae: 0.0239\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0128 - mae: 0.012 - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0134 - mae: 0.013 - 0s 5ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0234 - val_mae: 0.0234\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0242 - val_mae: 0.0242\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h2 = simple_model_jsmr_n1_h2.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 31.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 4s 15ms/step - loss: 0.2793 - mae: 0.2793 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0847 - mae: 0.0847 - val_loss: 0.0441 - val_mae: 0.0441\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 0.0424 - val_loss: 0.0445 - val_mae: 0.0445\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0328 - mae: 0.0328 - val_loss: 0.0256 - val_mae: 0.0256\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0288 - mae: 0.0288 - val_loss: 0.0233 - val_mae: 0.0233\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0244 - val_mae: 0.0244\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0226 - mae: 0.0226 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0370 - val_mae: 0.0370\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0425 - val_mae: 0.0425\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0333 - val_mae: 0.0333\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0314 - val_mae: 0.0314\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0239 - val_mae: 0.0239\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0266 - val_mae: 0.0266\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0259 - val_mae: 0.0259\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0265 - val_mae: 0.0265\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0244 - val_mae: 0.0244\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0270 - val_mae: 0.0270\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0243 - val_mae: 0.0243\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0249 - val_mae: 0.0249\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0270 - val_mae: 0.0270\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0251 - val_mae: 0.0251\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0276 - val_mae: 0.0276\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0230 - val_mae: 0.0230\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0120 - val_mae: 0.0120\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h3 = simple_model_jsmr_n1_h3.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 30.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 7s 25ms/step - loss: 0.2681 - mae: 0.2681 - val_loss: 0.1499 - val_mae: 0.1499\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0957 - mae: 0.0957 - val_loss: 0.0492 - val_mae: 0.0492\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0571 - val_mae: 0.0571\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.0361 - val_loss: 0.0429 - val_mae: 0.0429\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0322 - mae: 0.0322 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0243 - val_mae: 0.0243\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0318 - val_mae: 0.0318\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0252 - val_mae: 0.0252\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0307 - val_mae: 0.0307\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0232 - mae: 0.0232 - val_loss: 0.0260 - val_mae: 0.0260\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0298 - val_mae: 0.0298\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0257 - val_mae: 0.0257\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0241 - val_mae: 0.0241\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0304 - val_mae: 0.0304\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0324 - val_mae: 0.0324\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0249 - val_mae: 0.0249\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0271 - val_mae: 0.0271\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0280 - val_mae: 0.0280\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0224 - val_mae: 0.0224\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0332 - val_mae: 0.0332\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0327 - val_mae: 0.0327\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h4 = simple_model_jsmr_n1_h4.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "#time 43.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_jsmr_n1_h1 = simple_model_jsmr_n1_h1.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h2 = simple_model_jsmr_n1_h2.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h3= simple_model_jsmr_n1_h3.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h4= simple_model_jsmr_n1_h4.predict(X_test_jsmr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer 1\n",
      "mae score jsmr_n1_h1: 0.011318812825305483\n",
      "r2 score jsmr_n1_h1: 0.9943690684509984\n",
      "mape score jsmr_n1_h1: 0.03565450266272184\n",
      "rmse score jsmr_n1_h1: 0.016052783071759058\n",
      "hidden layer 2\n",
      "mae score jsmr_n1_h2: 0.023105861713602516\n",
      "r2 score jsmr_n1_h2: 0.984495483254619\n",
      "mape score jsmr_n1_h2: 0.05353211593323678\n",
      "rmse score jsmr_n1_h2: 0.02702812409054237\n",
      "hidden layer 3\n",
      "mae score jsmr_n1_h3: 0.01157825894564719\n",
      "r2 score jsmr_n1_h3: 0.9941938767627192\n",
      "mape score jsmr_n1_h3: 0.03242430534782007\n",
      "rmse score jsmr_n1_h3: 0.016230213939194986\n",
      "hidden layer 4\n",
      "mae score jsmr_n1_h4: 0.032494819793814744\n",
      "r2 score jsmr_n1_h4: 0.965350130015121\n",
      "mape score jsmr_n1_h4: 0.06866716078656558\n",
      "rmse score jsmr_n1_h4: 0.0374025859927203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 1\")\n",
    "print(\"mae score jsmr_n1_h1: \"+str(mean_absolute_error(preds_jsmr_n1_h1, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1: \"+str(r2_score(preds_jsmr_n1_h1, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1, y_test_jsmr_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 2\")\n",
    "print(\"mae score jsmr_n1_h2: \"+str(mean_absolute_error(preds_jsmr_n1_h2, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h2: \"+str(r2_score(preds_jsmr_n1_h2, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h2: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h2, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h2: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h2, y_test_jsmr_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 3\")\n",
    "print(\"mae score jsmr_n1_h3: \"+str(mean_absolute_error(preds_jsmr_n1_h3, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h3: \"+str(r2_score(preds_jsmr_n1_h3, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h3: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h3, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h3: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h3, y_test_jsmr_1))))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"hidden layer 4\")\n",
    "print(\"mae score jsmr_n1_h4: \"+str(mean_absolute_error(preds_jsmr_n1_h4, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h4: \"+str(r2_score(preds_jsmr_n1_h4, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h4: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h4, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h4: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h4, y_test_jsmr_1))))\n",
    "\n",
    "mae_jsmr_hl = {'hidden layer_n1_h1':mean_absolute_error(preds_jsmr_n1_h1, y_test_jsmr_1),'hidden layer_n1_h2':mean_absolute_error(preds_jsmr_n1_h2, y_test_jsmr_1),'hidden layer_n1_h3':mean_absolute_error(preds_jsmr_n1_h3, y_test_jsmr_1),'hidden layer_n1_h4':mean_absolute_error(preds_jsmr_n1_h4, y_test_jsmr_1)}\n",
    "\n",
    "mape_jsmr_hl = {'hidden layer_n1_h1':mean_absolute_percentage_error(preds_jsmr_n1_h1, y_test_jsmr_1),'hidden layer_n1_h2':mean_absolute_percentage_error(preds_jsmr_n1_h2, y_test_jsmr_1),'hidden layer_n1_h3':mean_absolute_percentage_error(preds_jsmr_n1_h3, y_test_jsmr_1),'hidden layer_n1_h4':mean_absolute_percentage_error(preds_jsmr_n1_h4, y_test_jsmr_1)}\n",
    "\n",
    "rmse_jsmr_hl = {'hidden layer_n1_h1':np.sqrt(mean_squared_error(preds_jsmr_n1_h1, y_test_jsmr_1)),'hidden layer_n1_h2':np.sqrt(mean_squared_error(preds_jsmr_n1_h2, y_test_jsmr_1)),'hidden layer_n1_h3':np.sqrt(mean_squared_error(preds_jsmr_n1_h3, y_test_jsmr_1)),'hidden layer_n1_h4':np.sqrt(mean_squared_error(preds_jsmr_n1_h4, y_test_jsmr_1))}\n",
    "\n",
    "r2_jsmr_hl = {'hidden layer_n1_h1':r2_score(preds_jsmr_n1_h1, y_test_jsmr_1),'hidden layer_n1_h2':r2_score(preds_jsmr_n1_h2, y_test_jsmr_1),'hidden layer_n1_h3':r2_score(preds_jsmr_n1_h3, y_test_jsmr_1),'hidden layer_n1_h4':r2_score(preds_jsmr_n1_h4, y_test_jsmr_1)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer 1\n",
    "# mae score jsmr_n1_h1: 0.011318812825305483\n",
    "# r2 score jsmr_n1_h1: 0.9943690684509984\n",
    "# mape score jsmr_n1_h1: 0.03565450266272184\n",
    "# rmse score jsmr_n1_h1: 0.016052783071759058\n",
    "# hidden layer 2\n",
    "# mae score jsmr_n1_h2: 0.023105861713602516\n",
    "# r2 score jsmr_n1_h2: 0.984495483254619\n",
    "# mape score jsmr_n1_h2: 0.05353211593323678\n",
    "# rmse score jsmr_n1_h2: 0.02702812409054237\n",
    "# hidden layer 3\n",
    "# mae score jsmr_n1_h3: 0.01157825894564719\n",
    "# r2 score jsmr_n1_h3: 0.9941938767627192\n",
    "# mape score jsmr_n1_h3: 0.03242430534782007\n",
    "# rmse score jsmr_n1_h3: 0.016230213939194986\n",
    "# hidden layer 4\n",
    "# mae score jsmr_n1_h4: 0.032494819793814744\n",
    "# r2 score jsmr_n1_h4: 0.965350130015121\n",
    "# mape score jsmr_n1_h4: 0.06866716078656558\n",
    "# rmse score jsmr_n1_h4: 0.0374025859927203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'hidden layer_n1_h1': 0.011318812825305483, 'hidden layer_n1_h3': 0.01157825894564719, 'hidden layer_n1_h2': 0.023105861713602516, 'hidden layer_n1_h4': 0.032494819793814744}\n",
      "sorted rmse\n",
      "{'hidden layer_n1_h1': 0.016052783071759058, 'hidden layer_n1_h3': 0.016230213939194986, 'hidden layer_n1_h2': 0.02702812409054237, 'hidden layer_n1_h4': 0.0374025859927203}\n",
      "sorted mape\n",
      "{'hidden layer_n1_h3': 0.03242430534782007, 'hidden layer_n1_h1': 0.03565450266272184, 'hidden layer_n1_h2': 0.05353211593323678, 'hidden layer_n1_h4': 0.06866716078656558}\n",
      "sorted r2\n",
      "{'hidden layer_n1_h1': 0.9943690684509984, 'hidden layer_n1_h3': 0.9941938767627192, 'hidden layer_n1_h2': 0.984495483254619, 'hidden layer_n1_h4': 0.965350130015121}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_jsmr_hl_sorted = dict(sorted(mae_jsmr_hl.items(),key=lambda item: item[1]))\n",
    "print(mae_jsmr_hl_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_jsmr_hl_sorted = dict(sorted(rmse_jsmr_hl.items(),key=lambda item: item[1]))\n",
    "print(rmse_jsmr_hl_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_jsmr_hl_sorted = dict(sorted(mape_jsmr_hl.items(),key=lambda item: item[1]))\n",
    "print(mape_jsmr_hl_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_jsmr_hl_sorted = dict(sorted(r2_jsmr_hl.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_jsmr_hl_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'hidden layer_n1_h1': 0.011318812825305483, 'hidden layer_n1_h3': 0.01157825894564719, 'hidden layer_n1_h2': 0.023105861713602516, 'hidden layer_n1_h4': 0.032494819793814744}\n",
    "# sorted rmse\n",
    "# {'hidden layer_n1_h1': 0.016052783071759058, 'hidden layer_n1_h3': 0.016230213939194986, 'hidden layer_n1_h2': 0.02702812409054237, 'hidden layer_n1_h4': 0.0374025859927203}\n",
    "# sorted mape\n",
    "# {'hidden layer_n1_h3': 0.03242430534782007, 'hidden layer_n1_h1': 0.03565450266272184, 'hidden layer_n1_h2': 0.05353211593323678, 'hidden layer_n1_h4': 0.06866716078656558}\n",
    "# sorted r2\n",
    "# {'hidden layer_n1_h1': 0.9943690684509984, 'hidden layer_n1_h3': 0.9941938767627192, 'hidden layer_n1_h2': 0.984495483254619, 'hidden layer_n1_h4': 0.965350130015121}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil tuning hidden layer\n",
    "Dari hasil diatas nampak untuk setiap data saham yang digunakan banyak hidden layer yg dibutuhkan untuk menghasilkan performa terbaik adalah 1 hidden layer untuk setiap data saham yang digunakan. dari keempat matriks menunjukan bahwa hidden layer satu menghasilkan performa terbaik dari hidden layer 2 3 dan 4. dan dari hasil diatas nampakh bahwa penambahan hidden layer tidak selamanya meningkatkan performa model untuk data saham yang digunakan.\n",
    "\n",
    "Selanjutnya untuk tuning neuron/unit akan digunakan hidden layer sebanyak 1 untuk semua pengujian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURON/Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm = df_antm.reset_index(drop=True)\n",
    "arr_antm = df_antm.to_numpy()\n",
    "flat_antm = arr_antm.flatten()\n",
    "antm_X_2, antm_y_2 = split_sequence(flat_antm, n_steps_2)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_antm_2, X_test_antm_2, y_train_antm_2, y_test_antm_2 = train_test_split(antm_X_2, antm_y_2, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "X_train_antm_2 = X_train_antm_2.reshape(X_train_antm_2.shape[0],X_train_antm_2.shape[1],n_features)\n",
    "X_test_antm_2 = X_test_antm_2.reshape(X_test_antm_2.shape[0],X_test_antm_2.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u8 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u8.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u8.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 16)                1152      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,169\n",
      "Trainable params: 1,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u16 = Sequential([\n",
    "  LSTM(16, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u16.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u32 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u32.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u32.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.0629 - mae: 0.0629 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u8 = simple_model_antm_n2_h1_u8.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 21.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 3s 10ms/step - loss: 0.0997 - mae: 0.0997 - val_loss: 0.0307 - val_mae: 0.0307\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0086 - val_mae: 0.0086\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u16 = simple_model_antm_n2_h1_u16.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 24.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 9ms/step - loss: 0.0682 - mae: 0.0682 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0087 - mae: 0.008 - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0080 - val_mae: 0.0080\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u32 = simple_model_antm_n2_h1_u32.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 21.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_antm_n2_h1_u8 = simple_model_antm_n2_h1_u8.predict(X_test_antm_2)\n",
    "preds_antm_n2_h1_u16 = simple_model_antm_n2_h1_u16.predict(X_test_antm_2)\n",
    "preds_antm_n2_h1_u32 = simple_model_antm_n2_h1_u32.predict(X_test_antm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron 8\n",
      "mae score antm_n2_h1_u8: 0.007381959033403783\n",
      "r2 score antm_n2_h1_u8: 0.9956150149776316\n",
      "mape score antm_n2_h1_u8: 0.031562910474329076\n",
      "rmse score antm_n2_h1_u8: 0.012952183842756504\n",
      "neuron 16\n",
      "mae score antm_n2_h1_u16: 0.00823605269281967\n",
      "r2 score antm_n2_h1_u16: 0.9955904992369539\n",
      "mape score antm_n2_h1_u16: 0.03322722405202451\n",
      "rmse score antm_n2_h1_u16: 0.013418698534813596\n",
      "neuron 32\n",
      "mae score antm_n2_h1_u32: 0.007800786881116363\n",
      "r2 score antm_n2_h1_u32: 0.9958286329046172\n",
      "mape score antm_n2_h1_u32: 0.03366333070273749\n",
      "rmse score antm_n2_h1_u32: 0.01281049725205452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"neuron 8\")\n",
    "print(\"mae score antm_n2_h1_u8: \"+str(mean_absolute_error(preds_antm_n2_h1_u8, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u8: \"+str(r2_score(preds_antm_n2_h1_u8, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u8: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u8, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u8: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u8, y_test_antm_2))))\n",
    "\n",
    "print(\"neuron 16\")\n",
    "print(\"mae score antm_n2_h1_u16: \"+str(mean_absolute_error(preds_antm_n2_h1_u16, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u16: \"+str(r2_score(preds_antm_n2_h1_u16, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u16: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u16, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u16: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u16, y_test_antm_2))))\n",
    "\n",
    "print(\"neuron 32\")\n",
    "print(\"mae score antm_n2_h1_u32: \"+str(mean_absolute_error(preds_antm_n2_h1_u32, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u32: \"+str(r2_score(preds_antm_n2_h1_u32, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u32: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u32, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u32: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u32, y_test_antm_2))))\n",
    "\n",
    "mae_antm_hl_u = {'model_n2_h1_u8':mean_absolute_error(preds_antm_n2_h1_u8, y_test_antm_2),'model_n2_h1':mean_absolute_error(preds_antm_n2_h1_u16, y_test_antm_2),'model_n2_h1_u32':mean_absolute_error(preds_antm_n2_h1_u32, y_test_antm_2)}\n",
    "\n",
    "mape_antm_hl_u = {'model_n2_h1_u8':mean_absolute_percentage_error(preds_antm_n2_h1_u8, y_test_antm_2),'model_n2_h1_u16':mean_absolute_percentage_error(preds_antm_n2_h1_u16, y_test_antm_2),'model_n2_h1_u32':mean_absolute_percentage_error(preds_antm_n2_h1_u32, y_test_antm_2)}\n",
    "\n",
    "rmse_antm_hl_u = {'model_n2_h1_u8':np.sqrt(mean_squared_error(preds_antm_n2_h1_u8, y_test_antm_2)),'model_n2_h1_u16':np.sqrt(mean_squared_error(preds_antm_n2_h1_u16, y_test_antm_2)),'model_n2_h1_u32':np.sqrt(mean_squared_error(preds_antm_n2_h1_u32, y_test_antm_2))}\n",
    "\n",
    "r2_antm_hl_u = {'model_n2_h1_u8':r2_score(preds_antm_n2_h1_u8, y_test_antm_2),'model_n2_h1_u16':r2_score(preds_antm_n2_h1_u16, y_test_antm_2),'model_n2_h1_u32':r2_score(preds_antm_n2_h1_u32, y_test_antm_2)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron 8\n",
    "# mae score antm_n2_h1_u8: 0.007381959033403783\n",
    "# r2 score antm_n2_h1_u8: 0.9956150149776316\n",
    "# mape score antm_n2_h1_u8: 0.031562910474329076\n",
    "# rmse score antm_n2_h1_u8: 0.012952183842756504\n",
    "# neuron 16\n",
    "# mae score antm_n2_h1_u16: 0.00823605269281967\n",
    "# r2 score antm_n2_h1_u16: 0.9955904992369539\n",
    "# mape score antm_n2_h1_u16: 0.03322722405202451\n",
    "# rmse score antm_n2_h1_u16: 0.013418698534813596\n",
    "# neuron 32\n",
    "# mae score antm_n2_h1_u32: 0.007800786881116363\n",
    "# r2 score antm_n2_h1_u32: 0.9958286329046172\n",
    "# mape score antm_n2_h1_u32: 0.03366333070273749\n",
    "# rmse score antm_n2_h1_u32: 0.01281049725205452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n2_h1_u8': 0.007381959033403783, 'model_n2_h1_u32': 0.007800786881116363, 'model_n2_h1': 0.00823605269281967}\n",
      "sorted rmse\n",
      "{'model_n2_h1_u32': 0.01281049725205452, 'model_n2_h1_u8': 0.012952183842756504, 'model_n2_h1_u16': 0.013418698534813596}\n",
      "sorted mape\n",
      "{'model_n2_h1_u8': 0.031562910474329076, 'model_n2_h1_u16': 0.03322722405202451, 'model_n2_h1_u32': 0.03366333070273749}\n",
      "sorted r2\n",
      "{'model_n2_h1_u32': 0.9958286329046172, 'model_n2_h1_u8': 0.9956150149776316, 'model_n2_h1_u16': 0.9955904992369539}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_antm_hl_u_sorted = dict(sorted(mae_antm_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mae_antm_hl_u_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_antm_hl_u_sorted = dict(sorted(rmse_antm_hl_u.items(),key=lambda item: item[1]))\n",
    "print(rmse_antm_hl_u_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_antm_hl_u_sorted = dict(sorted(mape_antm_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mape_antm_hl_u_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_antm_hl_u_sorted = dict(sorted(r2_antm_hl_u.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_antm_hl_u_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_antm_n2_h1_u8': 0.007381959033403783, 'model_antm_n2_h1_u32': 0.007800786881116363, 'model_antm_n2_h1': 0.00823605269281967}\n",
    "# sorted rmse\n",
    "# {'model_antm_n2_h1_u32': 0.01281049725205452, 'model_antm_n2_h1_u8': 0.012952183842756504, 'model_antm_n2_h1_u16': 0.013418698534813596}\n",
    "# sorted mape\n",
    "# {'model_antm_n2_h1_u8': 0.031562910474329076, 'model_antm_n2_h1_u16': 0.03322722405202451, 'model_antm_n2_h1_u32': 0.03366333070273749}\n",
    "# sorted r2\n",
    "# {'model_antm_n2_h1_u32': 0.9958286329046172, 'model_antm_n2_h1_u8': 0.9956150149776316, 'model_antm_n2_h1_u16': 0.9955904992369539}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asii = df_asii.reset_index(drop=True)\n",
    "arr_asii = df_asii.to_numpy()\n",
    "flat_asii = arr_asii.flatten()\n",
    "asii_X_3, asii_y_3 = split_sequence(flat_asii, n_steps_3)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_asii_3, X_test_asii_3, y_train_asii_3, y_test_asii_3 = train_test_split(asii_X_3, asii_y_3, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_asii_3 = X_train_asii_3.reshape(X_train_asii_3.shape[0],X_train_asii_3.shape[1],n_features)\n",
    "X_test_asii_3 = X_test_asii_3.reshape(X_test_asii_3.shape[0],X_test_asii_3.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u8 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u8.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u8.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 16)                1152      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,169\n",
      "Trainable params: 1,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u16 = Sequential([\n",
    "  LSTM(16, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u16.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u32 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u32.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u32.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 3s 15ms/step - loss: 0.3797 - mae: 0.3797 - val_loss: 0.1841 - val_mae: 0.1841\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1625 - mae: 0.1625 - val_loss: 0.1530 - val_mae: 0.1530\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1539 - val_mae: 0.1539\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1596 - mae: 0.1596 - val_loss: 0.1542 - val_mae: 0.1542\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1548 - val_mae: 0.1548\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1546 - val_mae: 0.1546\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1532 - val_mae: 0.1532\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1537 - val_mae: 0.1537\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1537 - val_mae: 0.1537\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1543 - val_mae: 0.1543\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1560 - val_mae: 0.1560\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1547 - val_mae: 0.1547\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1553 - val_mae: 0.1553\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1555 - val_mae: 0.1555\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1611 - mae: 0.1611 - val_loss: 0.1556 - val_mae: 0.1556\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1558 - val_mae: 0.1558\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1529 - val_mae: 0.1529\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1547 - val_mae: 0.1547\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1560 - val_mae: 0.1560\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1604 - mae: 0.1604 - val_loss: 0.1552 - val_mae: 0.1552\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1542 - val_mae: 0.1542\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1542 - val_mae: 0.1542\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1545 - val_mae: 0.1545\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1567 - val_mae: 0.1567\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1606 - mae: 0.1606 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1555 - val_mae: 0.1555\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1589 - mae: 0.158 - 0s 3ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1549 - val_mae: 0.1549\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1530 - val_mae: 0.1530\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1540 - val_mae: 0.1540\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1547 - val_mae: 0.1547\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1596 - mae: 0.1596 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1607 - mae: 0.1607 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1534 - val_mae: 0.1534\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1594 - mae: 0.1594 - val_loss: 0.1564 - val_mae: 0.1564\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1598 - mae: 0.159 - 0s 4ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1554 - val_mae: 0.1554\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1609 - mae: 0.1609 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1534 - val_mae: 0.1534\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1563 - val_mae: 0.1563\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1604 - mae: 0.1604 - val_loss: 0.1546 - val_mae: 0.1546\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1567 - val_mae: 0.1567\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1540 - val_mae: 0.1540\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1529 - val_mae: 0.1529\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1553 - val_mae: 0.1553\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1579 - val_mae: 0.1579\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1615 - mae: 0.1615 - val_loss: 0.1563 - val_mae: 0.1563\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1534 - val_mae: 0.1534\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1532 - val_mae: 0.1532\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1558 - val_mae: 0.1558\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1604 - mae: 0.1604 - val_loss: 0.1529 - val_mae: 0.1529\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.1533 - val_mae: 0.1533\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1543 - val_mae: 0.1543\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1537 - val_mae: 0.1537\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1548 - val_mae: 0.1548\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1606 - mae: 0.1606 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1598 - mae: 0.1598 - val_loss: 0.1527 - val_mae: 0.1527\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1605 - mae: 0.1605 - val_loss: 0.1561 - val_mae: 0.1561\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1531 - val_mae: 0.1531\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1558 - val_mae: 0.1558\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1546 - val_mae: 0.1546\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1528 - val_mae: 0.1528\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1599 - mae: 0.1599 - val_loss: 0.1554 - val_mae: 0.1554\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1536 - val_mae: 0.1536\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1545 - val_mae: 0.1545\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1601 - mae: 0.1601 - val_loss: 0.1531 - val_mae: 0.1531\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1603 - mae: 0.1603 - val_loss: 0.1549 - val_mae: 0.1549\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1602 - mae: 0.1602 - val_loss: 0.1543 - val_mae: 0.1543\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1600 - mae: 0.1600 - val_loss: 0.1564 - val_mae: 0.1564\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u8 = simple_model_asii_n3_h1_u8.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 12ms/step - loss: 0.1264 - mae: 0.1264 - val_loss: 0.0226 - val_mae: 0.0226\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0307 - val_mae: 0.0307\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0252 - val_mae: 0.0252\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0310 - val_mae: 0.0310\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0167 - mae: 0.016 - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0270 - val_mae: 0.0270\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0167 - val_mae: 0.0167\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u16 = simple_model_asii_n3_h1_u16.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 23.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.1090 - mae: 0.1090 - val_loss: 0.0243 - val_mae: 0.0243\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0240 - mae: 0.0240 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0218 - mae: 0.0218 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0224 - mae: 0.0224 - val_loss: 0.0349 - val_mae: 0.0349\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0248 - mae: 0.0248 - val_loss: 0.0279 - val_mae: 0.0279\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0240 - mae: 0.0240 - val_loss: 0.0301 - val_mae: 0.0301\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0305 - val_mae: 0.0305\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0271 - val_mae: 0.0271\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0295 - val_mae: 0.0295\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0286 - val_mae: 0.0286\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0250 - val_mae: 0.0250\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0157 - val_mae: 0.0157\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u32 = simple_model_asii_n3_h1_u32.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 23.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_asii_n3_h1_u8 = simple_model_asii_n3_h1_u8.predict(X_test_asii_3)\n",
    "preds_asii_n3_h1_u16 = simple_model_asii_n3_h1_u16.predict(X_test_asii_3)\n",
    "preds_asii_n3_h1_u32 = simple_model_asii_n3_h1_u32.predict(X_test_asii_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron 8\n",
      "mae score asii_n3_h1_u8: 0.15513243754641684\n",
      "r2 score asii_n3_h1_u8: -11116048445753.354\n",
      "mape score asii_n3_h1_u8: 0.26755254397103484\n",
      "rmse score asii_n3_h1_u8: 0.1987262875601528\n",
      "neuron 16\n",
      "mae score asii_n3_h1_u16: 0.017059779115095142\n",
      "r2 score asii_n3_h1_u16: 0.988098607751643\n",
      "mape score asii_n3_h1_u16: 0.0367542015337045\n",
      "rmse score asii_n3_h1_u16: 0.021834368279878055\n",
      "neuron 32\n",
      "mae score asii_n3_h1_u32: 0.01606562881645174\n",
      "r2 score asii_n3_h1_u32: 0.9890624663068344\n",
      "mape score asii_n3_h1_u32: 0.03518855064266929\n",
      "rmse score asii_n3_h1_u32: 0.02089426813565111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"neuron 8\")\n",
    "print(\"mae score asii_n3_h1_u8: \"+str(mean_absolute_error(preds_asii_n3_h1_u8, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u8: \"+str(r2_score(preds_asii_n3_h1_u8, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u8: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u8, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u8: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u8, y_test_asii_3))))\n",
    "\n",
    "print(\"neuron 16\")\n",
    "print(\"mae score asii_n3_h1_u16: \"+str(mean_absolute_error(preds_asii_n3_h1_u16, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u16: \"+str(r2_score(preds_asii_n3_h1_u16, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u16: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u16, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u16: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u16, y_test_asii_3))))\n",
    "\n",
    "print(\"neuron 32\")\n",
    "print(\"mae score asii_n3_h1_u32: \"+str(mean_absolute_error(preds_asii_n3_h1_u32, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u32: \"+str(r2_score(preds_asii_n3_h1_u32, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u32: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u32, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u32: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u32, y_test_asii_3))))\n",
    "\n",
    "mae_asii_hl_u = {'model_n3_h1_u8':mean_absolute_error(preds_asii_n3_h1_u8, y_test_asii_3),'model_n3_h1':mean_absolute_error(preds_asii_n3_h1_u16, y_test_asii_3),'model_n3_h1_u32':mean_absolute_error(preds_asii_n3_h1_u32, y_test_asii_3)}\n",
    "\n",
    "mape_asii_hl_u = {'model_n3_h1_u8':mean_absolute_percentage_error(preds_asii_n3_h1_u8, y_test_asii_3),'model_n3_h1_u16':mean_absolute_percentage_error(preds_asii_n3_h1_u16, y_test_asii_3),'model_n3_h1_u32':mean_absolute_percentage_error(preds_asii_n3_h1_u32, y_test_asii_3)}\n",
    "\n",
    "rmse_asii_hl_u = {'model_n3_h1_u8':np.sqrt(mean_squared_error(preds_asii_n3_h1_u8, y_test_asii_3)),'model_n3_h1_u16':np.sqrt(mean_squared_error(preds_asii_n3_h1_u16, y_test_asii_3)),'model_n3_h1_u32':np.sqrt(mean_squared_error(preds_asii_n3_h1_u32, y_test_asii_3))}\n",
    "\n",
    "r2_asii_hl_u = {'model_n3_h1_u8':r2_score(preds_asii_n3_h1_u8, y_test_asii_3),'model_n3_h1_u16':r2_score(preds_asii_n3_h1_u16, y_test_asii_3),'model_n3_h1_u32':r2_score(preds_asii_n3_h1_u32, y_test_asii_3)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron 8\n",
    "# mae score asii_n3_h1_u8: 0.15513243754641684\n",
    "# r2 score asii_n3_h1_u8: -11116048445753.354\n",
    "# mape score asii_n3_h1_u8: 0.26755254397103484\n",
    "# rmse score asii_n3_h1_u8: 0.1987262875601528\n",
    "# neuron 16\n",
    "# mae score asii_n3_h1_u16: 0.017059779115095142\n",
    "# r2 score asii_n3_h1_u16: 0.988098607751643\n",
    "# mape score asii_n3_h1_u16: 0.0367542015337045\n",
    "# rmse score asii_n3_h1_u16: 0.021834368279878055\n",
    "# neuron 32\n",
    "# mae score asii_n3_h1_u32: 0.01606562881645174\n",
    "# r2 score asii_n3_h1_u32: 0.9890624663068344\n",
    "# mape score asii_n3_h1_u32: 0.03518855064266929\n",
    "# rmse score asii_n3_h1_u32: 0.02089426813565111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n3_h1_u32': 0.01606562881645174, 'model_n3_h1': 0.017059779115095142, 'model_n3_h1_u8': 0.15513243754641684}\n",
      "sorted rmse\n",
      "{'model_n3_h1_u32': 0.02089426813565111, 'model_n3_h1_u16': 0.021834368279878055, 'model_n3_h1_u8': 0.1987262875601528}\n",
      "sorted mape\n",
      "{'model_n3_h1_u32': 0.03518855064266929, 'model_n3_h1_u16': 0.0367542015337045, 'model_n3_h1_u8': 0.26755254397103484}\n",
      "sorted r2\n",
      "{'model_n3_h1_u32': 0.9890624663068344, 'model_n3_h1_u16': 0.988098607751643, 'model_n3_h1_u8': -11116048445753.354}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_asii_hl_u_sorted = dict(sorted(mae_asii_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mae_asii_hl_u_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_asii_hl_u_sorted = dict(sorted(rmse_asii_hl_u.items(),key=lambda item: item[1]))\n",
    "print(rmse_asii_hl_u_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_asii_hl_u_sorted = dict(sorted(mape_asii_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mape_asii_hl_u_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_asii_hl_u_sorted = dict(sorted(r2_asii_hl_u.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_asii_hl_u_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_asii_n3_h1_u32': 0.01606562881645174, 'model_asii_n3_h1': 0.017059779115095142, 'model_asii_n3_h1_u8': 0.15513243754641684}\n",
    "# sorted rmse\n",
    "# {'model_asii_n3_h1_u32': 0.02089426813565111, 'model_asii_n3_h1_u16': 0.021834368279878055, 'model_asii_n3_h1_u8': 0.1987262875601528}\n",
    "# sorted mape\n",
    "# {'model_asii_n3_h1_u32': 0.03518855064266929, 'model_asii_n3_h1_u16': 0.0367542015337045, 'model_asii_n3_h1_u8': 0.26755254397103484}\n",
    "# sorted r2\n",
    "# {'model_asii_n3_h1_u32': 0.9890624663068344, 'model_asii_n3_h1_u16': 0.988098607751643, 'model_asii_n3_h1_u8': -11116048445753.354}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icbp = df_icbp.reset_index(drop=True)\n",
    "arr_icbp = df_icbp.to_numpy()\n",
    "flat_icbp = arr_icbp.flatten()\n",
    "icbp_X_1, icbp_y_1 = split_sequence(flat_icbp, n_steps_1)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_icbp_1, X_test_icbp_1, y_train_icbp_1, y_test_icbp_1 = train_test_split(icbp_X_1, icbp_y_1, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_icbp_1 = X_train_icbp_1.reshape(X_train_icbp_1.shape[0],X_train_icbp_1.shape[1],n_features)\n",
    "X_test_icbp_1 = X_test_icbp_1.reshape(X_test_icbp_1.shape[0],X_test_icbp_1.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u8 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u8.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u8.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 16)                1152      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,169\n",
      "Trainable params: 1,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u16 = Sequential([\n",
    "  LSTM(16, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u16.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u32 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u32.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u32.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 11ms/step - loss: 0.2193 - mae: 0.2193 - val_loss: 0.1097 - val_mae: 0.1097\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0539 - mae: 0.0539 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0078 - val_mae: 0.0078\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u8 = simple_model_icbp_n1_h1_u8.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 7ms/step - loss: 0.1785 - mae: 0.1785 - val_loss: 0.0715 - val_mae: 0.0715\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0314 - mae: 0.0314 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0132 - val_mae: 0.0132\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u16 = simple_model_icbp_n1_h1_u16.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 20.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.1979 - mae: 0.1979 - val_loss: 0.0812 - val_mae: 0.0812\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0374 - mae: 0.0374 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0205 - mae: 0.0205 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0084 - val_mae: 0.0084\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u32 = simple_model_icbp_n1_h1_u32.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_icbp_n1_h1_u8 = simple_model_icbp_n1_h1_u8.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h1_u16 = simple_model_icbp_n1_h1_u16.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h1_u32 = simple_model_icbp_n1_h1_u32.predict(X_test_icbp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron 8\n",
      "mae score icbp_n1_h1_u8: 0.007219575749619669\n",
      "r2 score icbp_n1_h1_u8: 0.9985081548048771\n",
      "mape score icbp_n1_h1_u8: 0.03275499929793462\n",
      "rmse score icbp_n1_h1_u8: 0.010855205473752638\n",
      "neuron 16\n",
      "mae score icbp_n1_h1_u16: 0.013130016098796896\n",
      "r2 score icbp_n1_h1_u16: 0.996696203217586\n",
      "mape score icbp_n1_h1_u16: 0.04979794569797597\n",
      "rmse score icbp_n1_h1_u16: 0.016273690008413277\n",
      "neuron 32\n",
      "mae score icbp_n1_h1_u32: 0.007642545358463815\n",
      "r2 score icbp_n1_h1_u32: 0.9983299891561908\n",
      "mape score icbp_n1_h1_u32: 0.03016892717619271\n",
      "rmse score icbp_n1_h1_u32: 0.011347603920705211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"neuron 8\")\n",
    "print(\"mae score icbp_n1_h1_u8: \"+str(mean_absolute_error(preds_icbp_n1_h1_u8, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u8: \"+str(r2_score(preds_icbp_n1_h1_u8, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u8: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u8, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u8: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8, y_test_icbp_1))))\n",
    "\n",
    "print(\"neuron 16\")\n",
    "print(\"mae score icbp_n1_h1_u16: \"+str(mean_absolute_error(preds_icbp_n1_h1_u16, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u16: \"+str(r2_score(preds_icbp_n1_h1_u16, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u16: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u16, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u16: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u16, y_test_icbp_1))))\n",
    "\n",
    "print(\"neuron 32\")\n",
    "print(\"mae score icbp_n1_h1_u32: \"+str(mean_absolute_error(preds_icbp_n1_h1_u32, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u32: \"+str(r2_score(preds_icbp_n1_h1_u32, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u32: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u32, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u32: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u32, y_test_icbp_1))))\n",
    "\n",
    "mae_icbp_hl_u = {'model_n1_h1_u8':mean_absolute_error(preds_icbp_n1_h1_u8, y_test_icbp_1),'model_n1_h1':mean_absolute_error(preds_icbp_n1_h1_u16, y_test_icbp_1),'model_n1_h1_u32':mean_absolute_error(preds_icbp_n1_h1_u32, y_test_icbp_1)}\n",
    "\n",
    "mape_icbp_hl_u = {'model_n1_h1_u8':mean_absolute_percentage_error(preds_icbp_n1_h1_u8, y_test_icbp_1),'model_n1_h1_u16':mean_absolute_percentage_error(preds_icbp_n1_h1_u16, y_test_icbp_1),'model_n1_h1_u32':mean_absolute_percentage_error(preds_icbp_n1_h1_u32, y_test_icbp_1)}\n",
    "\n",
    "rmse_icbp_hl_u = {'model_n1_h1_u8':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8, y_test_icbp_1)),'model_n1_h1_u16':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u16, y_test_icbp_1)),'model_n1_h1_u32':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u32, y_test_icbp_1))}\n",
    "\n",
    "r2_icbp_hl_u = {'model_n1_h1_u8':r2_score(preds_icbp_n1_h1_u8, y_test_icbp_1),'model_n1_h1_u16':r2_score(preds_icbp_n1_h1_u16, y_test_icbp_1),'model_n1_h1_u32':r2_score(preds_icbp_n1_h1_u32, y_test_icbp_1)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron 8\n",
    "# mae score icbp_n1_h1_u8: 0.007219575749619669\n",
    "# r2 score icbp_n1_h1_u8: 0.9985081548048771\n",
    "# mape score icbp_n1_h1_u8: 0.03275499929793462\n",
    "# rmse score icbp_n1_h1_u8: 0.010855205473752638\n",
    "# neuron 16\n",
    "# mae score icbp_n1_h1_u16: 0.013130016098796896\n",
    "# r2 score icbp_n1_h1_u16: 0.996696203217586\n",
    "# mape score icbp_n1_h1_u16: 0.04979794569797597\n",
    "# rmse score icbp_n1_h1_u16: 0.016273690008413277\n",
    "# neuron 32\n",
    "# mae score icbp_n1_h1_u32: 0.007642545358463815\n",
    "# r2 score icbp_n1_h1_u32: 0.9983299891561908\n",
    "# mape score icbp_n1_h1_u32: 0.03016892717619271\n",
    "# rmse score icbp_n1_h1_u32: 0.011347603920705211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n1_h1_u8': 0.007219575749619669, 'model_n1_h1_u32': 0.007642545358463815, 'model_n1_h1': 0.013130016098796896}\n",
      "sorted rmse\n",
      "{'model_n1_h1_u8': 0.010855205473752638, 'model_n1_h1_u32': 0.011347603920705211, 'model_n1_h1_u16': 0.016273690008413277}\n",
      "sorted mape\n",
      "{'model_n1_h1_u32': 0.03016892717619271, 'model_n1_h1_u8': 0.03275499929793462, 'model_n1_h1_u16': 0.04979794569797597}\n",
      "sorted r2\n",
      "{'model_n1_h1_u8': 0.9985081548048771, 'model_n1_h1_u32': 0.9983299891561908, 'model_n1_h1_u16': 0.996696203217586}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_icbp_hl_u_sorted = dict(sorted(mae_icbp_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mae_icbp_hl_u_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_icbp_hl_u_sorted = dict(sorted(rmse_icbp_hl_u.items(),key=lambda item: item[1]))\n",
    "print(rmse_icbp_hl_u_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_icbp_hl_u_sorted = dict(sorted(mape_icbp_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mape_icbp_hl_u_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_icbp_hl_u_sorted = dict(sorted(r2_icbp_hl_u.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_icbp_hl_u_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n1_h1_u8': 0.007219575749619669, 'model_n1_h1_u32': 0.007642545358463815, 'model_n1_h1': 0.013130016098796896}\n",
    "# sorted rmse\n",
    "# {'model_n1_h1_u8': 0.010855205473752638, 'model_n1_h1_u32': 0.011347603920705211, 'model_n1_h1_u16': 0.016273690008413277}\n",
    "# sorted mape\n",
    "# {'model_n1_h1_u32': 0.03016892717619271, 'model_n1_h1_u8': 0.03275499929793462, 'model_n1_h1_u16': 0.04979794569797597}\n",
    "# sorted r2\n",
    "# {'model_n1_h1_u8': 0.9985081548048771, 'model_n1_h1_u32': 0.9983299891561908, 'model_n1_h1_u16': 0.996696203217586}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jsmr = df_jsmr.reset_index(drop=True)\n",
    "arr_jsmr = df_jsmr.to_numpy()\n",
    "flat_jsmr = arr_jsmr.flatten()\n",
    "jsmr_X_1, jsmr_y_1 = split_sequence(flat_jsmr, n_steps_1)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_jsmr_1, X_test_jsmr_1, y_train_jsmr_1, y_test_jsmr_1 = train_test_split(jsmr_X_1, jsmr_y_1, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_jsmr_1 = X_train_jsmr_1.reshape(X_train_jsmr_1.shape[0],X_train_jsmr_1.shape[1],n_features)\n",
    "X_test_jsmr_1 = X_test_jsmr_1.reshape(X_test_jsmr_1.shape[0],X_test_jsmr_1.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u8 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 16)                1152      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,169\n",
      "Trainable params: 1,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u16 = Sequential([\n",
    "  LSTM(16, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u16.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u32 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u32.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u32.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.2246 - mae: 0.2246 - val_loss: 0.0923 - val_mae: 0.0923\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0631 - mae: 0.0631 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0248 - val_mae: 0.0248\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0122 - val_mae: 0.0122\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u8 = simple_model_jsmr_n1_h1_u8.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 20.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 14ms/step - loss: 0.1520 - mae: 0.1520 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0312 - mae: 0.0312 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0131 - mae: 0.013 - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0130 - val_mae: 0.0130\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u16 = simple_model_jsmr_n1_h1_u16.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 7ms/step - loss: 0.1757 - mae: 0.1757 - val_loss: 0.0692 - val_mae: 0.0692\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.0382 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0145 - val_mae: 0.0145\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u32 = simple_model_jsmr_n1_h1_u32.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 19.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_jsmr_n1_h1_u8 = simple_model_jsmr_n1_h1_u8.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h1_u16 = simple_model_jsmr_n1_h1_u16.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h1_u32 = simple_model_jsmr_n1_h1_u32.predict(X_test_jsmr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron 8\n",
      "mae score jsmr_n1_h1_u8: 0.012040242615234582\n",
      "r2 score jsmr_n1_h1_u8: 0.9935633197829596\n",
      "mape score jsmr_n1_h1_u8: 0.029570296893978765\n",
      "rmse score jsmr_n1_h1_u8: 0.017130419369398783\n",
      "neuron 16\n",
      "mae score jsmr_n1_h1_u16: 0.013059401724296498\n",
      "r2 score jsmr_n1_h1_u16: 0.9927780124599436\n",
      "mape score jsmr_n1_h1_u16: 0.03211615768041788\n",
      "rmse score jsmr_n1_h1_u16: 0.018129514513005887\n",
      "neuron 32\n",
      "mae score jsmr_n1_h1_u32: 0.013832471117947474\n",
      "r2 score jsmr_n1_h1_u32: 0.9927247075638287\n",
      "mape score jsmr_n1_h1_u32: 0.03328455771441629\n",
      "rmse score jsmr_n1_h1_u32: 0.018472413116260567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"neuron 8\")\n",
    "print(\"mae score jsmr_n1_h1_u8: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u8, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u8: \"+str(r2_score(preds_jsmr_n1_h1_u8, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u8: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u8, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u8: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8, y_test_jsmr_1))))\n",
    "\n",
    "print(\"neuron 16\")\n",
    "print(\"mae score jsmr_n1_h1_u16: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u16, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u16: \"+str(r2_score(preds_jsmr_n1_h1_u16, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u16: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u16, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u16: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u16, y_test_jsmr_1))))\n",
    "\n",
    "print(\"neuron 32\")\n",
    "print(\"mae score jsmr_n1_h1_u32: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u32, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u32: \"+str(r2_score(preds_jsmr_n1_h1_u32, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u32: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u32, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u32: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u32, y_test_jsmr_1))))\n",
    "\n",
    "mae_jsmr_hl_u = {'model_n1_h1_u8':mean_absolute_error(preds_jsmr_n1_h1_u8, y_test_jsmr_1),'model_n1_h1':mean_absolute_error(preds_jsmr_n1_h1_u16, y_test_jsmr_1),'model_n1_h1_u32':mean_absolute_error(preds_jsmr_n1_h1_u32, y_test_jsmr_1)}\n",
    "\n",
    "mape_jsmr_hl_u = {'model_n1_h1_u8':mean_absolute_percentage_error(preds_jsmr_n1_h1_u8, y_test_jsmr_1),'model_n1_h1_u16':mean_absolute_percentage_error(preds_jsmr_n1_h1_u16, y_test_jsmr_1),'model_n1_h1_u32':mean_absolute_percentage_error(preds_jsmr_n1_h1_u32, y_test_jsmr_1)}\n",
    "\n",
    "rmse_jsmr_hl_u = {'model_n1_h1_u8':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8, y_test_jsmr_1)),'model_n1_h1_u16':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u16, y_test_jsmr_1)),'model_n1_h1_u32':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u32, y_test_jsmr_1))}\n",
    "\n",
    "r2_jsmr_hl_u = {'model_n1_h1_u8':r2_score(preds_jsmr_n1_h1_u8, y_test_jsmr_1),'model_n1_h1_u16':r2_score(preds_jsmr_n1_h1_u16, y_test_jsmr_1),'model_n1_h1_u32':r2_score(preds_jsmr_n1_h1_u32, y_test_jsmr_1)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n1_h1_u8': 0.012040242615234582, 'model_n1_h1': 0.013059401724296498, 'model_n1_h1_u32': 0.013832471117947474}\n",
      "sorted rmse\n",
      "{'model_n1_h1_u8': 0.017130419369398783, 'model_n1_h1_u16': 0.018129514513005887, 'model_n1_h1_u32': 0.018472413116260567}\n",
      "sorted mape\n",
      "{'model_n1_h1_u8': 0.029570296893978765, 'model_n1_h1_u16': 0.03211615768041788, 'model_n1_h1_u32': 0.03328455771441629}\n",
      "sorted r2\n",
      "{'model_n1_h1_u8': 0.9935633197829596, 'model_n1_h1_u16': 0.9927780124599436, 'model_n1_h1_u32': 0.9927247075638287}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_jsmr_hl_u_sorted = dict(sorted(mae_jsmr_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mae_jsmr_hl_u_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_jsmr_hl_u_sorted = dict(sorted(rmse_jsmr_hl_u.items(),key=lambda item: item[1]))\n",
    "print(rmse_jsmr_hl_u_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_jsmr_hl_u_sorted = dict(sorted(mape_jsmr_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mape_jsmr_hl_u_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_jsmr_hl_u_sorted = dict(sorted(r2_jsmr_hl_u.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_jsmr_hl_u_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KESIMPULAN HASIL\n",
    "Dari hasil diatas konfigurasi yang didapatkan adalah sebagai berikut\n",
    "ANTM 8 dan 32, 8 unit dipilih dari melihat MAE dan MAPE untuk 32 unit dipilih karena melihat dari nilai RMSE dan R2\n",
    "ASII 32 unit semua matriks menunjukan kinerja terbaik model pada unit dg 32 unit\n",
    "ICBP dan JSMR menunjukan perfroma terbaik pada 8 unit dimana semua matriks menunjukan nilai terbaik pada unit 8 tersebut.\n",
    "\n",
    "dari hasil diatas, selanjutnya akan digunakan sebanyak 8 unit untuk memodelkan saham ANTM, ICBP, JSMR. untuk saham ASII akan digunakan sebanyak 32 unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEARNING RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm = df_antm.reset_index(drop=True)\n",
    "arr_antm = df_antm.to_numpy()\n",
    "flat_antm = arr_antm.flatten()\n",
    "antm_X_2, antm_y_2 = split_sequence(flat_antm, n_steps_2)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_antm_2, X_test_antm_2, y_train_antm_2, y_test_antm_2 = train_test_split(antm_X_2, antm_y_2, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "X_train_antm_2 = X_train_antm_2.reshape(X_train_antm_2.shape[0],X_train_antm_2.shape[1],n_features)\n",
    "X_test_antm_2 = X_test_antm_2.reshape(X_test_antm_2.shape[0],X_test_antm_2.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u8_lr1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u8_lr2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u8_lr3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.0621 - mae: 0.0621 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0367 - val_mae: 0.0367\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0317 - val_mae: 0.0317\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0292 - val_mae: 0.0292\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0224 - mae: 0.0224 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0244 - val_mae: 0.0244\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0268 - val_mae: 0.0268\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0241 - val_mae: 0.0241\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0239 - mae: 0.0239 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0257 - val_mae: 0.0257\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0218 - mae: 0.0218 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0329 - val_mae: 0.0329\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0369 - val_mae: 0.0369\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0204 - mae: 0.020 - 0s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0239 - val_mae: 0.0239\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0262 - val_mae: 0.0262\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0312 - val_mae: 0.0312\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0279 - val_mae: 0.0279\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0159 - val_mae: 0.0159\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u8_lr1 = simple_model_antm_n2_h1_u8_lr1.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 21.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0358 - val_mae: 0.0358\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0237 - val_mae: 0.0237\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0277 - val_mae: 0.0277\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0295 - val_mae: 0.0295\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0379 - val_mae: 0.0379\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0324 - val_mae: 0.0324\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0268 - val_mae: 0.0268\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0226 - val_mae: 0.0226\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0226 - val_mae: 0.0226\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0264 - val_mae: 0.0264\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0104 - val_mae: 0.0104\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u8_lr2 = simple_model_antm_n2_h1_u8_lr1.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 21.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0113 - mae: 0.011 - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0324 - val_mae: 0.0324\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0266 - val_mae: 0.0266\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0240 - val_mae: 0.0240\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0109 - mae: 0.010 - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0140 - mae: 0.014 - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0261 - val_mae: 0.0261\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0255 - val_mae: 0.0255\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u8_lr3 = simple_model_antm_n2_h1_u8_lr1.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 21.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_antm_n2_h1_u8_lr1 = simple_model_antm_n2_h1_u8_lr1.predict(X_test_antm_2)\n",
    "preds_antm_n2_h1_u8_lr2 = simple_model_antm_n2_h1_u8_lr2.predict(X_test_antm_2)\n",
    "preds_antm_n2_h1_u8_lr3 = simple_model_antm_n2_h1_u8_lr3.predict(X_test_antm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.1\n",
      "mae score antm_n2_h1_u8_lr1: 0.025849717922488864\n",
      "r2 score antm_n2_h1_u8_lr1: 0.9717693376234477\n",
      "mape score antm_n2_h1_u8_lr1: 0.6667925415305942\n",
      "rmse score antm_n2_h1_u8_lr1: 0.03129032055995892\n",
      "learning rate 0.01\n",
      "mae score antm_n2_h1_u8_lr2: 0.3295556057475342\n",
      "r2 score antm_n2_h1_u8_lr2: -418.77423100391877\n",
      "mape score antm_n2_h1_u8_lr2: 9.923141065236273\n",
      "rmse score antm_n2_h1_u8_lr2: 0.3950678494850448\n",
      "learning rate 0.001\n",
      "mae score antm_n2_h1_u8_lr3: 0.2997065586539258\n",
      "r2 score antm_n2_h1_u8_lr3: -153420.0328864784\n",
      "mape score antm_n2_h1_u8_lr3: 164.29004630496442\n",
      "rmse score antm_n2_h1_u8_lr3: 0.3596055408647369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"learning rate 0.1\")\n",
    "print(\"mae score antm_n2_h1_u8_lr1: \"+str(mean_absolute_error(preds_antm_n2_h1_u8_lr1, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u8_lr1: \"+str(r2_score(preds_antm_n2_h1_u8_lr1, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u8_lr1: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr1, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u8_lr1: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr1, y_test_antm_2))))\n",
    "\n",
    "print(\"learning rate 0.01\")\n",
    "print(\"mae score antm_n2_h1_u8_lr2: \"+str(mean_absolute_error(preds_antm_n2_h1_u8_lr2, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u8_lr2: \"+str(r2_score(preds_antm_n2_h1_u8_lr2, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u8_lr2: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr2, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u8_lr2: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr2, y_test_antm_2))))\n",
    "\n",
    "print(\"learning rate 0.001\")\n",
    "print(\"mae score antm_n2_h1_u8_lr3: \"+str(mean_absolute_error(preds_antm_n2_h1_u8_lr3, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u8_lr3: \"+str(r2_score(preds_antm_n2_h1_u8_lr3, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u8_lr3: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr3, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u8_lr3: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr3, y_test_antm_2))))\n",
    "\n",
    "mae_antm_hl_u_lr = {'model_n2_h1_u8_lr1':mean_absolute_error(preds_antm_n2_h1_u8_lr1, y_test_antm_2),'model_n2_h1_u8_lr2':mean_absolute_error(preds_antm_n2_h1_u8_lr2, y_test_antm_2),'model_n2_h1_u8_lr3':mean_absolute_error(preds_antm_n2_h1_u8_lr3, y_test_antm_2)}\n",
    "\n",
    "mape_antm_hl_u_lr = {'model_n2_h1_u8_lr1':mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr1, y_test_antm_2),'model_n2_h1_u8_lr2':mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr2, y_test_antm_2),'model_n2_h1_u8_lr3':mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr3, y_test_antm_2)}\n",
    "\n",
    "rmse_antm_hl_u_lr = {'model_n2_h1_u8_lr1':np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr1, y_test_antm_2)),'model_n2_h1_u8_lr2':np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr2, y_test_antm_2)),'model_n2_h1_u8_lr3':np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr3, y_test_antm_2))}\n",
    "\n",
    "r2_antm_hl_u_lr = {'model_n2_h1_u8_lr1':r2_score(preds_antm_n2_h1_u8_lr1, y_test_antm_2),'model_n2_h1_u8_lr2':r2_score(preds_antm_n2_h1_u8_lr2, y_test_antm_2),'model_n2_h1_u8_lr3':r2_score(preds_antm_n2_h1_u8_lr3, y_test_antm_2)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate 0.1\n",
    "# mae score antm_n2_h1_u8_lr1: 0.025849717922488864\n",
    "# r2 score antm_n2_h1_u8_lr1: 0.9717693376234477\n",
    "# mape score antm_n2_h1_u8_lr1: 0.6667925415305942\n",
    "# rmse score antm_n2_h1_u8_lr1: 0.03129032055995892\n",
    "# learning rate 0.01\n",
    "# mae score antm_n2_h1_u8_lr2: 0.3295556057475342\n",
    "# r2 score antm_n2_h1_u8_lr2: -418.77423100391877\n",
    "# mape score antm_n2_h1_u8_lr2: 9.923141065236273\n",
    "# rmse score antm_n2_h1_u8_lr2: 0.3950678494850448\n",
    "# learning rate 0.001\n",
    "# mae score antm_n2_h1_u8_lr3: 0.2997065586539258\n",
    "# r2 score antm_n2_h1_u8_lr3: -153420.0328864784\n",
    "# mape score antm_n2_h1_u8_lr3: 164.29004630496442\n",
    "# rmse score antm_n2_h1_u8_lr3: 0.3596055408647369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n2_h1_u8_lr1': 0.025849717922488864, 'model_n2_h1_u8_lr3': 0.2997065586539258, 'model_n2_h1': 0.3295556057475342}\n",
      "sorted rmse\n",
      "{'model_n2_h1_u8_lr1': 0.03129032055995892, 'model_n2_h1_u8_lr3': 0.3596055408647369, 'model_n2_h1_u8_lr2': 0.3950678494850448}\n",
      "sorted mape\n",
      "{'model_n2_h1_u8_lr1': 0.6667925415305942, 'model_n2_h1_u8_lr2': 9.923141065236273, 'model_n2_h1_u8_lr3': 164.29004630496442}\n",
      "sorted r2\n",
      "{'model_n2_h1_u8_lr1': 0.9717693376234477, 'model_n2_h1_u8_lr2': -418.77423100391877, 'model_n2_h1_u8_lr3': -153420.0328864784}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_antm_hl_u_lr_sorted = dict(sorted(mae_antm_hl_u_lr.items(),key=lambda item: item[1]))\n",
    "print(mae_antm_hl_u_lr_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_antm_hl_u_lr_sorted = dict(sorted(rmse_antm_hl_u_lr.items(),key=lambda item: item[1]))\n",
    "print(rmse_antm_hl_u_lr_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_antm_hl_u_lr_sorted = dict(sorted(mape_antm_hl_u_lr.items(),key=lambda item: item[1]))\n",
    "print(mape_antm_hl_u_lr_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_antm_hl_u_lr_sorted = dict(sorted(r2_antm_hl_u_lr.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_antm_hl_u_lr_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n2_h1_u8_lr1': 0.025849717922488864, 'model_n2_h1_u8_lr3': 0.2997065586539258, 'model_n2_h1': 0.3295556057475342}\n",
    "# sorted rmse\n",
    "# {'model_n2_h1_u8_lr1': 0.03129032055995892, 'model_n2_h1_u8_lr3': 0.3596055408647369, 'model_n2_h1_u8_lr2': 0.3950678494850448}\n",
    "# sorted mape\n",
    "# {'model_n2_h1_u8_lr1': 0.6667925415305942, 'model_n2_h1_u8_lr2': 9.923141065236273, 'model_n2_h1_u8_lr3': 164.29004630496442}\n",
    "# sorted r2\n",
    "# {'model_n2_h1_u8_lr1': 0.9717693376234477, 'model_n2_h1_u8_lr2': -418.77423100391877, 'model_n2_h1_u8_lr3': -153420.0328864784}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asii = df_asii.reset_index(drop=True)\n",
    "arr_asii = df_asii.to_numpy()\n",
    "flat_asii = arr_asii.flatten()\n",
    "asii_X_3, asii_y_3 = split_sequence(flat_asii, n_steps_3)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_asii_3, X_test_asii_3, y_train_asii_3, y_test_asii_3 = train_test_split(asii_X_3, asii_y_3, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_asii_3 = X_train_asii_3.reshape(X_train_asii_3.shape[0],X_train_asii_3.shape[1],n_features)\n",
    "X_test_asii_3 = X_test_asii_3.reshape(X_test_asii_3.shape[0],X_test_asii_3.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_48 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u32_lr1 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_49 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u32_lr2 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_50 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u32_lr3 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 9ms/step - loss: 0.0980 - mae: 0.0980 - val_loss: 0.0364 - val_mae: 0.0364\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0359 - mae: 0.0359 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0307 - mae: 0.0307 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0254 - mae: 0.0254 - val_loss: 0.0772 - val_mae: 0.0772\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.0246 - val_mae: 0.0246\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0251 - mae: 0.0251 - val_loss: 0.0246 - val_mae: 0.0246\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.0297 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0259 - mae: 0.0259 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0261 - val_mae: 0.0261\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0342 - val_mae: 0.0342\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0303 - val_mae: 0.0303\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.0304 - val_mae: 0.0304\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0246 - val_mae: 0.0246\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0226 - mae: 0.0226 - val_loss: 0.0308 - val_mae: 0.0308\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0236 - mae: 0.0236 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0256 - mae: 0.0256 - val_loss: 0.0251 - val_mae: 0.0251\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0234 - mae: 0.0234 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0249 - val_mae: 0.0249\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0305 - val_mae: 0.0305\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.0400 - val_mae: 0.0400\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0383 - val_mae: 0.0383\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0271 - val_mae: 0.0271\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0379 - val_mae: 0.0379\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0381 - val_mae: 0.0381\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0491 - val_mae: 0.0491\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0254 - mae: 0.0254 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0391 - val_mae: 0.0391\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0332 - mae: 0.0332 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0415 - val_mae: 0.0415\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0235 - mae: 0.0235 - val_loss: 0.0312 - val_mae: 0.0312\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0383 - val_mae: 0.0383\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0264 - mae: 0.0264 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0245 - mae: 0.0245 - val_loss: 0.0332 - val_mae: 0.0332\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0351 - val_mae: 0.0351\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0291 - val_mae: 0.0291\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0255 - val_mae: 0.0255\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0362 - val_mae: 0.0362\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0229 - val_mae: 0.0229\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0275 - val_mae: 0.0275\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0237 - val_mae: 0.0237\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0230 - val_mae: 0.0230\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0518 - val_mae: 0.0518\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0233 - mae: 0.0233 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0210 - mae: 0.021 - 0s 4ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0218 - mae: 0.0218 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0224 - val_mae: 0.0224\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0270 - val_mae: 0.0270\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0233 - mae: 0.0233 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0146 - val_mae: 0.0146\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u32_lr1 = simple_model_asii_n3_h1_u32_lr1.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 22.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0371 - val_mae: 0.0371\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0254 - val_mae: 0.0254\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0320 - val_mae: 0.0320\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0245 - val_mae: 0.0245\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0309 - val_mae: 0.0309\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0257 - val_mae: 0.0257\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0212 - val_mae: 0.0212\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0226 - val_mae: 0.0226\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0297 - val_mae: 0.0297\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0249 - val_mae: 0.0249\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0307 - val_mae: 0.0307\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0233 - val_mae: 0.0233\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0147 - val_mae: 0.0147\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u32_lr2 = simple_model_asii_n3_h1_u32_lr2.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 9ms/step - loss: 0.5075 - mae: 0.5075 - val_loss: 0.3695 - val_mae: 0.3695\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1686 - mae: 0.1686 - val_loss: 0.0479 - val_mae: 0.0479\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0352 - mae: 0.0352 - val_loss: 0.0249 - val_mae: 0.0249\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0244 - mae: 0.0244 - val_loss: 0.0226 - val_mae: 0.0226\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0169 - val_mae: 0.0169\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u32_lr3 = simple_model_asii_n3_h1_u32_lr3.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_asii_n3_h1_u32_lr1 = simple_model_asii_n3_h1_u32_lr1.predict(X_test_asii_3)\n",
    "preds_asii_n3_h1_u32_lr2 = simple_model_asii_n3_h1_u32_lr2.predict(X_test_asii_3)\n",
    "preds_asii_n3_h1_u32_lr3 = simple_model_asii_n3_h1_u32_lr3.predict(X_test_asii_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.1\n",
      "mae score asii_n3_h1_u32_lr1: 0.014984484662728566\n",
      "r2 score asii_n3_h1_u32_lr1: 0.9898421710809194\n",
      "mape score asii_n3_h1_u32_lr1: 0.03391435204325115\n",
      "rmse score asii_n3_h1_u32_lr1: 0.020020778403811657\n",
      "learning rate 0.01\n",
      "mae score asii_n3_h1_u32_lr2: 0.014862743641934127\n",
      "r2 score asii_n3_h1_u32_lr2: 0.9899428156740873\n",
      "mape score asii_n3_h1_u32_lr2: 0.03366923393004505\n",
      "rmse score asii_n3_h1_u32_lr2: 0.020030782988198177\n",
      "learning rate 0.001\n",
      "mae score asii_n3_h1_u32_lr3: 0.01738613382173947\n",
      "r2 score asii_n3_h1_u32_lr3: 0.9873040707733628\n",
      "mape score asii_n3_h1_u32_lr3: 0.038148205286427365\n",
      "rmse score asii_n3_h1_u32_lr3: 0.022448203110551682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"learning rate 0.1\")\n",
    "print(\"mae score asii_n3_h1_u32_lr1: \"+str(mean_absolute_error(preds_asii_n3_h1_u32_lr1, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u32_lr1: \"+str(r2_score(preds_asii_n3_h1_u32_lr1, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u32_lr1: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr1, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u32_lr1: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr1, y_test_asii_3))))\n",
    "\n",
    "print(\"learning rate 0.01\")\n",
    "print(\"mae score asii_n3_h1_u32_lr2: \"+str(mean_absolute_error(preds_asii_n3_h1_u32_lr2, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u32_lr2: \"+str(r2_score(preds_asii_n3_h1_u32_lr2, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u32_lr2: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr2, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u32_lr2: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr2, y_test_asii_3))))\n",
    "\n",
    "print(\"learning rate 0.001\")\n",
    "print(\"mae score asii_n3_h1_u32_lr3: \"+str(mean_absolute_error(preds_asii_n3_h1_u32_lr3, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u32_lr3: \"+str(r2_score(preds_asii_n3_h1_u32_lr3, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u32_lr3: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr3, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u32_lr3: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr3, y_test_asii_3))))\n",
    "\n",
    "mae_asii_hl_u_lr = {'model_n3_h1_u32_lr1':mean_absolute_error(preds_asii_n3_h1_u32_lr1, y_test_asii_3),'model_n3_h1_u32_lr2':mean_absolute_error(preds_asii_n3_h1_u32_lr2, y_test_asii_3),'model_n3_h1_u32_lr3':mean_absolute_error(preds_asii_n3_h1_u32_lr3, y_test_asii_3)}\n",
    "\n",
    "mape_asii_hl_u_lr = {'model_n3_h1_u32_lr1':mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr1, y_test_asii_3),'model_n3_h1_u32_lr2':mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr2, y_test_asii_3),'model_n3_h1_u32_lr3':mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr3, y_test_asii_3)}\n",
    "\n",
    "rmse_asii_hl_u_lr = {'model_n3_h1_u32_lr1':np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr1, y_test_asii_3)),'model_n3_h1_u32_lr2':np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr2, y_test_asii_3)),'model_n3_h1_u32_lr3':np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr3, y_test_asii_3))}\n",
    "\n",
    "r2_asii_hl_u_lr = {'model_n3_h1_u32_lr1':r2_score(preds_asii_n3_h1_u32_lr1, y_test_asii_3),'model_n3_h1_u32_lr2':r2_score(preds_asii_n3_h1_u32_lr2, y_test_asii_3),'model_n3_h1_u32_lr3':r2_score(preds_asii_n3_h1_u32_lr3, y_test_asii_3)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate 0.1\n",
    "# mae score asii_n3_h1_u32_lr1: 0.014984484662728566\n",
    "# r2 score asii_n3_h1_u32_lr1: 0.9898421710809194\n",
    "# mape score asii_n3_h1_u32_lr1: 0.03391435204325115\n",
    "# rmse score asii_n3_h1_u32_lr1: 0.020020778403811657\n",
    "# learning rate 0.01\n",
    "# mae score asii_n3_h1_u32_lr2: 0.014862743641934127\n",
    "# r2 score asii_n3_h1_u32_lr2: 0.9899428156740873\n",
    "# mape score asii_n3_h1_u32_lr2: 0.03366923393004505\n",
    "# rmse score asii_n3_h1_u32_lr2: 0.020030782988198177\n",
    "# learning rate 0.001\n",
    "# mae score asii_n3_h1_u32_lr3: 0.01738613382173947\n",
    "# r2 score asii_n3_h1_u32_lr3: 0.9873040707733628\n",
    "# mape score asii_n3_h1_u32_lr3: 0.038148205286427365\n",
    "# rmse score asii_n3_h1_u32_lr3: 0.022448203110551682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n3_h1_u32_lr2': 0.014862743641934127, 'model_n3_h1_u32_lr1': 0.014984484662728566, 'model_n3_h1_u32_lr3': 0.01738613382173947}\n",
      "sorted rmse\n",
      "{'model_n3_h1_u32_lr1': 0.020020778403811657, 'model_n3_h1_u32_lr2': 0.020030782988198177, 'model_n3_h1_u32_lr3': 0.022448203110551682}\n",
      "sorted mape\n",
      "{'model_n3_h1_u32_lr2': 0.03366923393004505, 'model_n3_h1_u32_lr1': 0.03391435204325115, 'model_n3_h1_u32_lr3': 0.038148205286427365}\n",
      "sorted r2\n",
      "{'model_n3_h1_u32_lr2': 0.9899428156740873, 'model_n3_h1_u32_lr1': 0.9898421710809194, 'model_n3_h1_u32_lr3': 0.9873040707733628}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_asii_hl_u_lr_sorted = dict(sorted(mae_asii_hl_u_lr.items(),key=lambda item: item[1]))\n",
    "print(mae_asii_hl_u_lr_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_asii_hl_u_lr_sorted = dict(sorted(rmse_asii_hl_u_lr.items(),key=lambda item: item[1]))\n",
    "print(rmse_asii_hl_u_lr_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_asii_hl_u_lr_sorted = dict(sorted(mape_asii_hl_u_lr.items(),key=lambda item: item[1]))\n",
    "print(mape_asii_hl_u_lr_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_asii_hl_u_lr_sorted = dict(sorted(r2_asii_hl_u_lr.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_asii_hl_u_lr_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n3_h1_u32_lr2': 0.014862743641934127, 'model_n3_h1_u32_lr1': 0.014984484662728566, 'model_n3_h1_u32_lr3': 0.01738613382173947}\n",
    "# sorted rmse\n",
    "# {'model_n3_h1_u32_lr1': 0.020020778403811657, 'model_n3_h1_u32_lr2': 0.020030782988198177, 'model_n3_h1_u32_lr3': 0.022448203110551682}\n",
    "# sorted mape\n",
    "# {'model_n3_h1_u32_lr2': 0.03366923393004505, 'model_n3_h1_u32_lr1': 0.03391435204325115, 'model_n3_h1_u32_lr3': 0.038148205286427365}\n",
    "# sorted r2\n",
    "# {'model_n3_h1_u32_lr2': 0.9899428156740873, 'model_n3_h1_u32_lr1': 0.9898421710809194, 'model_n3_h1_u32_lr3': 0.9873040707733628}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icbp = df_icbp.reset_index(drop=True)\n",
    "arr_icbp = df_icbp.to_numpy()\n",
    "flat_icbp = arr_icbp.flatten()\n",
    "icbp_X_1, icbp_y_1 = split_sequence(flat_icbp, n_steps_1)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_icbp_1, X_test_icbp_1, y_train_icbp_1, y_test_icbp_1 = train_test_split(icbp_X_1, icbp_y_1, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_icbp_1 = X_train_icbp_1.reshape(X_train_icbp_1.shape[0],X_train_icbp_1.shape[1],n_features)\n",
    "X_test_icbp_1 = X_test_icbp_1.reshape(X_test_icbp_1.shape[0],X_test_icbp_1.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u8_lr1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_34 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u8_lr2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_35 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u8_lr3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 9ms/step - loss: 0.0711 - mae: 0.0711 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.0251 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0242 - mae: 0.0242 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0355 - mae: 0.0355 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0249 - mae: 0.0249 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0261 - mae: 0.0261 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0425 - mae: 0.0425 - val_loss: 0.0310 - val_mae: 0.0310\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0353 - mae: 0.0353 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0281 - val_mae: 0.0281\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0212 - val_mae: 0.0212\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0376 - val_mae: 0.0376\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0379 - val_mae: 0.0379\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0474 - val_mae: 0.0474\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0295 - val_mae: 0.0295\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0257 - val_mae: 0.0257\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0385 - val_mae: 0.0385\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0369 - mae: 0.0369 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0375 - val_mae: 0.0375\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0288 - mae: 0.0288 - val_loss: 0.0272 - val_mae: 0.0272\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0233 - mae: 0.0233 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0344 - val_mae: 0.0344\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0320 - val_mae: 0.0320\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0460 - val_mae: 0.0460\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0212 - val_mae: 0.0212\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0251 - mae: 0.0251 - val_loss: 0.0379 - val_mae: 0.0379\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0280 - val_mae: 0.0280\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0277 - val_mae: 0.0277\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0275 - val_mae: 0.0275\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0357 - val_mae: 0.0357\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0386 - val_mae: 0.0386\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.0379 - val_mae: 0.0379\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0257 - val_mae: 0.0257\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0295 - val_mae: 0.0295\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0446 - mae: 0.0446 - val_loss: 0.0300 - val_mae: 0.0300\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0232 - mae: 0.0232 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0252 - mae: 0.0252 - val_loss: 0.0330 - val_mae: 0.0330\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0358 - val_mae: 0.0358\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0253 - mae: 0.0253 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0252 - mae: 0.0252 - val_loss: 0.0365 - val_mae: 0.0365\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0264 - val_mae: 0.0264\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0537 - val_mae: 0.0537\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0464 - val_mae: 0.0464\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0250 - val_mae: 0.0250\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0205 - val_mae: 0.0205\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u8_lr1 = simple_model_icbp_n1_h1_u8_lr1.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 22.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 7ms/step - loss: 0.2264 - mae: 0.2264 - val_loss: 0.1099 - val_mae: 0.1099\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0241 - val_mae: 0.0241\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0271 - val_mae: 0.0271\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0080\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u8_lr2 = simple_model_icbp_n1_h1_u8_lr2.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 19,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.4438 - mae: 0.4438 - val_loss: 0.4244 - val_mae: 0.4244\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3964 - mae: 0.3964 - val_loss: 0.3863 - val_mae: 0.3863\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3685 - mae: 0.3685 - val_loss: 0.3595 - val_mae: 0.3595\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3452 - mae: 0.3452 - val_loss: 0.3352 - val_mae: 0.3352\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3235 - mae: 0.3235 - val_loss: 0.3126 - val_mae: 0.3126\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3042 - mae: 0.3042 - val_loss: 0.2923 - val_mae: 0.2923\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2856 - mae: 0.2856 - val_loss: 0.2735 - val_mae: 0.2735\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2719 - mae: 0.2719 - val_loss: 0.2614 - val_mae: 0.2614\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2636 - mae: 0.2636 - val_loss: 0.2544 - val_mae: 0.2544\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2580 - mae: 0.2580 - val_loss: 0.2485 - val_mae: 0.2485\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2534 - mae: 0.2534 - val_loss: 0.2439 - val_mae: 0.2439\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2496 - mae: 0.2496 - val_loss: 0.2402 - val_mae: 0.2402\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2469 - mae: 0.2469 - val_loss: 0.2375 - val_mae: 0.2375\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2451 - mae: 0.2451 - val_loss: 0.2350 - val_mae: 0.2350\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2435 - mae: 0.2435 - val_loss: 0.2328 - val_mae: 0.2328\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2425 - mae: 0.2425 - val_loss: 0.2314 - val_mae: 0.2314\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2418 - mae: 0.2418 - val_loss: 0.2303 - val_mae: 0.2303\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2413 - mae: 0.2413 - val_loss: 0.2295 - val_mae: 0.2295\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2408 - mae: 0.2408 - val_loss: 0.2288 - val_mae: 0.2288\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2404 - mae: 0.2404 - val_loss: 0.2281 - val_mae: 0.2281\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2401 - mae: 0.2401 - val_loss: 0.2276 - val_mae: 0.2276\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2399 - mae: 0.2399 - val_loss: 0.2271 - val_mae: 0.2271\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2266 - val_mae: 0.2266\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2262 - val_mae: 0.2262\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2263 - val_mae: 0.2263\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2261 - val_mae: 0.2261\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2259 - val_mae: 0.2259\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2257 - val_mae: 0.2257\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2258 - val_mae: 0.2258\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2396 - mae: 0.2396 - val_loss: 0.2256 - val_mae: 0.2256\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2255 - val_mae: 0.2255\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.2394 - val_loss: 0.2254 - val_mae: 0.2254\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2395 - mae: 0.2395 - val_loss: 0.2254 - val_mae: 0.2254\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u8_lr3 = simple_model_icbp_n1_h1_u8_lr3.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 19,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_icbp_n1_h1_u8_lr1 = simple_model_icbp_n1_h1_u8_lr1.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h1_u8_lr2 = simple_model_icbp_n1_h1_u8_lr2.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h1_u8_lr3 = simple_model_icbp_n1_h1_u8_lr3.predict(X_test_icbp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.1\n",
      "mae score icbp_n1_h1_u8_lr1: 0.019869628638565638\n",
      "r2 score icbp_n1_h1_u8_lr1: 0.9930787205901155\n",
      "mape score icbp_n1_h1_u8_lr1: 0.09147425780397894\n",
      "rmse score icbp_n1_h1_u8_lr1: 0.022785472568212693\n",
      "learning rate 0.01\n",
      "mae score icbp_n1_h1_u8_lr2: 0.007375501048888308\n",
      "r2 score icbp_n1_h1_u8_lr2: 0.9984805983751265\n",
      "mape score icbp_n1_h1_u8_lr2: 0.03500379616597862\n",
      "rmse score icbp_n1_h1_u8_lr2: 0.01093223587971163\n",
      "learning rate 0.001\n",
      "mae score icbp_n1_h1_u8_lr3: 0.2481420855985792\n",
      "r2 score icbp_n1_h1_u8_lr3: -10130060349.416784\n",
      "mape score icbp_n1_h1_u8_lr3: 0.46248184707493295\n",
      "rmse score icbp_n1_h1_u8_lr3: 0.29176919267515794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"learning rate 0.1\")\n",
    "print(\"mae score icbp_n1_h1_u8_lr1: \"+str(mean_absolute_error(preds_icbp_n1_h1_u8_lr1, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u8_lr1: \"+str(r2_score(preds_icbp_n1_h1_u8_lr1, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u8_lr1: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr1, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u8_lr1: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr1, y_test_icbp_1))))\n",
    "\n",
    "print(\"learning rate 0.01\")\n",
    "print(\"mae score icbp_n1_h1_u8_lr2: \"+str(mean_absolute_error(preds_icbp_n1_h1_u8_lr2, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u8_lr2: \"+str(r2_score(preds_icbp_n1_h1_u8_lr2, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u8_lr2: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr2, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u8_lr2: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr2, y_test_icbp_1))))\n",
    "\n",
    "print(\"learning rate 0.001\")\n",
    "print(\"mae score icbp_n1_h1_u8_lr3: \"+str(mean_absolute_error(preds_icbp_n1_h1_u8_lr3, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u8_lr3: \"+str(r2_score(preds_icbp_n1_h1_u8_lr3, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u8_lr3: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr3, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u8_lr3: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr3, y_test_icbp_1))))\n",
    "\n",
    "mae_icbp_hl_u = {'model_n1_h1_u8_lr1':mean_absolute_error(preds_icbp_n1_h1_u8_lr1, y_test_icbp_1),'model_n1_h1_u8_lr2':mean_absolute_error(preds_icbp_n1_h1_u8_lr2, y_test_icbp_1),'model_n1_h1_u8_lr3':mean_absolute_error(preds_icbp_n1_h1_u8_lr3, y_test_icbp_1)}\n",
    "\n",
    "mape_icbp_hl_u = {'model_n1_h1_u8_lr1':mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr1, y_test_icbp_1),'model_n1_h1_u8_lr2':mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr2, y_test_icbp_1),'model_n1_h1_u8_lr3':mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr3, y_test_icbp_1)}\n",
    "\n",
    "rmse_icbp_hl_u = {'model_n1_h1_u8_lr1':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr1, y_test_icbp_1)),'model_n1_h1_u8_lr2':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr2, y_test_icbp_1)),'model_n1_h1_u8_lr3':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr3, y_test_icbp_1))}\n",
    "\n",
    "r2_icbp_hl_u = {'model_n1_h1_u8_lr1':r2_score(preds_icbp_n1_h1_u8_lr1, y_test_icbp_1),'model_n1_h1_u8_lr2':r2_score(preds_icbp_n1_h1_u8_lr2, y_test_icbp_1),'model_n1_h1_u8_lr3':r2_score(preds_icbp_n1_h1_u8_lr3, y_test_icbp_1)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate 0.1\n",
    "# mae score icbp_n1_h1_u8_lr1: 0.019869628638565638\n",
    "# r2 score icbp_n1_h1_u8_lr1: 0.9930787205901155\n",
    "# mape score icbp_n1_h1_u8_lr1: 0.09147425780397894\n",
    "# rmse score icbp_n1_h1_u8_lr1: 0.022785472568212693\n",
    "# learning rate 0.01\n",
    "# mae score icbp_n1_h1_u8_lr2: 0.007375501048888308\n",
    "# r2 score icbp_n1_h1_u8_lr2: 0.9984805983751265\n",
    "# mape score icbp_n1_h1_u8_lr2: 0.03500379616597862\n",
    "# rmse score icbp_n1_h1_u8_lr2: 0.01093223587971163\n",
    "# learning rate 0.001\n",
    "# mae score icbp_n1_h1_u8_lr3: 0.2481420855985792\n",
    "# r2 score icbp_n1_h1_u8_lr3: -10130060349.416784\n",
    "# mape score icbp_n1_h1_u8_lr3: 0.46248184707493295\n",
    "# rmse score icbp_n1_h1_u8_lr3: 0.29176919267515794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n1_h1_u8_lr2': 0.007375501048888308, 'model_n1_h1_u8_lr1': 0.019869628638565638, 'model_n1_h1_u8_lr3': 0.2481420855985792}\n",
      "sorted rmse\n",
      "{'model_n1_h1_u8_lr2': 0.01093223587971163, 'model_n1_h1_u8_lr1': 0.022785472568212693, 'model_n1_h1_u8_lr3': 0.29176919267515794}\n",
      "sorted mape\n",
      "{'model_n1_h1_u8_lr2': 0.03500379616597862, 'model_n1_h1_u8_lr1': 0.09147425780397894, 'model_n1_h1_u8_lr3': 0.46248184707493295}\n",
      "sorted r2\n",
      "{'model_n1_h1_u8_lr2': 0.9984805983751265, 'model_n1_h1_u8_lr1': 0.9930787205901155, 'model_n1_h1_u8_lr3': -10130060349.416784}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_icbp_hl_u_sorted = dict(sorted(mae_icbp_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mae_icbp_hl_u_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_icbp_hl_u_sorted = dict(sorted(rmse_icbp_hl_u.items(),key=lambda item: item[1]))\n",
    "print(rmse_icbp_hl_u_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_icbp_hl_u_sorted = dict(sorted(mape_icbp_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mape_icbp_hl_u_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_icbp_hl_u_sorted = dict(sorted(r2_icbp_hl_u.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_icbp_hl_u_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n1_h1_u8_lr2': 0.007375501048888308, 'model_n1_h1_u8_lr1': 0.019869628638565638, 'model_n1_h1_u8_lr3': 0.2481420855985792}\n",
    "# sorted rmse\n",
    "# {'model_n1_h1_u8_lr2': 0.01093223587971163, 'model_n1_h1_u8_lr1': 0.022785472568212693, 'model_n1_h1_u8_lr3': 0.29176919267515794}\n",
    "# sorted mape\n",
    "# {'model_n1_h1_u8_lr2': 0.03500379616597862, 'model_n1_h1_u8_lr1': 0.09147425780397894, 'model_n1_h1_u8_lr3': 0.46248184707493295}\n",
    "# sorted r2\n",
    "# {'model_n1_h1_u8_lr2': 0.9984805983751265, 'model_n1_h1_u8_lr1': 0.9930787205901155, 'model_n1_h1_u8_lr3': -10130060349.416784}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jsmr = df_jsmr.reset_index(drop=True)\n",
    "arr_jsmr = df_jsmr.to_numpy()\n",
    "flat_jsmr = arr_jsmr.flatten()\n",
    "jsmr_X_1, jsmr_y_1 = split_sequence(flat_jsmr, n_steps_1)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_jsmr_1, X_test_jsmr_1, y_train_jsmr_1, y_test_jsmr_1 = train_test_split(jsmr_X_1, jsmr_y_1, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_jsmr_1 = X_train_jsmr_1.reshape(X_train_jsmr_1.shape[0],X_train_jsmr_1.shape[1],n_features)\n",
    "X_test_jsmr_1 = X_test_jsmr_1.reshape(X_test_jsmr_1.shape[0],X_test_jsmr_1.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_36 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u8_lr1 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_37 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u8_lr2 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u8_lr3 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.2071 - mae: 0.2071 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1675 - mae: 0.1675 - val_loss: 0.1665 - val_mae: 0.1665\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1683 - mae: 0.1683 - val_loss: 0.1656 - val_mae: 0.1656\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1688 - mae: 0.1688 - val_loss: 0.1621 - val_mae: 0.1621\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1682 - mae: 0.1682 - val_loss: 0.1618 - val_mae: 0.1618\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.1610 - val_mae: 0.1610\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1688 - mae: 0.1688 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1741 - mae: 0.1741 - val_loss: 0.1679 - val_mae: 0.1679\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1707 - mae: 0.1707 - val_loss: 0.1606 - val_mae: 0.1606\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1677 - mae: 0.1677 - val_loss: 0.1665 - val_mae: 0.1665\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1678 - mae: 0.1678 - val_loss: 0.1695 - val_mae: 0.1695\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1721 - mae: 0.1721 - val_loss: 0.1780 - val_mae: 0.1780\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1715 - mae: 0.1715 - val_loss: 0.1608 - val_mae: 0.1608\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1693 - mae: 0.1693 - val_loss: 0.1607 - val_mae: 0.1607\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1687 - mae: 0.1687 - val_loss: 0.1632 - val_mae: 0.1632\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1680 - mae: 0.1680 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1678 - mae: 0.1678 - val_loss: 0.1623 - val_mae: 0.1623\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1692 - mae: 0.1692 - val_loss: 0.1660 - val_mae: 0.1660\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1695 - mae: 0.1695 - val_loss: 0.1690 - val_mae: 0.1690\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1681 - mae: 0.1681 - val_loss: 0.1729 - val_mae: 0.1729\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1674 - mae: 0.1674 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.1606 - val_mae: 0.1606\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1686 - mae: 0.1686 - val_loss: 0.1640 - val_mae: 0.1640\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1697 - mae: 0.1697 - val_loss: 0.1668 - val_mae: 0.1668\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1717 - mae: 0.1717 - val_loss: 0.1649 - val_mae: 0.1649\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1699 - mae: 0.1699 - val_loss: 0.1622 - val_mae: 0.1622\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1677 - mae: 0.1677 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1711 - mae: 0.1711 - val_loss: 0.1665 - val_mae: 0.1665\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1688 - mae: 0.1688 - val_loss: 0.1608 - val_mae: 0.1608\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1677 - mae: 0.1677 - val_loss: 0.1655 - val_mae: 0.1655\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1685 - mae: 0.1685 - val_loss: 0.1669 - val_mae: 0.1669\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1694 - mae: 0.1694 - val_loss: 0.1638 - val_mae: 0.1638\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1696 - mae: 0.1696 - val_loss: 0.1627 - val_mae: 0.1627\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1678 - mae: 0.1678 - val_loss: 0.1606 - val_mae: 0.1606\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1687 - mae: 0.1687 - val_loss: 0.1608 - val_mae: 0.1608\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1689 - mae: 0.1689 - val_loss: 0.1619 - val_mae: 0.1619\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1728 - mae: 0.1728 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1724 - mae: 0.1724 - val_loss: 0.1607 - val_mae: 0.1607\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1674 - mae: 0.1674 - val_loss: 0.1729 - val_mae: 0.1729\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1730 - mae: 0.1730 - val_loss: 0.1634 - val_mae: 0.1634\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1714 - mae: 0.1714 - val_loss: 0.1699 - val_mae: 0.1699\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1668 - mae: 0.1668 - val_loss: 0.1830 - val_mae: 0.1830\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1749 - mae: 0.1749 - val_loss: 0.1665 - val_mae: 0.1665\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1685 - mae: 0.1685 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.1623 - val_mae: 0.1623\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1689 - mae: 0.1689 - val_loss: 0.1643 - val_mae: 0.1643\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1727 - mae: 0.1727 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1683 - mae: 0.1683 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1690 - mae: 0.1690 - val_loss: 0.1626 - val_mae: 0.1626\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1700 - mae: 0.1700 - val_loss: 0.1848 - val_mae: 0.1848\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1752 - mae: 0.175 - 0s 4ms/step - loss: 0.1782 - mae: 0.1782 - val_loss: 0.1703 - val_mae: 0.1703\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1744 - mae: 0.1744 - val_loss: 0.1649 - val_mae: 0.1649\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1697 - mae: 0.1697 - val_loss: 0.1641 - val_mae: 0.1641\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1683 - mae: 0.1683 - val_loss: 0.1636 - val_mae: 0.1636\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1670 - mae: 0.1670 - val_loss: 0.1714 - val_mae: 0.1714\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1690 - mae: 0.1690 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1687 - mae: 0.1687 - val_loss: 0.1627 - val_mae: 0.1627\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1673 - mae: 0.1673 - val_loss: 0.1661 - val_mae: 0.1661\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1683 - mae: 0.1683 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1682 - mae: 0.1682 - val_loss: 0.1612 - val_mae: 0.1612\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1700 - mae: 0.1700 - val_loss: 0.1606 - val_mae: 0.1606\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1734 - mae: 0.1734 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1680 - mae: 0.1680 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1680 - mae: 0.1680 - val_loss: 0.1610 - val_mae: 0.1610\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1702 - mae: 0.1702 - val_loss: 0.1669 - val_mae: 0.1669\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1672 - mae: 0.1672 - val_loss: 0.1622 - val_mae: 0.1622\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1677 - mae: 0.1677 - val_loss: 0.1684 - val_mae: 0.1684\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1735 - mae: 0.1735 - val_loss: 0.1735 - val_mae: 0.1735\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1681 - mae: 0.1681 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1686 - mae: 0.1686 - val_loss: 0.1610 - val_mae: 0.1610\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1696 - mae: 0.1696 - val_loss: 0.1835 - val_mae: 0.1835\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - mae: 0.1755 - val_loss: 0.1759 - val_mae: 0.1759\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.1619 - val_mae: 0.1619\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.1690 - val_mae: 0.1690\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1690 - mae: 0.1690 - val_loss: 0.1622 - val_mae: 0.1622\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1680 - mae: 0.1680 - val_loss: 0.1637 - val_mae: 0.1637\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1697 - mae: 0.1697 - val_loss: 0.1721 - val_mae: 0.1721\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.1611 - val_mae: 0.1611\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1673 - mae: 0.1673 - val_loss: 0.1623 - val_mae: 0.1623\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1689 - mae: 0.1689 - val_loss: 0.1606 - val_mae: 0.1606\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1691 - mae: 0.1691 - val_loss: 0.1695 - val_mae: 0.1695\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1693 - mae: 0.1693 - val_loss: 0.1675 - val_mae: 0.1675\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1686 - mae: 0.1686 - val_loss: 0.1618 - val_mae: 0.1618\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1720 - mae: 0.1720 - val_loss: 0.1758 - val_mae: 0.1758\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1714 - mae: 0.1714 - val_loss: 0.1618 - val_mae: 0.1618\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1682 - mae: 0.1682 - val_loss: 0.1622 - val_mae: 0.1622\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1689 - mae: 0.1689 - val_loss: 0.1768 - val_mae: 0.1768\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1714 - mae: 0.1714 - val_loss: 0.1608 - val_mae: 0.1608\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1712 - mae: 0.1712 - val_loss: 0.1637 - val_mae: 0.1637\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1709 - mae: 0.1709 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1703 - mae: 0.1703 - val_loss: 0.1692 - val_mae: 0.1692\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1685 - mae: 0.1685 - val_loss: 0.1840 - val_mae: 0.1840\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1755 - mae: 0.1755 - val_loss: 0.1606 - val_mae: 0.1606\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1676 - mae: 0.1676 - val_loss: 0.1654 - val_mae: 0.1654\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1713 - mae: 0.1713 - val_loss: 0.1628 - val_mae: 0.1628\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1679 - mae: 0.1679 - val_loss: 0.1659 - val_mae: 0.1659\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1693 - mae: 0.1693 - val_loss: 0.1606 - val_mae: 0.1606\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1693 - mae: 0.1693 - val_loss: 0.1695 - val_mae: 0.1695\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1675 - mae: 0.1675 - val_loss: 0.1630 - val_mae: 0.1630\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1714 - mae: 0.1714 - val_loss: 0.1648 - val_mae: 0.1648\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u8_lr1 = simple_model_jsmr_n1_h1_u8_lr1.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 21.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 3s 8ms/step - loss: 0.2136 - mae: 0.2136 - val_loss: 0.0829 - val_mae: 0.0829\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0570 - mae: 0.0570 - val_loss: 0.0244 - val_mae: 0.0244\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0224 - mae: 0.022 - 0s 3ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0130 - mae: 0.013 - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0120 - val_mae: 0.0120\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u8_lr2 = simple_model_jsmr_n1_h1_u8_lr2.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.5841 - mae: 0.5841 - val_loss: 0.5441 - val_mae: 0.5441\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5142 - mae: 0.5142 - val_loss: 0.4851 - val_mae: 0.4851\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4623 - mae: 0.4623 - val_loss: 0.4357 - val_mae: 0.4357\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4156 - mae: 0.4156 - val_loss: 0.3886 - val_mae: 0.3886\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3705 - mae: 0.3705 - val_loss: 0.3431 - val_mae: 0.3431\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3282 - mae: 0.3282 - val_loss: 0.3013 - val_mae: 0.3013\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2915 - mae: 0.2915 - val_loss: 0.2649 - val_mae: 0.2649\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2585 - mae: 0.2585 - val_loss: 0.2329 - val_mae: 0.2329\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2308 - mae: 0.2308 - val_loss: 0.2074 - val_mae: 0.2074\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2084 - mae: 0.2084 - val_loss: 0.1893 - val_mae: 0.1893\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1928 - mae: 0.1928 - val_loss: 0.1774 - val_mae: 0.1774\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1823 - mae: 0.1823 - val_loss: 0.1696 - val_mae: 0.1696\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - mae: 0.1755 - val_loss: 0.1645 - val_mae: 0.1645\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1710 - mae: 0.1710 - val_loss: 0.1619 - val_mae: 0.1619\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1689 - mae: 0.1689 - val_loss: 0.1609 - val_mae: 0.1609\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1677 - mae: 0.1677 - val_loss: 0.1605 - val_mae: 0.1605\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1670 - mae: 0.1670 - val_loss: 0.1606 - val_mae: 0.1606\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1667 - mae: 0.1667 - val_loss: 0.1607 - val_mae: 0.1607\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1666 - mae: 0.1666 - val_loss: 0.1608 - val_mae: 0.1608\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1665 - mae: 0.1665 - val_loss: 0.1610 - val_mae: 0.1610\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1611 - val_mae: 0.1611\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1613 - val_mae: 0.1613\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1665 - mae: 0.1665 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1618 - val_mae: 0.1618\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1665 - mae: 0.1665 - val_loss: 0.1619 - val_mae: 0.1619\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1665 - mae: 0.1665 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1665 - mae: 0.1665 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1619 - val_mae: 0.1619\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1618 - val_mae: 0.1618\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1665 - mae: 0.1665 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1618 - val_mae: 0.1618\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1611 - val_mae: 0.1611\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1666 - mae: 0.166 - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1616 - val_mae: 0.1616\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1615 - val_mae: 0.1615\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1614 - val_mae: 0.1614\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1664 - mae: 0.1664 - val_loss: 0.1613 - val_mae: 0.1613\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u8_lr3 = simple_model_jsmr_n1_h1_u8_lr3.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 19,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_jsmr_n1_h1_u8_lr1 = simple_model_jsmr_n1_h1_u8_lr1.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h1_u8_lr2 = simple_model_jsmr_n1_h1_u8_lr2.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h1_u8_lr3 = simple_model_jsmr_n1_h1_u8_lr3.predict(X_test_jsmr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.1\n",
      "mae score jsmr_n1_h1_u8_lr1: 0.1747876878015338\n",
      "r2 score jsmr_n1_h1_u8_lr1: 0.0\n",
      "mape score jsmr_n1_h1_u8_lr1: 0.3206406132333469\n",
      "rmse score jsmr_n1_h1_u8_lr1: 0.21602432648161068\n",
      "learning rate 0.01\n",
      "mae score jsmr_n1_h1_u8_lr2: 0.01167398550338823\n",
      "r2 score jsmr_n1_h1_u8_lr2: 0.9938298320044374\n",
      "mape score jsmr_n1_h1_u8_lr2: 0.02903799041381432\n",
      "rmse score jsmr_n1_h1_u8_lr2: 0.016833908267642025\n",
      "learning rate 0.001\n",
      "mae score jsmr_n1_h1_u8_lr3: 0.17217571334708587\n",
      "r2 score jsmr_n1_h1_u8_lr3: -13320900317009.041\n",
      "mape score jsmr_n1_h1_u8_lr3: 0.28529146356206614\n",
      "rmse score jsmr_n1_h1_u8_lr3: 0.2175438915947297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"learning rate 0.1\")\n",
    "print(\"mae score jsmr_n1_h1_u8_lr1: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u8_lr1, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u8_lr1: \"+str(r2_score(preds_jsmr_n1_h1_u8_lr1, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u8_lr1: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr1, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u8_lr1: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr1, y_test_jsmr_1))))\n",
    "\n",
    "print(\"learning rate 0.01\")\n",
    "print(\"mae score jsmr_n1_h1_u8_lr2: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u8_lr2, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u8_lr2: \"+str(r2_score(preds_jsmr_n1_h1_u8_lr2, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u8_lr2: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr2, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u8_lr2: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr2, y_test_jsmr_1))))\n",
    "\n",
    "print(\"learning rate 0.001\")\n",
    "print(\"mae score jsmr_n1_h1_u8_lr3: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u8_lr3, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u8_lr3: \"+str(r2_score(preds_jsmr_n1_h1_u8_lr3, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u8_lr3: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr3, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u8_lr3: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr3, y_test_jsmr_1))))\n",
    "\n",
    "mae_jsmr_hl_u = {'model_n1_h1_u8_lr1':mean_absolute_error(preds_jsmr_n1_h1_u8_lr1, y_test_jsmr_1),'model_n1_h1_u8_lr2':mean_absolute_error(preds_jsmr_n1_h1_u8_lr2, y_test_jsmr_1),'model_n1_h1_u8_lr3':mean_absolute_error(preds_jsmr_n1_h1_u8_lr3, y_test_jsmr_1)}\n",
    "\n",
    "mape_jsmr_hl_u = {'model_n1_h1_u8_lr1':mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr1, y_test_jsmr_1),'model_n1_h1_u8_lr2':mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr2, y_test_jsmr_1),'model_n1_h1_u8_lr3':mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr3, y_test_jsmr_1)}\n",
    "\n",
    "rmse_jsmr_hl_u = {'model_n1_h1_u8_lr1':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr1, y_test_jsmr_1)),'model_n1_h1_u8_lr2':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr2, y_test_jsmr_1)),'model_n1_h1_u8_lr3':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr3, y_test_jsmr_1))}\n",
    "\n",
    "r2_jsmr_hl_u = {'model_n1_h1_u8_lr1':r2_score(preds_jsmr_n1_h1_u8_lr1, y_test_jsmr_1),'model_n1_h1_u8_lr2':r2_score(preds_jsmr_n1_h1_u8_lr2, y_test_jsmr_1),'model_n1_h1_u8_lr3':r2_score(preds_jsmr_n1_h1_u8_lr3, y_test_jsmr_1)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate 0.1\n",
    "# mae score jsmr_n1_h1_u8_lr1: 0.1747876878015338\n",
    "# r2 score jsmr_n1_h1_u8_lr1: 0.0\n",
    "# mape score jsmr_n1_h1_u8_lr1: 0.3206406132333469\n",
    "# rmse score jsmr_n1_h1_u8_lr1: 0.21602432648161068\n",
    "# learning rate 0.01\n",
    "# mae score jsmr_n1_h1_u8_lr2: 0.01167398550338823\n",
    "# r2 score jsmr_n1_h1_u8_lr2: 0.9938298320044374\n",
    "# mape score jsmr_n1_h1_u8_lr2: 0.02903799041381432\n",
    "# rmse score jsmr_n1_h1_u8_lr2: 0.016833908267642025\n",
    "# learning rate 0.001\n",
    "# mae score jsmr_n1_h1_u8_lr3: 0.17217571334708587\n",
    "# r2 score jsmr_n1_h1_u8_lr3: -13320900317009.041\n",
    "# mape score jsmr_n1_h1_u8_lr3: 0.28529146356206614\n",
    "# rmse score jsmr_n1_h1_u8_lr3: 0.2175438915947297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n1_h1_u8_lr2': 0.01167398550338823, 'model_n1_h1_u8_lr3': 0.17217571334708587, 'model_n1_h1_u8_lr1': 0.1747876878015338}\n",
      "sorted rmse\n",
      "{'model_n1_h1_u8_lr2': 0.016833908267642025, 'model_n1_h1_u8_lr1': 0.21602432648161068, 'model_n1_h1_u8_lr3': 0.2175438915947297}\n",
      "sorted mape\n",
      "{'model_n1_h1_u8_lr2': 0.02903799041381432, 'model_n1_h1_u8_lr3': 0.28529146356206614, 'model_n1_h1_u8_lr1': 0.3206406132333469}\n",
      "sorted r2\n",
      "{'model_n1_h1_u8_lr2': 0.9938298320044374, 'model_n1_h1_u8_lr1': 0.0, 'model_n1_h1_u8_lr3': -13320900317009.041}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_jsmr_hl_u_sorted = dict(sorted(mae_jsmr_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mae_jsmr_hl_u_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_jsmr_hl_u_sorted = dict(sorted(rmse_jsmr_hl_u.items(),key=lambda item: item[1]))\n",
    "print(rmse_jsmr_hl_u_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_jsmr_hl_u_sorted = dict(sorted(mape_jsmr_hl_u.items(),key=lambda item: item[1]))\n",
    "print(mape_jsmr_hl_u_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_jsmr_hl_u_sorted = dict(sorted(r2_jsmr_hl_u.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_jsmr_hl_u_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n1_h1_u8_lr2': 0.01167398550338823, 'model_n1_h1_u8_lr3': 0.17217571334708587, 'model_n1_h1_u8_lr1': 0.1747876878015338}\n",
    "# sorted rmse\n",
    "# {'model_n1_h1_u8_lr2': 0.016833908267642025, 'model_n1_h1_u8_lr1': 0.21602432648161068, 'model_n1_h1_u8_lr3': 0.2175438915947297}\n",
    "# sorted mape\n",
    "# {'model_n1_h1_u8_lr2': 0.02903799041381432, 'model_n1_h1_u8_lr3': 0.28529146356206614, 'model_n1_h1_u8_lr1': 0.3206406132333469}\n",
    "# sorted r2\n",
    "# {'model_n1_h1_u8_lr2': 0.9938298320044374, 'model_n1_h1_u8_lr1': 0.0, 'model_n1_h1_u8_lr3': -13320900317009.041}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KESIMPULAN HASIL\n",
    "Hasil diatas menunjukan konfigurasi learning rate untuk saham ANTM terbaik adalah 0.1 sedangkan untuk saham ASII, ICBP, JSMR menunjukan hasil terbaik dengan learning rate 0.01.\n",
    "\n",
    "selanjutnya learning rate yang akan digunakan adalah 0.1 untuk ANTM dan 0.01 untuk ASII, ICBP, dan JSMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm = df_antm.reset_index(drop=True)\n",
    "arr_antm = df_antm.to_numpy()\n",
    "flat_antm = arr_antm.flatten()\n",
    "antm_X_2, antm_y_2 = split_sequence(flat_antm, n_steps_2)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_antm_2, X_test_antm_2, y_train_antm_2, y_test_antm_2 = train_test_split(antm_X_2, antm_y_2, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "X_train_antm_2 = X_train_antm_2.reshape(X_train_antm_2.shape[0],X_train_antm_2.shape[1],n_features)\n",
    "X_test_antm_2 = X_test_antm_2.reshape(X_test_antm_2.shape[0],X_test_antm_2.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_39 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u8_lr1_e100 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr1_e100.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr1_e100.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_40 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u8_lr1_e150 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr1_e150.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr1_e150.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_41 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_antm_n2_h1_u8_lr1_e200 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_2, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr1_e200.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_antm_n2_h1_u8_lr1_e200.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 9ms/step - loss: 0.1534 - mae: 0.1534 - val_loss: 0.1530 - val_mae: 0.1530\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1405 - mae: 0.1405 - val_loss: 0.1535 - val_mae: 0.1535\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1419 - mae: 0.1419 - val_loss: 0.1532 - val_mae: 0.1532\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1418 - mae: 0.1418 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1430 - mae: 0.143 - 0s 3ms/step - loss: 0.1418 - mae: 0.1418 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1401 - mae: 0.1401 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1416 - mae: 0.1416 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1401 - mae: 0.1401 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1415 - mae: 0.1415 - val_loss: 0.1585 - val_mae: 0.1585\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1436 - mae: 0.1436 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1438 - mae: 0.1438 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1452 - mae: 0.1452 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1440 - mae: 0.1440 - val_loss: 0.1494 - val_mae: 0.1494\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1436 - mae: 0.1436 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1418 - mae: 0.1418 - val_loss: 0.1519 - val_mae: 0.1519\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1410 - mae: 0.1410 - val_loss: 0.1470 - val_mae: 0.1470\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1440 - mae: 0.1440 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1403 - mae: 0.1403 - val_loss: 0.1475 - val_mae: 0.1475\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1410 - mae: 0.1410 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425 - val_loss: 0.1472 - val_mae: 0.1472\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1435 - mae: 0.1435 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1416 - mae: 0.1416 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1403 - mae: 0.1403 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1420 - mae: 0.1420 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1410 - mae: 0.1410 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.1492 - val_mae: 0.1492\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1403 - mae: 0.1403 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.1465 - val_mae: 0.1465\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1422 - mae: 0.1422 - val_loss: 0.1467 - val_mae: 0.1467\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1415 - mae: 0.1415 - val_loss: 0.1503 - val_mae: 0.1503\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1404 - mae: 0.1404 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.1427 - val_loss: 0.1474 - val_mae: 0.1474\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1406 - mae: 0.1406 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1467 - val_mae: 0.1467\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.1677 - val_mae: 0.1677\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.1652 - val_mae: 0.1652\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1459 - mae: 0.1459 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1434 - mae: 0.1434 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.1617 - val_mae: 0.1617\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1444 - mae: 0.1444 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1410 - mae: 0.1410 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1405 - mae: 0.1405 - val_loss: 0.1554 - val_mae: 0.1554\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1468 - mae: 0.1468 - val_loss: 0.1575 - val_mae: 0.1575\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1439 - mae: 0.1439 - val_loss: 0.1664 - val_mae: 0.1664\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1460 - mae: 0.1460 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1410 - mae: 0.1410 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1419 - mae: 0.1419 - val_loss: 0.1543 - val_mae: 0.1543\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1628 - val_mae: 0.1628\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1430 - mae: 0.1430 - val_loss: 0.1485 - val_mae: 0.1485\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1421 - mae: 0.1421 - val_loss: 0.1549 - val_mae: 0.1549\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1409 - mae: 0.1409 - val_loss: 0.1554 - val_mae: 0.1554\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1423 - mae: 0.1423 - val_loss: 0.1552 - val_mae: 0.1552\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1506 - val_mae: 0.1506\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1435 - mae: 0.1435 - val_loss: 0.1580 - val_mae: 0.1580\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.1427 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1405 - mae: 0.1405 - val_loss: 0.1472 - val_mae: 0.1472\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1431 - mae: 0.1431 - val_loss: 0.1549 - val_mae: 0.1549\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1600 - val_mae: 0.1600\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1417 - mae: 0.1417 - val_loss: 0.1503 - val_mae: 0.1503\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1453 - mae: 0.1453 - val_loss: 0.1471 - val_mae: 0.1471\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1405 - mae: 0.1405 - val_loss: 0.1468 - val_mae: 0.1468\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1423 - mae: 0.1423 - val_loss: 0.1481 - val_mae: 0.1481\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1408 - mae: 0.1408 - val_loss: 0.1477 - val_mae: 0.1477\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1442 - mae: 0.1442 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1455 - mae: 0.1455 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1423 - mae: 0.1423 - val_loss: 0.1509 - val_mae: 0.1509\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1450 - mae: 0.1450 - val_loss: 0.1538 - val_mae: 0.1538\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.1427 - val_loss: 0.1599 - val_mae: 0.1599\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1428 - mae: 0.1428 - val_loss: 0.1489 - val_mae: 0.1489\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1417 - mae: 0.1417 - val_loss: 0.1470 - val_mae: 0.1470\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1415 - mae: 0.1415 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1406 - mae: 0.1406 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1441 - mae: 0.1441 - val_loss: 0.1531 - val_mae: 0.1531\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1430 - mae: 0.1430 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1421 - mae: 0.1421 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1471 - mae: 0.1471 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1419 - mae: 0.1419 - val_loss: 0.1487 - val_mae: 0.1487\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1439 - mae: 0.1439 - val_loss: 0.1466 - val_mae: 0.1466\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1431 - mae: 0.1431 - val_loss: 0.1581 - val_mae: 0.1581\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1493 - val_mae: 0.1493\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425 - val_loss: 0.1649 - val_mae: 0.1649\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1458 - mae: 0.1458 - val_loss: 0.1619 - val_mae: 0.1619\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1410 - mae: 0.1410 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1413 - mae: 0.1413 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1448 - mae: 0.1448 - val_loss: 0.1482 - val_mae: 0.1482\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425 - val_loss: 0.1561 - val_mae: 0.1561\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1445 - mae: 0.1445 - val_loss: 0.1502 - val_mae: 0.1502\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1425 - mae: 0.1425 - val_loss: 0.1461 - val_mae: 0.1461\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1426 - mae: 0.1426 - val_loss: 0.1480 - val_mae: 0.1480\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u8_lr1_e100 = simple_model_antm_n2_h1_u8_lr1_e100.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 22.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.0655 - mae: 0.0655 - val_loss: 0.0531 - val_mae: 0.0531\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0365 - val_mae: 0.0365\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0320 - val_mae: 0.0320\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0254 - val_mae: 0.0254\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0237 - val_mae: 0.0237\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0160 - mae: 0.016 - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0224 - val_mae: 0.0224\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0280 - val_mae: 0.0280\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0283 - val_mae: 0.0283\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0277 - val_mae: 0.0277\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0248 - val_mae: 0.0248\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0505 - val_mae: 0.0505\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0450 - val_mae: 0.0450\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0385 - val_mae: 0.0385\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0318 - val_mae: 0.0318\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 72/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 73/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 74/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 75/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 76/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 77/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 78/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 79/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0239 - val_mae: 0.0239\n",
      "Epoch 80/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 81/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 82/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 83/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 84/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 85/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 86/150\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0120 - mae: 0.012 - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 87/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 88/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 89/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 90/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 91/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 92/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 93/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0243 - val_mae: 0.0243\n",
      "Epoch 94/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0314 - val_mae: 0.0314\n",
      "Epoch 95/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 96/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 97/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 98/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 99/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 100/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 101/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 102/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 103/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 104/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 105/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 106/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 107/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 108/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 109/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 110/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 111/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 112/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 113/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 114/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 115/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 116/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 117/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 118/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 119/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 120/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 121/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 122/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 123/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0293 - val_mae: 0.0293\n",
      "Epoch 124/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 125/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 126/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 127/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 128/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0305 - val_mae: 0.0305\n",
      "Epoch 129/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0285 - val_mae: 0.0285\n",
      "Epoch 130/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 131/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 132/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 133/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 134/150\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0124 - mae: 0.012 - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 135/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 136/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 137/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 138/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 139/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 140/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 141/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 142/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 143/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 144/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 145/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 146/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 147/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 148/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 149/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 150/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0130 - val_mae: 0.0130\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u8_lr1_e150 = simple_model_antm_n2_h1_u8_lr1_e150.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=150,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 31.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.0437 - mae: 0.0437 - val_loss: 0.0290 - val_mae: 0.0290\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0260 - val_mae: 0.0260\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0226 - mae: 0.0226 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0257 - mae: 0.0257 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0264 - val_mae: 0.0264\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0258 - val_mae: 0.0258\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0333 - val_mae: 0.0333\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0326 - val_mae: 0.0326\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0307 - val_mae: 0.0307\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0314 - val_mae: 0.0314\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0241 - val_mae: 0.0241\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0290 - val_mae: 0.0290\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0339 - val_mae: 0.0339\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0252 - val_mae: 0.0252\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0233 - val_mae: 0.0233\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0291 - val_mae: 0.0291\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0261 - val_mae: 0.0261\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0234 - val_mae: 0.0234\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0253 - val_mae: 0.0253\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0240 - val_mae: 0.0240\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0266 - val_mae: 0.0266\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0233 - val_mae: 0.0233\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0109 - val_mae: 0.0109\n"
     ]
    }
   ],
   "source": [
    "smod_history_antm_n2_h1_u8_lr1_e200 = simple_model_antm_n2_h1_u8_lr1_e200.fit(X_train_antm_2, y_train_antm_2,\n",
    "          validation_split=0.2,\n",
    "          epochs=200,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 41.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_antm_n2_h1_u8_lr1_e100 = simple_model_antm_n2_h1_u8_lr1_e100.predict(X_test_antm_2)\n",
    "preds_antm_n2_h1_u8_lr1_e150 = simple_model_antm_n2_h1_u8_lr1_e150.predict(X_test_antm_2)\n",
    "preds_antm_n2_h1_u8_lr1_e200 = simple_model_antm_n2_h1_u8_lr1_e200.predict(X_test_antm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n",
      "mae score antm_n2_h1_u8_lr1_e100: 0.14754789239237595\n",
      "r2 score antm_n2_h1_u8_lr1_e100: -221038482894204.16\n",
      "mape score antm_n2_h1_u8_lr1_e100: 0.7403797531482074\n",
      "rmse score antm_n2_h1_u8_lr1_e100: 0.22154097275102877\n",
      "epoch 150\n",
      "mae score antm_n2_h1_u8_lr1_e150: 0.012603131954268052\n",
      "r2 score antm_n2_h1_u8_lr1_e150: 0.9924575065041806\n",
      "mape score antm_n2_h1_u8_lr1_e150: 0.07157605810937363\n",
      "rmse score antm_n2_h1_u8_lr1_e150: 0.017055567313677432\n",
      "epoch 200\n",
      "mae score antm_n2_h1_u8_lr1_e200: 0.010756083597232485\n",
      "r2 score antm_n2_h1_u8_lr1_e200: 0.9944954731854885\n",
      "mape score antm_n2_h1_u8_lr1_e200: 0.047077413811716186\n",
      "rmse score antm_n2_h1_u8_lr1_e200: 0.014875900820590184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"epoch 100\")\n",
    "print(\"mae score antm_n2_h1_u8_lr1_e100: \"+str(mean_absolute_error(preds_antm_n2_h1_u8_lr1_e100, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u8_lr1_e100: \"+str(r2_score(preds_antm_n2_h1_u8_lr1_e100, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u8_lr1_e100: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr1_e100, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u8_lr1_e100: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr1_e100, y_test_antm_2))))\n",
    "\n",
    "print(\"epoch 150\")\n",
    "print(\"mae score antm_n2_h1_u8_lr1_e150: \"+str(mean_absolute_error(preds_antm_n2_h1_u8_lr1_e150, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u8_lr1_e150: \"+str(r2_score(preds_antm_n2_h1_u8_lr1_e150, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u8_lr1_e150: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr1_e150, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u8_lr1_e150: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr1_e150, y_test_antm_2))))\n",
    "\n",
    "print(\"epoch 200\")\n",
    "print(\"mae score antm_n2_h1_u8_lr1_e200: \"+str(mean_absolute_error(preds_antm_n2_h1_u8_lr1_e200, y_test_antm_2)))\n",
    "print(\"r2 score antm_n2_h1_u8_lr1_e200: \"+str(r2_score(preds_antm_n2_h1_u8_lr1_e200, y_test_antm_2)))\n",
    "print(\"mape score antm_n2_h1_u8_lr1_e200: \"+str(mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr1_e200, y_test_antm_2)))\n",
    "print(\"rmse score antm_n2_h1_u8_lr1_e200: \"+str(np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr1_e200, y_test_antm_2))))\n",
    "\n",
    "mae_antm_hl_u_lr_e = {'model_n2_h1_u8_lr1_e100':mean_absolute_error(preds_antm_n2_h1_u8_lr1_e100, y_test_antm_2),'model_n2_h1_u8_lr1_e150':mean_absolute_error(preds_antm_n2_h1_u8_lr1_e150, y_test_antm_2),'model_n2_h1_u8_lr1_e200':mean_absolute_error(preds_antm_n2_h1_u8_lr1_e200, y_test_antm_2)}\n",
    "\n",
    "mape_antm_hl_u_lr_e = {'model_n2_h1_u8_lr1_e100':mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr1_e100, y_test_antm_2),'model_n2_h1_u8_lr1_e150':mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr1_e150, y_test_antm_2),'model_n2_h1_u8_lr1_e200':mean_absolute_percentage_error(preds_antm_n2_h1_u8_lr1_e200, y_test_antm_2)}\n",
    "\n",
    "rmse_antm_hl_u_lr_e = {'model_n2_h1_u8_lr1_e100':np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr1_e100, y_test_antm_2)),'model_n2_h1_u8_lr1_e150':np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr1_e150, y_test_antm_2)),'model_n2_h1_u8_lr1_e200':np.sqrt(mean_squared_error(preds_antm_n2_h1_u8_lr1_e200, y_test_antm_2))}\n",
    "\n",
    "r2_antm_hl_u_lr_e = {'model_n2_h1_u8_lr1_e100':r2_score(preds_antm_n2_h1_u8_lr1_e100, y_test_antm_2),'model_n2_h1_u8_lr1_e150':r2_score(preds_antm_n2_h1_u8_lr1_e150, y_test_antm_2),'model_n2_h1_u8_lr1_e200':r2_score(preds_antm_n2_h1_u8_lr1_e200, y_test_antm_2)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 100\n",
    "# mae score antm_n2_h1_u8_lr1_e100: 0.14754789239237595\n",
    "# r2 score antm_n2_h1_u8_lr1_e100: -221038482894204.16\n",
    "# mape score antm_n2_h1_u8_lr1_e100: 0.7403797531482074\n",
    "# rmse score antm_n2_h1_u8_lr1_e100: 0.22154097275102877\n",
    "# epoch 150\n",
    "# mae score antm_n2_h1_u8_lr1_e150: 0.012603131954268052\n",
    "# r2 score antm_n2_h1_u8_lr1_e150: 0.9924575065041806\n",
    "# mape score antm_n2_h1_u8_lr1_e150: 0.07157605810937363\n",
    "# rmse score antm_n2_h1_u8_lr1_e150: 0.017055567313677432\n",
    "# epoch 200\n",
    "# mae score antm_n2_h1_u8_lr1_e200: 0.010756083597232485\n",
    "# r2 score antm_n2_h1_u8_lr1_e200: 0.9944954731854885\n",
    "# mape score antm_n2_h1_u8_lr1_e200: 0.047077413811716186\n",
    "# rmse score antm_n2_h1_u8_lr1_e200: 0.014875900820590184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n2_h1_u8_lr1_e200': 0.010756083597232485, 'model_n2_h1_u8_lr1_e150': 0.012603131954268052, 'model_n2_h1_u8_lr1_e100': 0.14754789239237595}\n",
      "sorted rmse\n",
      "{'model_n2_h1_u8_lr1_e200': 0.014875900820590184, 'model_n2_h1_u8_lr1_e150': 0.017055567313677432, 'model_n2_h1_u8_lr1_e100': 0.22154097275102877}\n",
      "sorted mape\n",
      "{'model_n2_h1_u8_lr1_e200': 0.047077413811716186, 'model_n2_h1_u8_lr1_e150': 0.07157605810937363, 'model_n2_h1_u8_lr1_e100': 0.7403797531482074}\n",
      "sorted r2\n",
      "{'model_n2_h1_u8_lr1_e200': 0.9944954731854885, 'model_n2_h1_u8_lr1_e150': 0.9924575065041806, 'model_n2_h1_u8_lr1_e100': -221038482894204.16}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_antm_hl_u_lr_e_sorted = dict(sorted(mae_antm_hl_u_lr_e.items(),key=lambda item: item[1]))\n",
    "print(mae_antm_hl_u_lr_e_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_antm_hl_u_lr_e_sorted = dict(sorted(rmse_antm_hl_u_lr_e.items(),key=lambda item: item[1]))\n",
    "print(rmse_antm_hl_u_lr_e_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_antm_hl_u_lr_e_sorted = dict(sorted(mape_antm_hl_u_lr_e.items(),key=lambda item: item[1]))\n",
    "print(mape_antm_hl_u_lr_e_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_antm_hl_u_lr_e_sorted = dict(sorted(r2_antm_hl_u_lr_e.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_antm_hl_u_lr_e_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n2_h1_u8_lr1_e200': 0.010756083597232485, 'model_n2_h1_u8_lr1_e150': 0.012603131954268052, 'model_n2_h1_u8_lr1_e100': 0.14754789239237595}\n",
    "# sorted rmse\n",
    "# {'model_n2_h1_u8_lr1_e200': 0.014875900820590184, 'model_n2_h1_u8_lr1_e150': 0.017055567313677432, 'model_n2_h1_u8_lr1_e100': 0.22154097275102877}\n",
    "# sorted mape\n",
    "# {'model_n2_h1_u8_lr1_e200': 0.047077413811716186, 'model_n2_h1_u8_lr1_e150': 0.07157605810937363, 'model_n2_h1_u8_lr1_e100': 0.7403797531482074}\n",
    "# sorted r2\n",
    "# {'model_n2_h1_u8_lr1_e200': 0.9944954731854885, 'model_n2_h1_u8_lr1_e150': 0.9924575065041806, 'model_n2_h1_u8_lr1_e100': -221038482894204.16}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asii = df_asii.reset_index(drop=True)\n",
    "arr_asii = df_asii.to_numpy()\n",
    "flat_asii = arr_asii.flatten()\n",
    "asii_X_3, asii_y_3 = split_sequence(flat_asii, n_steps_3)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_asii_3, X_test_asii_3, y_train_asii_3, y_test_asii_3 = train_test_split(asii_X_3, asii_y_3, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_asii_3 = X_train_asii_3.reshape(X_train_asii_3.shape[0],X_train_asii_3.shape[1],n_features)\n",
    "X_test_asii_3 = X_test_asii_3.reshape(X_test_asii_3.shape[0],X_test_asii_3.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_51 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u32_lr2_e100 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr2_e100.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr2_e100.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_52 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u32_lr2_e150 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr2_e150.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr2_e150.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_53 (LSTM)              (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_asii_n3_h1_u32_lr2_e200 = Sequential([\n",
    "  LSTM(32, activation='relu',input_shape=(n_steps_3, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr2_e200.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_asii_n3_h1_u32_lr2_e200.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 4s 9ms/step - loss: 0.1214 - mae: 0.1214 - val_loss: 0.0290 - val_mae: 0.0290\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0256 - mae: 0.0256 - val_loss: 0.0252 - val_mae: 0.0252\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.0238 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0145 - val_mae: 0.0145\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u32_lr2_e100 = simple_model_asii_n3_h1_u32_lr2_e100.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 25.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.0904 - mae: 0.0904 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0276 - val_mae: 0.0276\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0224 - val_mae: 0.0224\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0219 - mae: 0.0219 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0339 - val_mae: 0.0339\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0201 - mae: 0.0201 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0317 - val_mae: 0.0317\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0244 - val_mae: 0.0244\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0267 - val_mae: 0.0267\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0239 - val_mae: 0.0239\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 72/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 73/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 74/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 75/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 76/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 77/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 78/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 79/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 80/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 81/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 82/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 83/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 84/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 85/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 86/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 87/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 88/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 89/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 90/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 91/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 92/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 93/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 94/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 95/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 96/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 97/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 98/150\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0164 - mae: 0.016 - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 99/150\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 100/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 101/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 102/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 103/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0259 - val_mae: 0.0259\n",
      "Epoch 104/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0270 - val_mae: 0.0270\n",
      "Epoch 105/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 106/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 107/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 108/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 109/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 110/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 111/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 112/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 113/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 114/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0250 - val_mae: 0.0250\n",
      "Epoch 115/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 116/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 117/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 118/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 119/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 120/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 121/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 122/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 123/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 124/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 125/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 126/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 127/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 128/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 129/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 130/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 131/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 132/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 133/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 134/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 135/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 136/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 137/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 138/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 139/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 140/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 141/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 142/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 143/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 144/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 145/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 146/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 147/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 148/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 149/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 150/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0146 - val_mae: 0.0146\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u32_lr2_e150 = simple_model_asii_n3_h1_u32_lr2_e150.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=150,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 35.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.1624 - mae: 0.1624 - val_loss: 0.0571 - val_mae: 0.0571\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0338 - mae: 0.0338 - val_loss: 0.0266 - val_mae: 0.0266\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0254 - mae: 0.0254 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0221 - mae: 0.0221 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0224 - val_mae: 0.0224\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0330 - val_mae: 0.0330\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0226 - val_mae: 0.0226\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0254 - val_mae: 0.0254\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0275 - val_mae: 0.0275\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0259 - val_mae: 0.0259\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0259 - val_mae: 0.0259\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0160 - mae: 0.016 - 0s 5ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0225 - val_mae: 0.0225\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0160 - val_mae: 0.0160\n"
     ]
    }
   ],
   "source": [
    "smod_history_asii_n3_h1_u32_lr2_e200 = simple_model_asii_n3_h1_u32_lr2_e200.fit(X_train_asii_3, y_train_asii_3,\n",
    "          validation_split=0.2,\n",
    "          epochs=200,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 45.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_asii_n3_h1_u32_lr2_e100 = simple_model_asii_n3_h1_u32_lr2_e100.predict(X_test_asii_3)\n",
    "preds_asii_n3_h1_u32_lr2_e150 = simple_model_asii_n3_h1_u32_lr2_e150.predict(X_test_asii_3)\n",
    "preds_asii_n3_h1_u32_lr2_e200 = simple_model_asii_n3_h1_u32_lr2_e200.predict(X_test_asii_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n",
      "mae score asii_n3_h1_u32_lr2_e100: 0.014796198288149291\n",
      "r2 score asii_n3_h1_u32_lr2_e100: 0.9900005761927053\n",
      "mape score asii_n3_h1_u32_lr2_e100: 0.03252959845439422\n",
      "rmse score asii_n3_h1_u32_lr2_e100: 0.019880899176690187\n",
      "epoch 150\n",
      "mae score asii_n3_h1_u32_lr2_e150: 0.014720629079311317\n",
      "r2 score asii_n3_h1_u32_lr2_e150: 0.9900421439449422\n",
      "mape score asii_n3_h1_u32_lr2_e150: 0.03349409492304816\n",
      "rmse score asii_n3_h1_u32_lr2_e150: 0.019787171074738395\n",
      "epoch 200\n",
      "mae score asii_n3_h1_u32_lr2_e200: 0.015531000751860619\n",
      "r2 score asii_n3_h1_u32_lr2_e200: 0.9889763587181039\n",
      "mape score asii_n3_h1_u32_lr2_e200: 0.03368880365631896\n",
      "rmse score asii_n3_h1_u32_lr2_e200: 0.020626043608880918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"epoch 100\")\n",
    "print(\"mae score asii_n3_h1_u32_lr2_e100: \"+str(mean_absolute_error(preds_asii_n3_h1_u32_lr2_e100, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u32_lr2_e100: \"+str(r2_score(preds_asii_n3_h1_u32_lr2_e100, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u32_lr2_e100: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr2_e100, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u32_lr2_e100: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr2_e100, y_test_asii_3))))\n",
    "\n",
    "print(\"epoch 150\")\n",
    "print(\"mae score asii_n3_h1_u32_lr2_e150: \"+str(mean_absolute_error(preds_asii_n3_h1_u32_lr2_e150, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u32_lr2_e150: \"+str(r2_score(preds_asii_n3_h1_u32_lr2_e150, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u32_lr2_e150: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr2_e150, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u32_lr2_e150: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr2_e150, y_test_asii_3))))\n",
    "\n",
    "print(\"epoch 200\")\n",
    "print(\"mae score asii_n3_h1_u32_lr2_e200: \"+str(mean_absolute_error(preds_asii_n3_h1_u32_lr2_e200, y_test_asii_3)))\n",
    "print(\"r2 score asii_n3_h1_u32_lr2_e200: \"+str(r2_score(preds_asii_n3_h1_u32_lr2_e200, y_test_asii_3)))\n",
    "print(\"mape score asii_n3_h1_u32_lr2_e200: \"+str(mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr2_e200, y_test_asii_3)))\n",
    "print(\"rmse score asii_n3_h1_u32_lr2_e200: \"+str(np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr2_e200, y_test_asii_3))))\n",
    "\n",
    "mae_asii_hl_u_lr_e = {'model_n3_h1_u32_lr2_e100':mean_absolute_error(preds_asii_n3_h1_u32_lr2_e100, y_test_asii_3),'model_n3_h1_u32_lr2_e150':mean_absolute_error(preds_asii_n3_h1_u32_lr2_e150, y_test_asii_3),'model_n3_h1_u32_lr2_e200':mean_absolute_error(preds_asii_n3_h1_u32_lr2_e200, y_test_asii_3)}\n",
    "\n",
    "mape_asii_hl_u_lr_e = {'model_n3_h1_u32_lr2_e100':mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr2_e100, y_test_asii_3),'model_n3_h1_u32_lr2_e150':mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr2_e150, y_test_asii_3),'model_n3_h1_u32_lr2_e200':mean_absolute_percentage_error(preds_asii_n3_h1_u32_lr2_e200, y_test_asii_3)}\n",
    "\n",
    "rmse_asii_hl_u_lr_e = {'model_n3_h1_u32_lr2_e100':np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr2_e100, y_test_asii_3)),'model_n3_h1_u32_lr2_e150':np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr2_e150, y_test_asii_3)),'model_n3_h1_u32_lr2_e200':np.sqrt(mean_squared_error(preds_asii_n3_h1_u32_lr2_e200, y_test_asii_3))}\n",
    "\n",
    "r2_asii_hl_u_lr_e = {'model_n3_h1_u32_lr2_e100':r2_score(preds_asii_n3_h1_u32_lr2_e100, y_test_asii_3),'model_n3_h1_u32_lr2_e150':r2_score(preds_asii_n3_h1_u32_lr2_e150, y_test_asii_3),'model_n3_h1_u32_lr2_e200':r2_score(preds_asii_n3_h1_u32_lr2_e200, y_test_asii_3)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 100\n",
    "# mae score asii_n3_h1_u32_lr2_e100: 0.014796198288149291\n",
    "# r2 score asii_n3_h1_u32_lr2_e100: 0.9900005761927053\n",
    "# mape score asii_n3_h1_u32_lr2_e100: 0.03252959845439422\n",
    "# rmse score asii_n3_h1_u32_lr2_e100: 0.019880899176690187\n",
    "# epoch 150\n",
    "# mae score asii_n3_h1_u32_lr2_e150: 0.014720629079311317\n",
    "# r2 score asii_n3_h1_u32_lr2_e150: 0.9900421439449422\n",
    "# mape score asii_n3_h1_u32_lr2_e150: 0.03349409492304816\n",
    "# rmse score asii_n3_h1_u32_lr2_e150: 0.019787171074738395\n",
    "# epoch 200\n",
    "# mae score asii_n3_h1_u32_lr2_e200: 0.015531000751860619\n",
    "# r2 score asii_n3_h1_u32_lr2_e200: 0.9889763587181039\n",
    "# mape score asii_n3_h1_u32_lr2_e200: 0.03368880365631896\n",
    "# rmse score asii_n3_h1_u32_lr2_e200: 0.020626043608880918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n3_h1_u32_lr2_e150': 0.014720629079311317, 'model_n3_h1_u32_lr2_e100': 0.014796198288149291, 'model_n3_h1_u32_lr2_e200': 0.015531000751860619}\n",
      "sorted rmse\n",
      "{'model_n3_h1_u32_lr2_e150': 0.019787171074738395, 'model_n3_h1_u32_lr2_e100': 0.019880899176690187, 'model_n3_h1_u32_lr2_e200': 0.020626043608880918}\n",
      "sorted mape\n",
      "{'model_n3_h1_u32_lr2_e100': 0.03252959845439422, 'model_n3_h1_u32_lr2_e150': 0.03349409492304816, 'model_n3_h1_u32_lr2_e200': 0.03368880365631896}\n",
      "sorted r2\n",
      "{'model_n3_h1_u32_lr2_e150': 0.9900421439449422, 'model_n3_h1_u32_lr2_e100': 0.9900005761927053, 'model_n3_h1_u32_lr2_e200': 0.9889763587181039}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_asii_hl_u_lr_e_sorted = dict(sorted(mae_asii_hl_u_lr_e.items(),key=lambda item: item[1]))\n",
    "print(mae_asii_hl_u_lr_e_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_asii_hl_u_lr_e_sorted = dict(sorted(rmse_asii_hl_u_lr_e.items(),key=lambda item: item[1]))\n",
    "print(rmse_asii_hl_u_lr_e_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_asii_hl_u_lr_e_sorted = dict(sorted(mape_asii_hl_u_lr_e.items(),key=lambda item: item[1]))\n",
    "print(mape_asii_hl_u_lr_e_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_asii_hl_u_lr_e_sorted = dict(sorted(r2_asii_hl_u_lr_e.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_asii_hl_u_lr_e_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n3_h1_u32_lr2_e150': 0.014720629079311317, 'model_n3_h1_u32_lr2_e100': 0.014796198288149291, 'model_n3_h1_u32_lr2_e200': 0.015531000751860619}\n",
    "# sorted rmse\n",
    "# {'model_n3_h1_u32_lr2_e150': 0.019787171074738395, 'model_n3_h1_u32_lr2_e100': 0.019880899176690187, 'model_n3_h1_u32_lr2_e200': 0.020626043608880918}\n",
    "# sorted mape\n",
    "# {'model_n3_h1_u32_lr2_e100': 0.03252959845439422, 'model_n3_h1_u32_lr2_e150': 0.03349409492304816, 'model_n3_h1_u32_lr2_e200': 0.03368880365631896}\n",
    "# sorted r2\n",
    "# {'model_n3_h1_u32_lr2_e150': 0.9900421439449422, 'model_n3_h1_u32_lr2_e100': 0.9900005761927053, 'model_n3_h1_u32_lr2_e200': 0.9889763587181039}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icbp = df_icbp.reset_index(drop=True)\n",
    "arr_icbp = df_icbp.to_numpy()\n",
    "flat_icbp = arr_icbp.flatten()\n",
    "icbp_X_1, icbp_y_1 = split_sequence(flat_icbp, n_steps_1)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_icbp_1, X_test_icbp_1, y_train_icbp_1, y_test_icbp_1 = train_test_split(icbp_X_1, icbp_y_1, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_icbp_1 = X_train_icbp_1.reshape(X_train_icbp_1.shape[0],X_train_icbp_1.shape[1],n_features)\n",
    "X_test_icbp_1 = X_test_icbp_1.reshape(X_test_icbp_1.shape[0],X_test_icbp_1.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_54 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u8_lr1_e100 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr1_e100.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr1_e100.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_55 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u8_lr1_e150 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr1_e150.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr1_e150.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_56 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_icbp_n1_h1_u8_lr1_e200 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr1_e200.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_icbp_n1_h1_u8_lr1_e200.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 7ms/step - loss: 0.2215 - mae: 0.2215 - val_loss: 0.0979 - val_mae: 0.0979\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0481 - mae: 0.0481 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0079 - mae: 0.007 - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0125 - val_mae: 0.0125\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u8_lr1_e100 = simple_model_icbp_n1_h1_u8_lr1_e100.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 20.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.2860 - mae: 0.2860 - val_loss: 0.1748 - val_mae: 0.1748\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1342 - mae: 0.1342 - val_loss: 0.0706 - val_mae: 0.0706\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0351 - mae: 0.0351 - val_loss: 0.0264 - val_mae: 0.0264\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0236 - mae: 0.0236 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 72/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 73/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 74/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 75/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 76/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 77/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 78/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 79/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 80/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 81/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 82/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 83/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 84/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 85/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 86/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 87/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 88/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 89/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 90/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 91/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 92/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 93/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 94/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 95/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 96/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 97/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 98/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 99/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 100/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 101/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 102/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 103/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 104/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 105/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 106/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 107/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 108/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 109/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 110/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 111/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 112/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 113/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 114/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 115/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 116/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 117/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 118/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 119/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 120/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 121/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 122/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 123/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 124/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 125/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 126/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 127/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 128/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 129/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 130/150\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 131/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 132/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 133/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 134/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 135/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 136/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 137/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 138/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 139/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 140/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 141/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 142/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 143/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 144/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 145/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 146/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 147/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 148/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 149/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 150/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0094 - val_mae: 0.0094\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u8_lr1_e150 = simple_model_icbp_n1_h1_u8_lr1_e150.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=150,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 29.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 2s 7ms/step - loss: 0.2476 - mae: 0.2476 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0878 - mae: 0.0878 - val_loss: 0.0230 - val_mae: 0.0230\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0075 - val_mae: 0.0075\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0079 - val_mae: 0.0079\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0079 - mae: 0.007 - 0s 6ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0078 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0081 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0081 - val_mae: 0.0081\n"
     ]
    }
   ],
   "source": [
    "smod_history_icbp_n1_h1_u8_lr1_e200 = simple_model_icbp_n1_h1_u8_lr1_e200.fit(X_train_icbp_1, y_train_icbp_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=200,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 37.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_icbp_n1_h1_u8_lr1_e100 = simple_model_icbp_n1_h1_u8_lr1_e100.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h1_u8_lr1_e150 = simple_model_icbp_n1_h1_u8_lr1_e150.predict(X_test_icbp_1)\n",
    "preds_icbp_n1_h1_u8_lr1_e200 = simple_model_icbp_n1_h1_u8_lr1_e200.predict(X_test_icbp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n",
      "mae score icbp_n1_h1_u8_lr1_e100: 0.011829416279720813\n",
      "r2 score icbp_n1_h1_u8_lr1_e100: 0.9969111260811065\n",
      "mape score icbp_n1_h1_u8_lr1_e100: 0.05391095328713023\n",
      "rmse score icbp_n1_h1_u8_lr1_e100: 0.015309465075169035\n",
      "epoch 150\n",
      "mae score icbp_n1_h1_u8_lr1_e150: 0.00863103057045081\n",
      "r2 score icbp_n1_h1_u8_lr1_e150: 0.9980756743822062\n",
      "mape score icbp_n1_h1_u8_lr1_e150: 0.044077354469535264\n",
      "rmse score icbp_n1_h1_u8_lr1_e150: 0.012175448247557782\n",
      "epoch 200\n",
      "mae score icbp_n1_h1_u8_lr1_e200: 0.007548246517585376\n",
      "r2 score icbp_n1_h1_u8_lr1_e200: 0.9984169773841658\n",
      "mape score icbp_n1_h1_u8_lr1_e200: 0.02786548272161317\n",
      "rmse score icbp_n1_h1_u8_lr1_e200: 0.011187546983256878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"epoch 100\")\n",
    "print(\"mae score icbp_n1_h1_u8_lr1_e100: \"+str(mean_absolute_error(preds_icbp_n1_h1_u8_lr1_e100, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u8_lr1_e100: \"+str(r2_score(preds_icbp_n1_h1_u8_lr1_e100, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u8_lr1_e100: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr1_e100, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u8_lr1_e100: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr1_e100, y_test_icbp_1))))\n",
    "\n",
    "print(\"epoch 150\")\n",
    "print(\"mae score icbp_n1_h1_u8_lr1_e150: \"+str(mean_absolute_error(preds_icbp_n1_h1_u8_lr1_e150, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u8_lr1_e150: \"+str(r2_score(preds_icbp_n1_h1_u8_lr1_e150, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u8_lr1_e150: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr1_e150, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u8_lr1_e150: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr1_e150, y_test_icbp_1))))\n",
    "\n",
    "print(\"epoch 200\")\n",
    "print(\"mae score icbp_n1_h1_u8_lr1_e200: \"+str(mean_absolute_error(preds_icbp_n1_h1_u8_lr1_e200, y_test_icbp_1)))\n",
    "print(\"r2 score icbp_n1_h1_u8_lr1_e200: \"+str(r2_score(preds_icbp_n1_h1_u8_lr1_e200, y_test_icbp_1)))\n",
    "print(\"mape score icbp_n1_h1_u8_lr1_e200: \"+str(mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr1_e200, y_test_icbp_1)))\n",
    "print(\"rmse score icbp_n1_h1_u8_lr1_e200: \"+str(np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr1_e200, y_test_icbp_1))))\n",
    "\n",
    "mae_icbp_hl_u_lr_ep = {'model_n1_h1_u8_lr1_e100':mean_absolute_error(preds_icbp_n1_h1_u8_lr1_e100, y_test_icbp_1),'model_n1_h1_u8_lr1_e150':mean_absolute_error(preds_icbp_n1_h1_u8_lr1_e150, y_test_icbp_1),'model_n1_h1_u8_lr1_e200':mean_absolute_error(preds_icbp_n1_h1_u8_lr1_e200, y_test_icbp_1)}\n",
    "\n",
    "mape_icbp_hl_u_lr_ep = {'model_n1_h1_u8_lr1_e100':mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr1_e100, y_test_icbp_1),'model_n1_h1_u8_lr1_e150':mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr1_e150, y_test_icbp_1),'model_n1_h1_u8_lr1_e200':mean_absolute_percentage_error(preds_icbp_n1_h1_u8_lr1_e200, y_test_icbp_1)}\n",
    "\n",
    "rmse_icbp_hl_u_lr_ep = {'model_n1_h1_u8_lr1_e100':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr1_e100, y_test_icbp_1)),'model_n1_h1_u8_lr1_e150':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr1_e150, y_test_icbp_1)),'model_n1_h1_u8_lr1_e200':np.sqrt(mean_squared_error(preds_icbp_n1_h1_u8_lr1_e200, y_test_icbp_1))}\n",
    "\n",
    "r2_icbp_hl_u_lr_ep = {'model_n1_h1_u8_lr1_e100':r2_score(preds_icbp_n1_h1_u8_lr1_e100, y_test_icbp_1),'model_n1_h1_u8_lr1_e150':r2_score(preds_icbp_n1_h1_u8_lr1_e150, y_test_icbp_1),'model_n1_h1_u8_lr1_e200':r2_score(preds_icbp_n1_h1_u8_lr1_e200, y_test_icbp_1)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 100\n",
    "# mae score icbp_n1_h1_u8_lr1_e100: 0.011829416279720813\n",
    "# r2 score icbp_n1_h1_u8_lr1_e100: 0.9969111260811065\n",
    "# mape score icbp_n1_h1_u8_lr1_e100: 0.05391095328713023\n",
    "# rmse score icbp_n1_h1_u8_lr1_e100: 0.015309465075169035\n",
    "# epoch 150\n",
    "# mae score icbp_n1_h1_u8_lr1_e150: 0.00863103057045081\n",
    "# r2 score icbp_n1_h1_u8_lr1_e150: 0.9980756743822062\n",
    "# mape score icbp_n1_h1_u8_lr1_e150: 0.044077354469535264\n",
    "# rmse score icbp_n1_h1_u8_lr1_e150: 0.012175448247557782\n",
    "# epoch 200\n",
    "# mae score icbp_n1_h1_u8_lr1_e200: 0.007548246517585376\n",
    "# r2 score icbp_n1_h1_u8_lr1_e200: 0.9984169773841658\n",
    "# mape score icbp_n1_h1_u8_lr1_e200: 0.02786548272161317\n",
    "# rmse score icbp_n1_h1_u8_lr1_e200: 0.011187546983256878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n1_h1_u8_lr1_e200': 0.007548246517585376, 'model_n1_h1_u8_lr1_e150': 0.00863103057045081, 'model_n1_h1_u8_lr1_e100': 0.011829416279720813}\n",
      "sorted rmse\n",
      "{'model_n1_h1_u8_lr1_e200': 0.011187546983256878, 'model_n1_h1_u8_lr1_e150': 0.012175448247557782, 'model_n1_h1_u8_lr1_e100': 0.015309465075169035}\n",
      "sorted mape\n",
      "{'model_n1_h1_u8_lr1_e200': 0.02786548272161317, 'model_n1_h1_u8_lr1_e150': 0.044077354469535264, 'model_n1_h1_u8_lr1_e100': 0.05391095328713023}\n",
      "sorted r2\n",
      "{'model_n1_h1_u8_lr1_e200': 0.9984169773841658, 'model_n1_h1_u8_lr1_e150': 0.9980756743822062, 'model_n1_h1_u8_lr1_e100': 0.9969111260811065}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_icbp_hl_u_lr_ep_sorted = dict(sorted(mae_icbp_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mae_icbp_hl_u_lr_ep_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_icbp_hl_u_lr_ep_sorted = dict(sorted(rmse_icbp_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(rmse_icbp_hl_u_lr_ep_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_icbp_hl_u_lr_ep_sorted = dict(sorted(mape_icbp_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mape_icbp_hl_u_lr_ep_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_icbp_hl_u_lr_ep_sorted = dict(sorted(r2_icbp_hl_u_lr_ep.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_icbp_hl_u_lr_ep_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n1_h1_u8_lr1_e200': 0.007548246517585376, 'model_n1_h1_u8_lr1_e150': 0.00863103057045081, 'model_n1_h1_u8_lr1_e100': 0.011829416279720813}\n",
    "# sorted rmse\n",
    "# {'model_n1_h1_u8_lr1_e200': 0.011187546983256878, 'model_n1_h1_u8_lr1_e150': 0.012175448247557782, 'model_n1_h1_u8_lr1_e100': 0.015309465075169035}\n",
    "# sorted mape\n",
    "# {'model_n1_h1_u8_lr1_e200': 0.02786548272161317, 'model_n1_h1_u8_lr1_e150': 0.044077354469535264, 'model_n1_h1_u8_lr1_e100': 0.05391095328713023}\n",
    "# sorted r2\n",
    "# {'model_n1_h1_u8_lr1_e200': 0.9984169773841658, 'model_n1_h1_u8_lr1_e150': 0.9980756743822062, 'model_n1_h1_u8_lr1_e100': 0.9969111260811065}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jsmr = df_jsmr.reset_index(drop=True)\n",
    "arr_jsmr = df_jsmr.to_numpy()\n",
    "flat_jsmr = arr_jsmr.flatten()\n",
    "jsmr_X_1, jsmr_y_1 = split_sequence(flat_jsmr, n_steps_1)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_jsmr_1, X_test_jsmr_1, y_train_jsmr_1, y_test_jsmr_1 = train_test_split(jsmr_X_1, jsmr_y_1, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_jsmr_1 = X_train_jsmr_1.reshape(X_train_jsmr_1.shape[0],X_train_jsmr_1.shape[1],n_features)\n",
    "X_test_jsmr_1 = X_test_jsmr_1.reshape(X_test_jsmr_1.shape[0],X_test_jsmr_1.shape[1],n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_57 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e100 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e100.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e100.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_58 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e150 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e150.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e150.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_59 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e200 = Sequential([\n",
    "  LSTM(8, activation='relu',input_shape=(n_steps_1, n_features)),\n",
    "  Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e200.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae'],\n",
    ")\n",
    "\n",
    "simple_model_jsmr_n1_h1_u8_lr1_e200.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 7ms/step - loss: 0.2797 - mae: 0.2797 - val_loss: 0.1137 - val_mae: 0.1137\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0940 - mae: 0.0940 - val_loss: 0.0536 - val_mae: 0.0536\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.0317 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0219 - mae: 0.0219 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0192 - val_mae: 0.0192\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u8_lr1_e100 = simple_model_jsmr_n1_h1_u8_lr1_e100.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.2624 - mae: 0.2624 - val_loss: 0.1048 - val_mae: 0.1048\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0841 - mae: 0.0841 - val_loss: 0.0510 - val_mae: 0.0510\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 72/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 73/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 74/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 75/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 76/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 77/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 78/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 79/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 80/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 81/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 82/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 83/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 84/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 85/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 86/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 87/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 88/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 89/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 90/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 91/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 92/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 93/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 94/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 95/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 96/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 97/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 98/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 99/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 100/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 101/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 102/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 103/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 104/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 105/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 106/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 107/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 108/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 109/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 110/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 111/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 112/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 113/150\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 114/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 115/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 116/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 117/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 118/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 119/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 120/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 121/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 122/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 123/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 124/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 125/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 126/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 127/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 128/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 129/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 130/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 131/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 132/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 133/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 134/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 135/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 136/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 137/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 138/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 139/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 140/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 141/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 142/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 143/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 144/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 145/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 146/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 147/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 148/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 149/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 150/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0126 - val_mae: 0.0126\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u8_lr1_e150 = simple_model_jsmr_n1_h1_u8_lr1_e150.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=150,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 29.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 2s 11ms/step - loss: 0.2544 - mae: 0.2544 - val_loss: 0.1082 - val_mae: 0.1082\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0895 - mae: 0.0895 - val_loss: 0.0559 - val_mae: 0.0559\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.0338 - val_loss: 0.0212 - val_mae: 0.0212\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0219 - val_mae: 0.0219\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0139 - val_mae: 0.0139\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0132 - mae: 0.013 - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0239 - val_mae: 0.0239\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0126 - val_mae: 0.0126\n"
     ]
    }
   ],
   "source": [
    "smod_history_jsmr_n1_h1_u8_lr1_e200 = simple_model_jsmr_n1_h1_u8_lr1_e200.fit(X_train_jsmr_1, y_train_jsmr_1,\n",
    "          validation_split=0.2,\n",
    "          epochs=200,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "#time 41.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_jsmr_n1_h1_u8_lr1_e100 = simple_model_jsmr_n1_h1_u8_lr1_e100.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h1_u8_lr1_e150 = simple_model_jsmr_n1_h1_u8_lr1_e150.predict(X_test_jsmr_1)\n",
    "preds_jsmr_n1_h1_u8_lr1_e200 = simple_model_jsmr_n1_h1_u8_lr1_e200.predict(X_test_jsmr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n",
      "mae score jsmr_n1_h1_u8_lr1_e100: 0.018119861212689825\n",
      "r2 score jsmr_n1_h1_u8_lr1_e100: 0.9894752418624992\n",
      "mape score jsmr_n1_h1_u8_lr1_e100: 0.043781076594289176\n",
      "rmse score jsmr_n1_h1_u8_lr1_e100: 0.022323166047446056\n",
      "epoch 150\n",
      "mae score jsmr_n1_h1_u8_lr1_e150: 0.012107913609979913\n",
      "r2 score jsmr_n1_h1_u8_lr1_e150: 0.9937337140250488\n",
      "mape score jsmr_n1_h1_u8_lr1_e150: 0.03172246383620455\n",
      "rmse score jsmr_n1_h1_u8_lr1_e150: 0.016932659020940932\n",
      "epoch 200\n",
      "mae score jsmr_n1_h1_u8_lr1_e200: 0.012089393602446269\n",
      "r2 score jsmr_n1_h1_u8_lr1_e200: 0.9937688105739413\n",
      "mape score jsmr_n1_h1_u8_lr1_e200: 0.029906221177962093\n",
      "rmse score jsmr_n1_h1_u8_lr1_e200: 0.016973096009955235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print(\"epoch 100\")\n",
    "print(\"mae score jsmr_n1_h1_u8_lr1_e100: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u8_lr1_e100, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u8_lr1_e100: \"+str(r2_score(preds_jsmr_n1_h1_u8_lr1_e100, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u8_lr1_e100: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr1_e100, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u8_lr1_e100: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr1_e100, y_test_jsmr_1))))\n",
    "\n",
    "print(\"epoch 150\")\n",
    "print(\"mae score jsmr_n1_h1_u8_lr1_e150: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u8_lr1_e150, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u8_lr1_e150: \"+str(r2_score(preds_jsmr_n1_h1_u8_lr1_e150, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u8_lr1_e150: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr1_e150, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u8_lr1_e150: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr1_e150, y_test_jsmr_1))))\n",
    "\n",
    "print(\"epoch 200\")\n",
    "print(\"mae score jsmr_n1_h1_u8_lr1_e200: \"+str(mean_absolute_error(preds_jsmr_n1_h1_u8_lr1_e200, y_test_jsmr_1)))\n",
    "print(\"r2 score jsmr_n1_h1_u8_lr1_e200: \"+str(r2_score(preds_jsmr_n1_h1_u8_lr1_e200, y_test_jsmr_1)))\n",
    "print(\"mape score jsmr_n1_h1_u8_lr1_e200: \"+str(mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr1_e200, y_test_jsmr_1)))\n",
    "print(\"rmse score jsmr_n1_h1_u8_lr1_e200: \"+str(np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr1_e200, y_test_jsmr_1))))\n",
    "\n",
    "mae_jsmr_hl_u_lr_ep = {'model_n1_h1_u8_lr1_e100':mean_absolute_error(preds_jsmr_n1_h1_u8_lr1_e100, y_test_jsmr_1),'model_n1_h1_u8_lr1_e150':mean_absolute_error(preds_jsmr_n1_h1_u8_lr1_e150, y_test_jsmr_1),'model_n1_h1_u8_lr1_e200':mean_absolute_error(preds_jsmr_n1_h1_u8_lr1_e200, y_test_jsmr_1)}\n",
    "\n",
    "mape_jsmr_hl_u_lr_ep = {'model_n1_h1_u8_lr1_e100':mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr1_e100, y_test_jsmr_1),'model_n1_h1_u8_lr1_e150':mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr1_e150, y_test_jsmr_1),'model_n1_h1_u8_lr1_e200':mean_absolute_percentage_error(preds_jsmr_n1_h1_u8_lr1_e200, y_test_jsmr_1)}\n",
    "\n",
    "rmse_jsmr_hl_u_lr_ep = {'model_n1_h1_u8_lr1_e100':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr1_e100, y_test_jsmr_1)),'model_n1_h1_u8_lr1_e150':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr1_e150, y_test_jsmr_1)),'model_n1_h1_u8_lr1_e200':np.sqrt(mean_squared_error(preds_jsmr_n1_h1_u8_lr1_e200, y_test_jsmr_1))}\n",
    "\n",
    "r2_jsmr_hl_u_lr_ep = {'model_n1_h1_u8_lr1_e100':r2_score(preds_jsmr_n1_h1_u8_lr1_e100, y_test_jsmr_1),'model_n1_h1_u8_lr1_e150':r2_score(preds_jsmr_n1_h1_u8_lr1_e150, y_test_jsmr_1),'model_n1_h1_u8_lr1_e200':r2_score(preds_jsmr_n1_h1_u8_lr1_e200, y_test_jsmr_1)} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 100\n",
    "# mae score jsmr_n1_h1_u8_lr1_e100: 0.018119861212689825\n",
    "# r2 score jsmr_n1_h1_u8_lr1_e100: 0.9894752418624992\n",
    "# mape score jsmr_n1_h1_u8_lr1_e100: 0.043781076594289176\n",
    "# rmse score jsmr_n1_h1_u8_lr1_e100: 0.022323166047446056\n",
    "# epoch 150\n",
    "# mae score jsmr_n1_h1_u8_lr1_e150: 0.012107913609979913\n",
    "# r2 score jsmr_n1_h1_u8_lr1_e150: 0.9937337140250488\n",
    "# mape score jsmr_n1_h1_u8_lr1_e150: 0.03172246383620455\n",
    "# rmse score jsmr_n1_h1_u8_lr1_e150: 0.016932659020940932\n",
    "# epoch 200\n",
    "# mae score jsmr_n1_h1_u8_lr1_e200: 0.012089393602446269\n",
    "# r2 score jsmr_n1_h1_u8_lr1_e200: 0.9937688105739413\n",
    "# mape score jsmr_n1_h1_u8_lr1_e200: 0.029906221177962093\n",
    "# rmse score jsmr_n1_h1_u8_lr1_e200: 0.016973096009955235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_n1_h1_u8_lr1_e200': 0.012089393602446269, 'model_n1_h1_u8_lr1_e150': 0.012107913609979913, 'model_n1_h1_u8_lr1_e100': 0.018119861212689825}\n",
      "sorted rmse\n",
      "{'model_n1_h1_u8_lr1_e150': 0.016932659020940932, 'model_n1_h1_u8_lr1_e200': 0.016973096009955235, 'model_n1_h1_u8_lr1_e100': 0.022323166047446056}\n",
      "sorted mape\n",
      "{'model_n1_h1_u8_lr1_e200': 0.029906221177962093, 'model_n1_h1_u8_lr1_e150': 0.03172246383620455, 'model_n1_h1_u8_lr1_e100': 0.043781076594289176}\n",
      "sorted r2\n",
      "{'model_n1_h1_u8_lr1_e200': 0.9937688105739413, 'model_n1_h1_u8_lr1_e150': 0.9937337140250488, 'model_n1_h1_u8_lr1_e100': 0.9894752418624992}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_jsmr_hl_u_lr_ep_sorted = dict(sorted(mae_jsmr_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mae_jsmr_hl_u_lr_ep_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_jsmr_hl_u_lr_ep_sorted = dict(sorted(rmse_jsmr_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(rmse_jsmr_hl_u_lr_ep_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_jsmr_hl_u_lr_ep_sorted = dict(sorted(mape_jsmr_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mape_jsmr_hl_u_lr_ep_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_jsmr_hl_u_lr_ep_sorted = dict(sorted(r2_jsmr_hl_u_lr_ep.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_jsmr_hl_u_lr_ep_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted mae\n",
    "# {'model_n1_h1_u8_lr1_e200': 0.012089393602446269, 'model_n1_h1_u8_lr1_e150': 0.012107913609979913, 'model_n1_h1_u8_lr1_e100': 0.018119861212689825}\n",
    "# sorted rmse\n",
    "# {'model_n1_h1_u8_lr1_e150': 0.016932659020940932, 'model_n1_h1_u8_lr1_e200': 0.016973096009955235, 'model_n1_h1_u8_lr1_e100': 0.022323166047446056}\n",
    "# sorted mape\n",
    "# {'model_n1_h1_u8_lr1_e200': 0.029906221177962093, 'model_n1_h1_u8_lr1_e150': 0.03172246383620455, 'model_n1_h1_u8_lr1_e100': 0.043781076594289176}\n",
    "# sorted r2\n",
    "# {'model_n1_h1_u8_lr1_e200': 0.9937688105739413, 'model_n1_h1_u8_lr1_e150': 0.9937337140250488, 'model_n1_h1_u8_lr1_e100': 0.9894752418624992}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KESIMPULAN HASIL\n",
    "Dari hasil tuning parameter epoch diatas dapat dilihat bahwa tiga saham bekerja paling baik ketika epochnya ditambah dalam kasus ini epooch terbesar yaitu sebanyak 200, data saham tersebut ialah ANTM,ICBP,JSMR sedangkan untuk data saham ASII ketika di uji beberapa kali menunjukan epoch 150 selalu memberikan hasil yang baik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUning batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data and normalize data\n",
    "df_antm = normalize_data(data_close.antm,'antm')\n",
    "#reset index\n",
    "df_antm = reset_index_data(df_antm)\n",
    "#data to supervised\n",
    "antm_X, antm_y = split_sequence(df_antm, 2)\n",
    "#split to train and test\n",
    "X_train_antm, X_test_antm, y_train_antm, y_test_antm = train_test_split(antm_X, antm_y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_antm = reshape_data(X_train_antm,1)\n",
    "X_test_antm = reshape_data(X_test_antm,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 8)                 320       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 2s 8ms/step - loss: 0.0529 - mae: 0.0529 - val_loss: 0.0412 - val_mae: 0.0412\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0270 - val_mae: 0.0270\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0203 - mae: 0.020 - 0s 3ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0238 - val_mae: 0.0238\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0229 - val_mae: 0.0229\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0255 - val_mae: 0.0255\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0216 - val_mae: 0.0216\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0263 - val_mae: 0.0263\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0263 - val_mae: 0.0263\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0130 - mae: 0.013 - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0259 - val_mae: 0.0259\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0265 - val_mae: 0.0265\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0127 - val_mae: 0.0127\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0249 - val_mae: 0.0249\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0291 - val_mae: 0.0291\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0090 - mae: 0.009 - 0s 4ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0098 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0238 - val_mae: 0.0238\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0258 - val_mae: 0.0258\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0346 - val_mae: 0.0346\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0258 - val_mae: 0.0258\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0122 - val_mae: 0.0122\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0129 - val_mae: 0.0129\n"
     ]
    }
   ],
   "source": [
    "cfg_antm = [8,'relu',2,1,0.1,32,200]\n",
    "model_antm_bs32,history_antm_model  = train_lstm(X_train_antm,y_train_antm,cfg_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "105/105 [==============================] - 2s 5ms/step - loss: 0.0314 - mae: 0.0314 - val_loss: 0.0318 - val_mae: 0.0318\n",
      "Epoch 2/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 3/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 4/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 5/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0329 - val_mae: 0.0329\n",
      "Epoch 6/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 7/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0412 - val_mae: 0.0412\n",
      "Epoch 8/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 9/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 10/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0252 - val_mae: 0.0252\n",
      "Epoch 11/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 12/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 13/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 14/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0453 - val_mae: 0.0453\n",
      "Epoch 15/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 16/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 17/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 18/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 19/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 20/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 21/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 22/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 23/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 24/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 25/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 26/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0300 - val_mae: 0.0300\n",
      "Epoch 27/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 28/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 29/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 30/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 31/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 32/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 33/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 34/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 35/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 36/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 37/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 38/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 39/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 40/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 41/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 42/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0316 - val_mae: 0.0316\n",
      "Epoch 43/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0284 - val_mae: 0.0284\n",
      "Epoch 44/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 45/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0103 - val_mae: 0.0103\n",
      "Epoch 46/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 47/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 48/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 49/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 50/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 51/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 52/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 53/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 54/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 55/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 56/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 57/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 58/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0128 - val_mae: 0.0128\n",
      "Epoch 59/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 60/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 61/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 62/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 63/200\n",
      "105/105 [==============================] - 1s 6ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 64/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 65/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 66/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 67/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 68/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 69/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 70/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 71/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 72/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 73/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0105 - val_mae: 0.0105\n",
      "Epoch 74/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0283 - val_mae: 0.0283\n",
      "Epoch 75/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 76/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 77/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0382 - val_mae: 0.0382\n",
      "Epoch 78/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0255 - val_mae: 0.0255\n",
      "Epoch 79/200\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0115 - val_mae: 0.0115\n",
      "Epoch 80/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 81/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 82/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 83/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 84/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 85/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 86/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 87/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 88/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 89/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 90/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 91/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0248 - val_mae: 0.0248\n",
      "Epoch 92/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 93/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 94/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 95/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 96/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 97/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 98/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 99/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 100/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 101/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 102/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 103/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0306 - val_mae: 0.0306\n",
      "Epoch 104/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 105/200\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 106/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 107/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 108/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 109/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 110/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 111/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 112/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 113/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0091 - val_mae: 0.0091\n",
      "Epoch 114/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 115/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 116/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 117/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 118/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 119/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 120/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 121/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 122/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 123/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 124/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 125/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 126/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0078 - val_mae: 0.0078\n",
      "Epoch 127/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 128/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0261 - val_mae: 0.0261\n",
      "Epoch 129/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 130/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 131/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 132/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 133/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 134/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 135/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0305 - val_mae: 0.0305\n",
      "Epoch 136/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 137/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 138/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 139/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 140/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 141/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 142/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 143/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 144/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 145/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0082 - val_mae: 0.0082\n",
      "Epoch 146/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 147/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 148/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 149/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 150/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 151/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 152/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 153/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 154/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 155/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0134 - val_mae: 0.0134\n",
      "Epoch 156/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0116 - val_mae: 0.0116\n",
      "Epoch 157/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 158/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0093 - val_mae: 0.0093\n",
      "Epoch 159/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 160/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 161/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0276 - val_mae: 0.0276\n",
      "Epoch 162/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 163/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 164/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 165/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0144 - val_mae: 0.0144\n",
      "Epoch 166/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0133 - val_mae: 0.0133\n",
      "Epoch 167/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0143 - val_mae: 0.0143\n",
      "Epoch 168/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 169/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 170/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 171/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 172/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 173/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 174/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0115 - val_loss: 0.0086 - val_mae: 0.0086\n",
      "Epoch 175/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0130 - val_mae: 0.0130\n",
      "Epoch 176/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 177/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 178/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 179/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 180/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 181/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0128 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 182/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 183/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0116 - val_loss: 0.0077 - val_mae: 0.0077\n",
      "Epoch 184/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 185/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0140 - val_mae: 0.0140\n",
      "Epoch 186/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 187/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 188/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 189/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 190/200\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0123 - val_mae: 0.0123\n",
      "Epoch 191/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0206 - val_mae: 0.0206\n",
      "Epoch 192/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0255 - val_mae: 0.0255\n",
      "Epoch 193/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 194/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 195/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 196/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0125 - mae: 0.0125 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 197/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0113 - mae: 0.0113 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 198/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 199/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 200/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0156 - val_mae: 0.0156\n"
     ]
    }
   ],
   "source": [
    "cfg_antm = [8,'relu',2,1,0.1,16,200]\n",
    "model_antm_bs16,history_antm_model  = train_lstm(X_train_antm,y_train_antm,cfg_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "210/210 [==============================] - 2s 4ms/step - loss: 0.0320 - mae: 0.0320 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 2/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 3/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 4/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0207 - val_mae: 0.0207\n",
      "Epoch 5/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0305 - val_mae: 0.0305\n",
      "Epoch 6/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 7/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 8/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 9/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 10/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0141 - val_mae: 0.0141\n",
      "Epoch 11/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 12/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 13/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0347 - val_mae: 0.0347\n",
      "Epoch 14/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 15/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 16/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 17/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 18/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 19/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0290 - val_mae: 0.0290\n",
      "Epoch 20/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 21/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0345 - val_mae: 0.0345\n",
      "Epoch 22/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 23/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 24/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 25/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 26/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0404 - val_mae: 0.0404\n",
      "Epoch 27/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 28/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0517 - val_mae: 0.0517\n",
      "Epoch 29/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 30/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 31/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0238 - val_mae: 0.0238\n",
      "Epoch 32/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0246 - val_mae: 0.0246\n",
      "Epoch 33/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0203 - mae: 0.0203 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 34/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 35/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0528 - val_mae: 0.0528\n",
      "Epoch 36/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 37/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0099 - val_mae: 0.0099\n",
      "Epoch 38/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 39/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 40/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 41/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 42/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0371 - val_mae: 0.0371\n",
      "Epoch 43/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 44/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0097 - val_mae: 0.0097\n",
      "Epoch 45/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 46/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0102 - val_mae: 0.0102\n",
      "Epoch 47/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 48/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0117 - val_mae: 0.0117\n",
      "Epoch 49/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0285 - val_mae: 0.0285\n",
      "Epoch 50/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 51/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0284 - val_mae: 0.0284\n",
      "Epoch 52/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 53/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 54/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 55/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 56/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0334 - val_mae: 0.0334\n",
      "Epoch 57/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 58/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 59/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 60/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 61/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0262 - val_mae: 0.0262\n",
      "Epoch 62/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 63/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0413 - val_mae: 0.0413\n",
      "Epoch 64/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 65/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 66/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0231 - val_mae: 0.0231\n",
      "Epoch 67/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 68/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0318 - mae: 0.0318 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 69/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0212 - val_mae: 0.0212\n",
      "Epoch 70/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0263 - val_mae: 0.0263\n",
      "Epoch 71/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0106 - val_mae: 0.0106TA: 0s - loss: 0.0133 - mae: 0.\n",
      "Epoch 72/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 73/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0135 - val_mae: 0.0135\n",
      "Epoch 74/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 75/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 76/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0087 - val_mae: 0.0087\n",
      "Epoch 77/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0282 - val_mae: 0.0282\n",
      "Epoch 78/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0109 - val_mae: 0.0109\n",
      "Epoch 79/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 80/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 81/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0081 - val_mae: 0.0081\n",
      "Epoch 82/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0337 - val_mae: 0.0337\n",
      "Epoch 83/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 84/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0108 - val_mae: 0.0108\n",
      "Epoch 85/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0229 - mae: 0.0229 - val_loss: 0.0286 - val_mae: 0.0286\n",
      "Epoch 86/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 87/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 88/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 89/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 90/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 91/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 92/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 93/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 94/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0251 - val_mae: 0.0251\n",
      "Epoch 95/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0112 - val_mae: 0.0112\n",
      "Epoch 96/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 97/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 98/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0106 - val_mae: 0.0106\n",
      "Epoch 99/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.0255 - val_mae: 0.0255\n",
      "Epoch 100/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 101/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 102/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 103/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 104/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 105/200\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0188 - mae: 0.018 - 1s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 106/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0247 - val_mae: 0.0247\n",
      "Epoch 107/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0114 - val_mae: 0.0114\n",
      "Epoch 108/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 109/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0111 - val_mae: 0.0111\n",
      "Epoch 110/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 111/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0327 - val_mae: 0.0327\n",
      "Epoch 112/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0088 - val_mae: 0.0088\n",
      "Epoch 113/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 114/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 115/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0096 - val_mae: 0.0096\n",
      "Epoch 116/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 117/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 118/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 119/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0307 - val_mae: 0.0307\n",
      "Epoch 120/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0085 - val_mae: 0.0085\n",
      "Epoch 121/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 122/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0129 - val_mae: 0.0129\n",
      "Epoch 123/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 124/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 125/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 126/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 127/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0359 - val_mae: 0.0359\n",
      "Epoch 128/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0301 - val_mae: 0.0301\n",
      "Epoch 129/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 130/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 131/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0094 - val_mae: 0.0094\n",
      "Epoch 132/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 133/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0242 - val_mae: 0.0242\n",
      "Epoch 134/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 135/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 136/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 137/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 138/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0353 - val_mae: 0.0353\n",
      "Epoch 139/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0110 - val_mae: 0.0110\n",
      "Epoch 140/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0297 - val_mae: 0.0297\n",
      "Epoch 141/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 142/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0182 - val_mae: 0.0182\n",
      "Epoch 143/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0125 - val_mae: 0.0125\n",
      "Epoch 144/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0101 - val_mae: 0.0101\n",
      "Epoch 145/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0121 - val_mae: 0.0121\n",
      "Epoch 146/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.0387 - val_mae: 0.0387\n",
      "Epoch 147/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0124 - val_mae: 0.0124\n",
      "Epoch 148/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0090 - val_mae: 0.0090\n",
      "Epoch 149/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0236 - val_mae: 0.0236\n",
      "Epoch 150/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0301 - val_mae: 0.0301\n",
      "Epoch 151/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0118 - val_mae: 0.0118\n",
      "Epoch 152/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 153/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 154/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 155/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0131 - val_mae: 0.0131\n",
      "Epoch 156/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 157/200\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0200 - val_mae: 0.0200\n",
      "Epoch 158/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 159/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 160/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 161/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 162/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0131 - mae: 0.0131 - val_loss: 0.0239 - val_mae: 0.0239\n",
      "Epoch 163/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 164/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 165/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0138 - val_mae: 0.0138\n",
      "Epoch 166/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0212 - val_mae: 0.0212\n",
      "Epoch 167/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 168/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 169/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 170/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0139 - mae: 0.0139 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 171/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0084 - val_mae: 0.0084\n",
      "Epoch 172/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 173/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 174/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0098 - val_mae: 0.0098\n",
      "Epoch 175/200\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.0124 - mae: 0.0124 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 176/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0142 - val_mae: 0.0142\n",
      "Epoch 177/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0119 - val_mae: 0.0119\n",
      "Epoch 178/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0220 - val_mae: 0.0220\n",
      "Epoch 179/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.0120 - val_mae: 0.0120\n",
      "Epoch 180/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 181/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0100 - val_mae: 0.0100\n",
      "Epoch 182/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0133 - val_loss: 0.0076 - val_mae: 0.0076\n",
      "Epoch 183/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 184/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 185/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0145 - val_mae: 0.0145\n",
      "Epoch 186/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0104 - val_mae: 0.0104\n",
      "Epoch 187/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 188/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0149 - val_loss: 0.0107 - val_mae: 0.0107\n",
      "Epoch 189/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0203 - val_mae: 0.0203\n",
      "Epoch 190/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0089 - val_mae: 0.0089\n",
      "Epoch 191/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0240 - val_mae: 0.0240\n",
      "Epoch 192/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 193/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0145 - mae: 0.0145 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 194/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0209 - val_mae: 0.0209\n",
      "Epoch 195/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0134 - mae: 0.0134 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 196/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0136 - val_mae: 0.0136\n",
      "Epoch 197/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.0137 - val_mae: 0.0137\n",
      "Epoch 198/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 199/200\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0132 - val_mae: 0.0132\n",
      "Epoch 200/200\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.0127 - val_mae: 0.0127\n"
     ]
    }
   ],
   "source": [
    "cfg_antm = [8,'relu',2,1,0.1,8,200]\n",
    "model_antm_bs8,history_antm_model  = train_lstm(X_train_antm,y_train_antm,cfg_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriks score for antm\n",
      "mae score: 0.012488533145321043\n",
      "r2 score 0.9927547014825319\n",
      "mape score 0.06780591780945283\n",
      "rmse score 0.01666907824200452\n"
     ]
    }
   ],
   "source": [
    "preds_antm_bs32 = model_antm_bs32.predict(X_test_antm)\n",
    "matriks_evaluate(preds_antm_bs32,y_test_antm,'antm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n",
      "-12916762222769.19\n",
      "0.63\n",
      "0.21\n"
     ]
    }
   ],
   "source": [
    "pembulatan(0.14910318578612322,2)\n",
    "pembulatan(-12916762222769.193,2)\n",
    "pembulatan(0.6321739528965653,2)\n",
    "pembulatan(0.21421848154314144,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriks score for antm\n",
      "mae score: 0.01507653190057723\n",
      "r2 score 0.9916395348442628\n",
      "mape score 2.640310693804523\n",
      "rmse score 0.019064418329882173\n"
     ]
    }
   ],
   "source": [
    "preds_antm_bs16 = model_antm_bs16.predict(X_test_antm)\n",
    "matriks_evaluate(preds_antm_bs16,y_test_antm,'antm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.99\n",
      "0.08\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "pembulatan(0.012999653801640209,2)\n",
    "pembulatan(0.9919025455962707,2)\n",
    "pembulatan(0.07505881372311643,2)\n",
    "pembulatan(0.018099920968931704,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriks score for antm\n",
      "mae score: 0.01294259904090866\n",
      "r2 score 0.9926595925838604\n",
      "mape score 0.08227245690492796\n",
      "rmse score 0.018235288320124676\n"
     ]
    }
   ],
   "source": [
    "preds_antm_bs8 = model_antm_bs8.predict(X_test_antm)\n",
    "matriks_evaluate(preds_antm_bs8,y_test_antm,'antm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.99\n",
      "0.05\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "pembulatan(0.011365720854837554,2)\n",
    "pembulatan(0.9939515647082884,2)\n",
    "pembulatan(0.053395620704576,2)\n",
    "pembulatan(0.015886105416762518,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_antm_hl_u_lr_ep = {'model_bs32':mean_absolute_error(preds_antm_bs32, y_test_antm),'model_bs16':mean_absolute_error(preds_antm_bs16, y_test_antm),'model_bs8':mean_absolute_error(preds_antm_bs8, y_test_antm)}\n",
    "\n",
    "mape_antm_hl_u_lr_ep = {'model_bs32':mean_absolute_percentage_error(preds_antm_bs32, y_test_antm),'model_bs16':mean_absolute_percentage_error(preds_antm_bs16, y_test_antm),'model_bs8':mean_absolute_percentage_error(preds_antm_bs8, y_test_antm)}\n",
    "\n",
    "rmse_antm_hl_u_lr_ep = {'model_bs32':np.sqrt(mean_squared_error(preds_antm_bs32, y_test_antm)),'model_bs16':np.sqrt(mean_squared_error(preds_antm_bs16, y_test_antm)),'model_bs8':np.sqrt(mean_squared_error(preds_antm_bs8, y_test_antm))}\n",
    "\n",
    "r2_antm_hl_u_lr_ep = {'model_bs32':r2_score(preds_antm_bs32, y_test_antm),'model_bs16':r2_score(preds_antm_bs16, y_test_antm),'model_bs8':r2_score(preds_antm_bs8, y_test_antm)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted mae\n",
      "{'model_bs32': 0.012488533145321043, 'model_bs8': 0.01294259904090866, 'model_bs16': 0.01507653190057723}\n",
      "sorted rmse\n",
      "{'model_bs32': 0.01666907824200452, 'model_bs8': 0.018235288320124676, 'model_bs16': 0.019064418329882173}\n",
      "sorted mape\n",
      "{'model_bs32': 0.06780591780945283, 'model_bs8': 0.08227245690492796, 'model_bs16': 2.640310693804523}\n",
      "sorted r2\n",
      "{'model_bs32': 0.9927547014825319, 'model_bs8': 0.9926595925838604, 'model_bs16': 0.9916395348442628}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_antm_hl_u_lr_ep_sorted = dict(sorted(mae_antm_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mae_antm_hl_u_lr_ep_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_antm_hl_u_lr_ep_sorted = dict(sorted(rmse_antm_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(rmse_antm_hl_u_lr_ep_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_antm_hl_u_lr_ep_sorted = dict(sorted(mape_antm_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mape_antm_hl_u_lr_ep_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_antm_hl_u_lr_ep_sorted = dict(sorted(r2_antm_hl_u_lr_ep.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_antm_hl_u_lr_ep_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data and normalize data\n",
    "df_asii = normalize_data(data_close.asii,'asii')\n",
    "#reset index\n",
    "df_asii = reset_index_data(df_asii)\n",
    "#data to supervised\n",
    "asii_X, asii_y = split_sequence(df_asii, 3)\n",
    "#split to train and test\n",
    "X_train_asii, X_test_asii, y_train_asii, y_test_asii = train_test_split(asii_X, asii_y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_asii = reshape_data(X_train_asii,1)\n",
    "X_test_asii = reshape_data(X_test_asii,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "53/53 [==============================] - 2s 7ms/step - loss: 0.1378 - mae: 0.1378 - val_loss: 0.0371 - val_mae: 0.0371\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0204 - val_mae: 0.0204\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0293 - val_mae: 0.0293\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0229 - val_mae: 0.0229\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0218 - mae: 0.0218 - val_loss: 0.0264 - val_mae: 0.0264\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.0206 - val_loss: 0.0205 - val_mae: 0.0205\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0210 - val_mae: 0.0210\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0195 - val_loss: 0.0180 - val_mae: 0.0180\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0201 - val_mae: 0.0201\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0292 - val_mae: 0.0292\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0205 - mae: 0.0205 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0208 - val_mae: 0.0208\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0223 - val_mae: 0.0223\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0227 - val_mae: 0.0227\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0213 - val_mae: 0.0213\n",
      "Epoch 72/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 73/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 74/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 75/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 76/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 77/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 78/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 79/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 80/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 81/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0222 - val_mae: 0.0222\n",
      "Epoch 82/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 83/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 84/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 85/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 86/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 87/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 88/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 89/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 90/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 91/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 92/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 93/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 94/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 95/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 96/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 97/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 98/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 99/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 100/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0192 - val_mae: 0.0192\n",
      "Epoch 101/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 102/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 103/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 104/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 105/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 106/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 107/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 108/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 109/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 110/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 111/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 112/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 113/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 114/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 115/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 116/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 117/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 118/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 119/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 120/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 121/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 122/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 123/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0157 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 124/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 125/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 126/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 127/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 128/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 129/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 130/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 131/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 132/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 133/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 134/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 135/150\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.0154 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 136/150\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 137/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 138/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 139/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 140/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 141/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 142/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 143/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 144/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 145/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 146/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 147/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0146 - val_mae: 0.0146\n",
      "Epoch 148/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 149/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 150/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0159 - val_mae: 0.0159\n"
     ]
    }
   ],
   "source": [
    "cfg_asii = [32,'relu',3,1,0.01,32,150]\n",
    "model_asii_bs32,history_asii_model,  = train_lstm(X_train_asii,y_train_asii,cfg_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "105/105 [==============================] - 2s 7ms/step - loss: 0.0810 - mae: 0.0810 - val_loss: 0.0256 - val_mae: 0.0256\n",
      "Epoch 2/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0232 - val_mae: 0.0232\n",
      "Epoch 3/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 4/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 5/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 6/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0218 - mae: 0.0218 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 7/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 8/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0268 - val_mae: 0.0268\n",
      "Epoch 9/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0199 - val_mae: 0.0199\n",
      "Epoch 10/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 11/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 12/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0258 - val_mae: 0.0258\n",
      "Epoch 13/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 14/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 15/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 16/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0288 - val_mae: 0.0288\n",
      "Epoch 17/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 18/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 19/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 20/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 21/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 22/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 23/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 24/150\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 25/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0174 - val_mae: 0.0174\n",
      "Epoch 26/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 27/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 28/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 29/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 30/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0263 - val_mae: 0.0263\n",
      "Epoch 31/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 32/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 33/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 34/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 35/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 36/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 37/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 38/150\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0161 - val_mae: 0.0161\n",
      "Epoch 39/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 40/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 41/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185 - val_loss: 0.0224 - val_mae: 0.0224\n",
      "Epoch 42/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 43/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 44/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 45/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 46/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 47/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 48/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 49/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 50/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 51/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 52/150\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 53/150\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0228 - val_mae: 0.0228\n",
      "Epoch 54/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 55/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 56/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 57/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 58/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 59/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 60/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 61/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 62/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 63/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 64/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 65/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0217 - val_mae: 0.0217\n",
      "Epoch 66/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 67/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0190 - val_mae: 0.0190\n",
      "Epoch 68/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 69/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 70/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 71/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 72/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0286 - val_mae: 0.0286\n",
      "Epoch 73/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 74/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 75/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 76/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 77/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 78/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 79/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 80/150\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0221 - val_mae: 0.0221\n",
      "Epoch 81/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0181 - val_mae: 0.0181\n",
      "Epoch 82/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0169 - val_mae: 0.0169\n",
      "Epoch 83/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 84/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 85/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0202 - val_mae: 0.0202\n",
      "Epoch 86/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 87/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 88/150\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 89/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0226 - val_mae: 0.0226\n",
      "Epoch 90/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 91/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 92/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 93/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 94/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 95/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0166 - val_mae: 0.0166\n",
      "Epoch 96/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 97/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 98/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0171 - val_mae: 0.0171\n",
      "Epoch 99/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0170 - val_mae: 0.0170\n",
      "Epoch 100/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0195 - val_mae: 0.0195\n",
      "Epoch 101/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 102/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 103/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 104/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 105/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 106/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0218 - val_mae: 0.0218\n",
      "Epoch 107/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 108/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 109/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 110/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 111/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0211 - val_mae: 0.0211\n",
      "Epoch 112/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 113/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 114/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 115/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 116/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 117/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 118/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 119/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 120/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0160 - val_mae: 0.0160\n",
      "Epoch 121/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 122/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0159 - val_loss: 0.0188 - val_mae: 0.0188\n",
      "Epoch 123/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 124/150\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 125/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 126/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 127/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0167 - mae: 0.0167 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 128/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0197 - val_mae: 0.0197\n",
      "Epoch 129/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 130/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 131/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 132/150\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 133/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 134/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0162 - val_mae: 0.0162\n",
      "Epoch 135/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 136/150\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 137/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 138/150\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0187 - val_mae: 0.0187\n",
      "Epoch 139/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0149 - val_mae: 0.0149\n",
      "Epoch 140/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 141/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 142/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 143/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0214 - val_mae: 0.0214\n",
      "Epoch 144/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 145/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.0148 - val_mae: 0.0148\n",
      "Epoch 146/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 147/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.0156 - val_mae: 0.0156\n",
      "Epoch 148/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161 - val_loss: 0.0155 - val_mae: 0.0155\n",
      "Epoch 149/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 150/150\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.0152 - val_mae: 0.0152\n"
     ]
    }
   ],
   "source": [
    "cfg_asii = [32,'relu',3,1,0.01,16,150]\n",
    "model_asii_bs16,history_asii_model,  = train_lstm(X_train_asii,y_train_asii,cfg_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 32)                4352      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 3s 5ms/step - loss: 0.0662 - mae: 0.0662 - val_loss: 0.0290 - val_mae: 0.0290\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0269 - val_mae: 0.0269\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0248 - mae: 0.0248 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0210 - mae: 0.0210 - val_loss: 0.0173 - val_mae: 0.0173\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0194 - val_mae: 0.0194\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0459 - val_mae: 0.0459\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0212 - mae: 0.0212 - val_loss: 0.0183 - val_mae: 0.0183\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0172 - val_mae: 0.0172\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0193 - val_mae: 0.0193\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0191 - val_mae: 0.0191\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0179 - val_mae: 0.0179\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0198 - mae: 0.0198 - val_loss: 0.0189 - val_mae: 0.0189\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.0167 - val_mae: 0.0167\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0182 - mae: 0.0182 - val_loss: 0.0353 - val_mae: 0.0353\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0199 - mae: 0.0199 - val_loss: 0.0178 - val_mae: 0.0178\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0174 - mae: 0.0174 - val_loss: 0.0272 - val_mae: 0.0272\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0188 - mae: 0.0188 - val_loss: 0.0198 - val_mae: 0.0198\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0186 - mae: 0.0186 - val_loss: 0.0215 - val_mae: 0.0215\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0184 - mae: 0.0184 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0165 - val_mae: 0.0165\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.0196 - val_mae: 0.0196\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0152 - val_mae: 0.0152\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0180 - mae: 0.0180 - val_loss: 0.0158 - val_mae: 0.0158\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0157 - val_mae: 0.0157\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0234 - val_mae: 0.0234\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0190 - mae: 0.0190 - val_loss: 0.0177 - val_mae: 0.0177\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0168 - val_mae: 0.0168\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0171 - mae: 0.0171 - val_loss: 0.0175 - val_mae: 0.0175\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0189 - mae: 0.0189 - val_loss: 0.0163 - val_mae: 0.0163\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0186 - val_mae: 0.0186\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0202 - mae: 0.0202 - val_loss: 0.0164 - val_mae: 0.0164\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0181 - mae: 0.0181 - val_loss: 0.0176 - val_mae: 0.0176\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0170 - mae: 0.0170 - val_loss: 0.0151 - val_mae: 0.0151\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.0150 - val_mae: 0.0150\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0178 - mae: 0.0178 - val_loss: 0.0147 - val_mae: 0.0147\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0154 - val_mae: 0.0154\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.0185 - val_mae: 0.0185\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0184 - val_mae: 0.0184\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0175 - mae: 0.017 - 1s 3ms/step - loss: 0.0177 - mae: 0.0177 - val_loss: 0.0153 - val_mae: 0.0153\n",
      "Epoch 51/150\n",
      "194/210 [==========================>...] - ETA: 0s - loss: 0.0180 - mae: 0.0180"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32me:\\programming\\lstm\\LSTM_Pemodelan.ipynb Cell 40\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cfg_asii \u001b[39m=\u001b[39m [\u001b[39m32\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0.01\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m150\u001b[39m]\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_asii_bs8,history_asii_model,  \u001b[39m=\u001b[39m train_lstm(X_train_asii,y_train_asii,cfg_asii)\n",
      "\n",
      "\u001b[1;32me:\\programming\\lstm\\LSTM_Pemodelan.ipynb Cell 40\u001b[0m in \u001b[0;36mtrain_lstm\u001b[1;34m(X_train, y_train, config)\u001b[0m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model_vanila_lstm\u001b[39m.\u001b[39mcompile(\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mlearning_rate),\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m'\u001b[39m,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m],\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model_vanila_lstm\u001b[39m.\u001b[39msummary()\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m history_vanila_lstm \u001b[39m=\u001b[39m model_vanila_lstm\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m       epochs\u001b[39m=\u001b[39;49mepochs,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m       shuffle \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/programming/lstm/LSTM_Pemodelan.ipynb#X54sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model_vanila_lstm, history_vanila_lstm\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1252\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\u001b[0;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;32m   1239\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n",
      "\u001b[0;32m   1240\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n",
      "\u001b[0;32m   1241\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1250\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n",
      "\u001b[0;32m   1251\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n",
      "\u001b[1;32m-> 1252\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n",
      "\u001b[0;32m   1253\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n",
      "\u001b[0;32m   1254\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n",
      "\u001b[0;32m   1255\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n",
      "\u001b[0;32m   1256\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n",
      "\u001b[0;32m   1257\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n",
      "\u001b[0;32m   1258\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n",
      "\u001b[0;32m   1259\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n",
      "\u001b[0;32m   1260\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n",
      "\u001b[0;32m   1261\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n",
      "\u001b[0;32m   1262\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n",
      "\u001b[0;32m   1263\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;32m   1264\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n",
      "\u001b[0;32m   1265\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1537\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1535\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n",
      "\u001b[0;32m   1536\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n",
      "\u001b[1;32m-> 1537\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n",
      "\u001b[0;32m   1538\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n",
      "\u001b[0;32m   1539\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n",
      "\u001b[1;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "\u001b[0;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:949\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    946\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[0;32m    947\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n",
      "\u001b[0;32m    948\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n",
      "\u001b[1;32m--> 949\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;32m    950\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n",
      "\u001b[0;32m    951\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    952\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "\u001b[0;32m   3128\u001b[0m   (graph_function,\n",
      "\u001b[0;32m   3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "\u001b[1;32m-> 3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n",
      "\u001b[0;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "\u001b[0;32m   1955\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\u001b[0;32m   1956\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\u001b[0;32m   1957\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n",
      "\u001b[0;32m   1958\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\u001b[1;32m-> 1959\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n",
      "\u001b[0;32m   1960\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n",
      "\u001b[0;32m   1961\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\u001b[0;32m   1962\u001b[0m     args,\n",
      "\u001b[0;32m   1963\u001b[0m     possible_gradient_type,\n",
      "\u001b[0;32m   1964\u001b[0m     executing_eagerly)\n",
      "\u001b[0;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "\u001b[0;32m    596\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n",
      "\u001b[0;32m    597\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n",
      "\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n",
      "\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n",
      "\u001b[0;32m    601\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n",
      "\u001b[0;32m    602\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n",
      "\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n",
      "\u001b[0;32m    604\u001b[0m   \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m    605\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n",
      "\u001b[0;32m    606\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n",
      "\u001b[0;32m    607\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    610\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n",
      "\u001b[0;32m    611\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\MuhammadNurAlim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n",
      "\u001b[1;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n",
      "\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n",
      "\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg_asii = [32,'relu',3,1,0.01,8,150]\n",
    "model_asii_bs8,history_asii_model,  = train_lstm(X_train_asii,y_train_asii,cfg_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_asii_bs32 = model_asii_bs32.predict(X_test_asii)\n",
    "matriks_evaluate(preds_asii_bs32,y_test_asii,'asii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.016920856064242262,2)\n",
    "pembulatan(0.9874077270736897,2)\n",
    "pembulatan(0.03633563979389126,2)\n",
    "pembulatan(0.022011401288948202,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_asii_bs16 = model_asii_bs16.predict(X_test_asii)\n",
    "matriks_evaluate(preds_asii_bs16,y_test_asii,'asii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.017254665063887373,2)\n",
    "pembulatan(0.9879353116214824,2)\n",
    "pembulatan(0.04013173821403081,2)\n",
    "pembulatan(0.021790129419086132,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_asii_bs8 = model_asii_bs8.predict(X_test_asii)\n",
    "matriks_evaluate(preds_asii_bs8,y_test_asii,'asii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.015346604139969425,2)\n",
    "pembulatan(0.9900479608200057,2)\n",
    "pembulatan(0.033018683195921786,2)\n",
    "pembulatan(0.02020180579718549,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_asii_hl_u_lr_ep = {'model_bs32':mean_absolute_error(preds_asii_bs32, y_test_asii),'model_bs16':mean_absolute_error(preds_asii_bs16, y_test_asii),'model_bs8':mean_absolute_error(preds_asii_bs8, y_test_asii)}\n",
    "\n",
    "mape_asii_hl_u_lr_ep = {'model_bs32':mean_absolute_percentage_error(preds_asii_bs32, y_test_asii),'model_bs16':mean_absolute_percentage_error(preds_asii_bs16, y_test_asii),'model_bs8':mean_absolute_percentage_error(preds_asii_bs8, y_test_asii)}\n",
    "\n",
    "rmse_asii_hl_u_lr_ep = {'model_bs32':np.sqrt(mean_squared_error(preds_asii_bs32, y_test_asii)),'model_bs16':np.sqrt(mean_squared_error(preds_asii_bs16, y_test_asii)),'model_bs8':np.sqrt(mean_squared_error(preds_asii_bs8, y_test_asii))}\n",
    "\n",
    "r2_asii_hl_u_lr_ep = {'model_bs32':r2_score(preds_asii_bs32, y_test_asii),'model_bs16':r2_score(preds_asii_bs16, y_test_asii),'model_bs8':r2_score(preds_asii_bs8, y_test_asii)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_asii_hl_u_lr_ep_sorted = dict(sorted(mae_asii_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mae_asii_hl_u_lr_ep_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_asii_hl_u_lr_ep_sorted = dict(sorted(rmse_asii_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(rmse_asii_hl_u_lr_ep_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_asii_hl_u_lr_ep_sorted = dict(sorted(mape_asii_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mape_asii_hl_u_lr_ep_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_asii_hl_u_lr_ep_sorted = dict(sorted(r2_asii_hl_u_lr_ep.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_asii_hl_u_lr_ep_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data and normalize data\n",
    "df_icbp = normalize_data(data_close.icbp,'icbp')\n",
    "#reset index\n",
    "df_icbp = reset_index_data(df_icbp)\n",
    "#data to supervised\n",
    "icbp_X, icbp_y = split_sequence(df_icbp, 1)\n",
    "#split to train and test\n",
    "X_train_icbp, X_test_icbp, y_train_icbp, y_test_icbp = train_test_split(icbp_X, icbp_y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_icbp = reshape_data(X_train_icbp,1)\n",
    "X_test_icbp = reshape_data(X_test_icbp,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron, activation, n_steps, n_features,learning_rate, batch_size,epochs\n",
    "cfg_icbp = [8,'relu',1,1,0.01,32,200]\n",
    "model_icbp_bs32,history_icbp_model,  = train_lstm(X_train_icbp,y_train_icbp,cfg_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron, activation, n_steps, n_features,learning_rate, batch_size,epochs\n",
    "cfg_icbp = [8,'relu',1,1,0.01,16,200]\n",
    "model_icbp_bs16,history_icbp_model,  = train_lstm(X_train_icbp,y_train_icbp,cfg_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron, activation, n_steps, n_features,learning_rate, batch_size,epochs\n",
    "cfg_icbp = [8,'relu',1,1,0.01,8,200]\n",
    "model_icbp_bs8,history_icbp_model,  = train_lstm(X_train_icbp,y_train_icbp,cfg_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_icbp_bs32 = model_icbp_bs32.predict(X_test_icbp)\n",
    "matriks_evaluate(preds_icbp_bs32,y_test_icbp,'icbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.007353329179454687,2)\n",
    "pembulatan(0.9981393854996866,2)\n",
    "pembulatan(0.02843190299760299,2)\n",
    "pembulatan(0.01201080759215415,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_icbp_bs16 = model_icbp_bs16.predict(X_test_icbp)\n",
    "matriks_evaluate(preds_icbp_bs16,y_test_icbp,'icbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.007274663427842254,2)\n",
    "pembulatan(0.9981533501318129,2)\n",
    "pembulatan(0.0277478888285619,2)\n",
    "pembulatan(0.011995981801348952,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_icbp_bs8 = model_icbp_bs8.predict(X_test_icbp)\n",
    "matriks_evaluate(preds_icbp_bs8,y_test_icbp,'icbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.014329047331934453,2)\n",
    "pembulatan(0.9953377625240442,2)\n",
    "pembulatan(0.06350116606387053,2)\n",
    "pembulatan(0.018692824157166034,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_icbp_hl_u_lr_ep = {'model_bs32':mean_absolute_error(preds_icbp_bs32, y_test_icbp),'model_bs16':mean_absolute_error(preds_icbp_bs16, y_test_icbp),'model_bs8':mean_absolute_error(preds_icbp_bs8, y_test_icbp)}\n",
    "\n",
    "mape_icbp_hl_u_lr_ep = {'model_bs32':mean_absolute_percentage_error(preds_icbp_bs32, y_test_icbp),'model_bs16':mean_absolute_percentage_error(preds_icbp_bs16, y_test_icbp),'model_bs8':mean_absolute_percentage_error(preds_icbp_bs8, y_test_icbp)}\n",
    "\n",
    "rmse_icbp_hl_u_lr_ep = {'model_bs32':np.sqrt(mean_squared_error(preds_icbp_bs32, y_test_icbp)),'model_bs16':np.sqrt(mean_squared_error(preds_icbp_bs16, y_test_icbp)),'model_bs8':np.sqrt(mean_squared_error(preds_icbp_bs8, y_test_icbp))}\n",
    "\n",
    "r2_icbp_hl_u_lr_ep = {'model_bs32':r2_score(preds_icbp_bs32, y_test_icbp),'model_bs16':r2_score(preds_icbp_bs16, y_test_icbp),'model_bs8':r2_score(preds_icbp_bs8, y_test_icbp)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_icbp_hl_u_lr_ep_sorted = dict(sorted(mae_icbp_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mae_icbp_hl_u_lr_ep_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_icbp_hl_u_lr_ep_sorted = dict(sorted(rmse_icbp_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(rmse_icbp_hl_u_lr_ep_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_icbp_hl_u_lr_ep_sorted = dict(sorted(mape_icbp_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mape_icbp_hl_u_lr_ep_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_icbp_hl_u_lr_ep_sorted = dict(sorted(r2_icbp_hl_u_lr_ep.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_icbp_hl_u_lr_ep_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data and normalize data\n",
    "df_jsmr = normalize_data(data_close.jsmr,'jsmr')\n",
    "#reset index\n",
    "df_jsmr = reset_index_data(df_jsmr)\n",
    "#data to supervised\n",
    "jsmr_X, jsmr_y = split_sequence(df_jsmr, 1)\n",
    "#split to train and test\n",
    "X_train_jsmr, X_test_jsmr, y_train_jsmr, y_test_jsmr = train_test_split(jsmr_X, jsmr_y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_jsmr = reshape_data(X_train_jsmr,1)\n",
    "X_test_jsmr = reshape_data(X_test_jsmr,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron, activation, n_steps, n_features,learning_rate, batch_size,epochs\n",
    "cfg_jsmr = [8,'relu',1,1,0.01,32,200]\n",
    "model_jsmr_bs32,history_jsmr_model,  = train_lstm(X_train_jsmr,y_train_jsmr,cfg_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron, activation, n_steps, n_features,learning_rate, batch_size,epochs\n",
    "cfg_jsmr = [8,'relu',1,1,0.01,16,200]\n",
    "model_jsmr_bs16,history_jsmr_model,  = train_lstm(X_train_jsmr,y_train_jsmr,cfg_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron, activation, n_steps, n_features,learning_rate, batch_size,epochs\n",
    "cfg_jsmr = [8,'relu',1,1,0.01,8,200]\n",
    "model_jsmr_bs8,history_jsmr_model,  = train_lstm(X_train_jsmr,y_train_jsmr,cfg_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_jsmr_bs32 = model_jsmr_bs32.predict(X_test_jsmr)\n",
    "matriks_evaluate(preds_jsmr_bs32,y_test_jsmr,'jsmr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.017781660946700365,2)\n",
    "pembulatan(0.9887229545556224,2)\n",
    "pembulatan(0.057102426873167404,2)\n",
    "pembulatan(0.02244715803377186,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_jsmr_bs16 = model_jsmr_bs16.predict(X_test_jsmr)\n",
    "matriks_evaluate(preds_jsmr_bs16,y_test_jsmr,'jsmr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.011454908625903459,2)\n",
    "pembulatan(0.9940081988547483,2)\n",
    "pembulatan(0.028470031941793497,2)\n",
    "pembulatan(0.016602562556061077,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_jsmr_bs8 = model_jsmr_bs8.predict(X_test_jsmr)\n",
    "matriks_evaluate(preds_jsmr_bs8,y_test_jsmr,'jsmr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pembulatan(0.011488508080148499,2)\n",
    "pembulatan(0.9939849099075261,2)\n",
    "pembulatan(0.029825446451819868,2)\n",
    "pembulatan(0.01656066385999743,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_jsmr_hl_u_lr_ep = {'model_bs32':mean_absolute_error(preds_jsmr_bs32, y_test_jsmr),'model_bs16':mean_absolute_error(preds_jsmr_bs16, y_test_jsmr),'model_bs8':mean_absolute_error(preds_jsmr_bs8, y_test_jsmr)}\n",
    "\n",
    "mape_jsmr_hl_u_lr_ep = {'model_bs32':mean_absolute_percentage_error(preds_jsmr_bs32, y_test_jsmr),'model_bs16':mean_absolute_percentage_error(preds_jsmr_bs16, y_test_jsmr),'model_bs8':mean_absolute_percentage_error(preds_jsmr_bs8, y_test_jsmr)}\n",
    "\n",
    "rmse_jsmr_hl_u_lr_ep = {'model_bs32':np.sqrt(mean_squared_error(preds_jsmr_bs32, y_test_jsmr)),'model_bs16':np.sqrt(mean_squared_error(preds_jsmr_bs16, y_test_jsmr)),'model_bs8':np.sqrt(mean_squared_error(preds_jsmr_bs8, y_test_jsmr))}\n",
    "\n",
    "r2_jsmr_hl_u_lr_ep = {'model_bs32':r2_score(preds_jsmr_bs32, y_test_jsmr),'model_bs16':r2_score(preds_jsmr_bs16, y_test_jsmr),'model_bs8':r2_score(preds_jsmr_bs8, y_test_jsmr)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorted mae\")\n",
    "mae_jsmr_hl_u_lr_ep_sorted = dict(sorted(mae_jsmr_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mae_jsmr_hl_u_lr_ep_sorted)\n",
    "print(\"sorted rmse\")\n",
    "rmse_jsmr_hl_u_lr_ep_sorted = dict(sorted(rmse_jsmr_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(rmse_jsmr_hl_u_lr_ep_sorted)\n",
    "print(\"sorted mape\")\n",
    "mape_jsmr_hl_u_lr_ep_sorted = dict(sorted(mape_jsmr_hl_u_lr_ep.items(),key=lambda item: item[1]))\n",
    "print(mape_jsmr_hl_u_lr_ep_sorted)\n",
    "print(\"sorted r2\")\n",
    "r2_jsmr_hl_u_lr_ep_sorted = dict(sorted(r2_jsmr_hl_u_lr_ep.items(),key=lambda item: item[1] ,reverse=True))\n",
    "print(r2_jsmr_hl_u_lr_ep_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KESIMPULAN BATCH SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tuning batchj size ini terdapat beberapa hasil untuk ANTM 8 ASII 8 ICBP dan JSMR 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurasi sementara dari model yang akan dibangun adalah\n",
    "# ANTM epoch 200 learning rate 0.1 neuron/unit/node 8 atau 32 hidden layer 1 timesteps 2\n",
    "# ASII epoch 150 atau 100 learning rate 0.01 neuron/unit/node 32 hidden layer 1 timesteps 3\n",
    "# ICBP epoch 200 learning rate 0.01 neuron/unit/node 8 hidden layer 1 timesteps 1\n",
    "# JSMR epoch 200 learning rate 0.01 neuron/unit/node 8 hidden layer 1 timesteps 1 atau 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selanjutnya akan dicoba untuk menambahkan drop layer pada model yang telah dibuat dan fungsi aktivasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train test split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train_antm_3, X_test_antm_3, y_train_antm_3, y_test_antm_3 = train_test_split(antm_X_3, antm_y_3, test_size=0.33, random_state=42)\n",
    "# X_train_antm_7, X_test_antm_7, y_train_antm_7, y_test_antm_7 = train_test_split(antm_X_7, antm_y_7, test_size=0.33, random_state=42)\n",
    "# X_train_antm_20, X_test_antm_20, y_train_antm_20, y_test_antm_20 = train_test_split(antm_X_20, antm_y_20, test_size=0.33, random_state=42)\n",
    "# X_train_antm_30, X_test_antm_30, y_train_antm_30, y_test_antm_30 = train_test_split(antm_X_30, antm_y_30, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from sklearn.metrics import r2_score\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, LSTM\n",
    "# random.seed(42)\n",
    "\n",
    "# batch_size = 32\n",
    "# simple_model_one_antm = Sequential([\n",
    "#   LSTM(8, activation='relu',input_shape=(n_steps, n_features)),\n",
    "#   Dense(1),\n",
    "# ])\n",
    "\n",
    "\n",
    "# simple_model_one_antm.compile(\n",
    "#   optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "#   loss='mean_absolute_error',\n",
    "#   metrics=['mae'],\n",
    "# )\n",
    "\n",
    "# simple_model_one_antm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smod_history_one_antm = simple_model_one_antm.fit(X_train_antm, y_train_antm,\n",
    "#           validation_split=0.2,\n",
    "#           epochs=100,\n",
    "#           batch_size=batch_size,\n",
    "#           shuffle = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_one_antm = simple_model_one_antm.predict(X_test_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# print(\"mape score antm: \"+str(mean_absolute_error(preds_one_antm, y_test_antm)))\n",
    "# print(\"mape score antm: \"+str(r2_score(preds_one_antm, y_test_antm)))\n",
    "# print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_one_antm, y_test_antm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_one_antm = scaler.inverse_transform(preds_one_antm)\n",
    "# preds_one_antm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3816365fdcd687a07caedfe721e5894fb1dd0a24482efb967fc5a605423a1021"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
