{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import date, datetime\n",
    "from multiprocessing.spawn import import_main_path\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "# print(today)\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2022-06-27'\n",
    "\n",
    "panel_data_antm = data.DataReader('ANTM.JK','yahoo',start_date, end_date)\n",
    "panel_data_asii = data.DataReader('ASII.JK','yahoo',start_date, end_date)\n",
    "panel_data_icbp = data.DataReader('ICBP.JK','yahoo',start_date, end_date)\n",
    "panel_data_jsmr = data.DataReader('JSMR.JK','yahoo',start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#antm\n",
    "panel_data_antm['average'] = panel_data_antm[['Open','Close','High','Low']].mean(axis=1).round(2)\n",
    "panel_data_antm['daily_return'] = panel_data_antm['Open'] - panel_data_antm['Close']\n",
    "#asii\n",
    "panel_data_asii['average'] = panel_data_asii[['Open','Close','High','Low']].mean(axis=1).round(2)\n",
    "panel_data_asii['daily_return'] = panel_data_asii['Open'] - panel_data_asii['Close']\n",
    "#icbp\n",
    "panel_data_icbp['average'] = panel_data_icbp[['Open','Close','High','Low']].mean(axis=1).round(2)\n",
    "panel_data_icbp['daily_return'] = panel_data_icbp['Open'] - panel_data_icbp['Close']\n",
    "#jsmr\n",
    "panel_data_jsmr['average'] = panel_data_jsmr[['Open','Close','High','Low']].mean(axis=1).round(2)\n",
    "panel_data_jsmr['daily_return'] = panel_data_jsmr['Open'] - panel_data_jsmr['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm = pd.DataFrame(panel_data_antm)\n",
    "df_asii = pd.DataFrame(panel_data_asii)\n",
    "df_icbp = pd.DataFrame(panel_data_icbp)\n",
    "df_jsmr = pd.DataFrame(panel_data_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a min max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_antm = pd.DataFrame(scaler.fit_transform(panel_data_antm),columns=['high','low','open','close','volume','adj_close','average','daily_return'])\n",
    "df_asii = pd.DataFrame(scaler.fit_transform(panel_data_asii),columns=['high','low','open','close','volume','adj_close','average','daily_return'])\n",
    "df_icbp = pd.DataFrame(scaler.fit_transform(panel_data_icbp),columns=['high','low','open','close','volume','adj_close','average','daily_return'])\n",
    "df_jsmr = pd.DataFrame(scaler.fit_transform(panel_data_jsmr),columns=['high','low','open','close','volume','adj_close','average','daily_return'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm.drop(columns=['adj_close','volume'], inplace=True)\n",
    "df_asii.drop(columns=['adj_close','volume'], inplace=True)\n",
    "df_icbp.drop(columns=['adj_close','volume'], inplace=True)\n",
    "df_jsmr.drop(columns=['adj_close','volume'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to windowed data sets\n",
    "ylist_antm = panel_data_antm['Adj Close']\n",
    "ylist_asii = panel_data_asii['Adj Close']\n",
    "ylist_icbp = panel_data_icbp['Adj Close']\n",
    "ylist_jsmr = panel_data_jsmr['Adj Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAGS and PERIOD\n",
    "n_future = 20\n",
    "n_past = 3*20\n",
    "total_period = 4*20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNGSI AKTIVASI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_end_antm = len(ylist_antm)\n",
    "idx_start_antm = idx_end_antm - total_period\n",
    "\n",
    "X_new_antm = []\n",
    "y_new_antm = []\n",
    "\n",
    "while idx_start_antm > 0:\n",
    "  x_line_antm = ylist_antm[idx_start_antm:idx_start_antm+n_past]\n",
    "  y_line_antm = ylist_antm[idx_start_antm+n_past:idx_start_antm+total_period]\n",
    "\n",
    "  X_new_antm.append(x_line_antm)\n",
    "  y_new_antm.append(y_line_antm)\n",
    "\n",
    "  idx_start_antm = idx_start_antm - 1\n",
    "\n",
    "X_new_antm = np.array(X_new_antm)\n",
    "y_new_antm = np.array(y_new_antm)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_antm, X_test_antm, y_train_antm, y_test_antm = train_test_split(X_new_antm, y_new_antm, test_size=0.33, random_state=42)\n",
    "\n",
    "# reshape data into the right format for RNNs\n",
    "n_samples = X_train_antm.shape[0]\n",
    "n_timesteps = X_train_antm.shape[1]\n",
    "n_steps = y_train_antm.shape[1]\n",
    "n_features = 1\n",
    "\n",
    "X_train_rs_antm = X_train_antm.reshape(n_samples, n_timesteps, n_features )\n",
    "X_test_rs_antm = X_test_antm.reshape(X_test_antm.shape[0], n_timesteps, n_features )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 10s 99ms/step - loss: 993.9017 - mae: 993.9017 - val_loss: 883.0706 - val_mae: 883.0706\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 818.9482 - mae: 818.9482 - val_loss: 711.1483 - val_mae: 711.1483\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 658.3809 - mae: 658.3809 - val_loss: 567.8150 - val_mae: 567.8150\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 525.3561 - mae: 525.3561 - val_loss: 449.9359 - val_mae: 449.9359\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 434.2703 - mae: 434.2703 - val_loss: 396.6594 - val_mae: 396.6594\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 399.4779 - mae: 399.4779 - val_loss: 380.1750 - val_mae: 380.1750\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 391.2181 - mae: 391.2181 - val_loss: 376.9222 - val_mae: 376.9222\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 389.6895 - mae: 389.6895 - val_loss: 376.3913 - val_mae: 376.3913\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 389.3564 - mae: 389.3564 - val_loss: 376.2922 - val_mae: 376.2922\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 389.3007 - mae: 389.3007 - val_loss: 376.2959 - val_mae: 376.2959\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 389.1708 - mae: 389.1708 - val_loss: 376.3171 - val_mae: 376.3171\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 389.2550 - mae: 389.2550 - val_loss: 376.3361 - val_mae: 376.3361\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 389.1798 - mae: 389.1798 - val_loss: 376.3443 - val_mae: 376.3443\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 88ms/step - loss: 389.1591 - mae: 389.1591 - val_loss: 376.4326 - val_mae: 376.4326\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 389.1581 - mae: 389.1581 - val_loss: 376.4634 - val_mae: 376.4634\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 106ms/step - loss: 389.4187 - mae: 389.4187 - val_loss: 376.4029 - val_mae: 376.4029\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 7s 138ms/step - loss: 389.1506 - mae: 389.1506 - val_loss: 376.3625 - val_mae: 376.3625\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 9s 167ms/step - loss: 389.1918 - mae: 389.1918 - val_loss: 376.3582 - val_mae: 376.3582\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 6s 127ms/step - loss: 389.1671 - mae: 389.1671 - val_loss: 376.3539 - val_mae: 376.3539\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 389.1805 - mae: 389.1805 - val_loss: 376.3600 - val_mae: 376.3600\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit64_lr1_sigmoid = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit64_lr1_sigmoid.summary()\n",
    "\n",
    "simple_model_three_antm_unit64_lr1_sigmoid.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit64_lr_sigmoid = simple_model_three_antm_unit64_lr1_sigmoid.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit64_lr1_sigmoid = simple_model_three_antm_unit64_lr1_sigmoid.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score antm: 405.62\n",
      "mape score antm: 0.45\n",
      "r2 score antm: -85643944917.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit64_lr1_sigmoid, y_test_antm).round(2)))\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit64_lr1_sigmoid, y_test_antm).round(2)))\n",
    "print(\"r2 score antm: \"+str(r2_score(preds_three_antm_unit64_lr1_sigmoid, y_test_antm).round(2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_end_asii = len(ylist_asii)\n",
    "idx_start_asii = idx_end_asii - total_period\n",
    "\n",
    "X_new_asii = []\n",
    "y_new_asii = []\n",
    "\n",
    "while idx_start_asii > 0:\n",
    "  x_line_asii = ylist_asii[idx_start_asii:idx_start_asii+n_past]\n",
    "  y_line_asii = ylist_asii[idx_start_asii+n_past:idx_start_asii+total_period]\n",
    "\n",
    "  X_new_asii.append(x_line_asii)\n",
    "  y_new_asii.append(y_line_asii)\n",
    "\n",
    "  idx_start_asii = idx_start_asii - 1\n",
    "\n",
    "X_new_asii = np.array(X_new_asii)\n",
    "y_new_asii = np.array(y_new_asii)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_asii, X_test_asii, y_train_asii, y_test_asii = train_test_split(X_new_asii, y_new_asii, test_size=0.33, random_state=42)\n",
    "\n",
    "# reshape data into the right format for RNNs\n",
    "n_samples = X_train_asii.shape[0]\n",
    "n_timesteps = X_train_asii.shape[1]\n",
    "n_steps = y_train_asii.shape[1]\n",
    "n_features = 1\n",
    "\n",
    "X_train_rs_asii = X_train_asii.reshape(n_samples, n_timesteps, n_features )\n",
    "X_test_rs_asii = X_test_asii.reshape(X_test_asii.shape[0], n_timesteps, n_features )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 9s 86ms/step - loss: 5566.6763 - mae: 5566.6763 - val_loss: 5427.3789 - val_mae: 5427.3789\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 5383.7998 - mae: 5383.7998 - val_loss: 5244.9414 - val_mae: 5244.9414\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5201.7041 - mae: 5201.7041 - val_loss: 5063.1016 - val_mae: 5063.1016\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 5019.9990 - mae: 5019.9990 - val_loss: 4881.5093 - val_mae: 4881.5093\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 4838.4775 - mae: 4838.4775 - val_loss: 4700.0513 - val_mae: 4700.0513\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 4657.0640 - mae: 4657.0640 - val_loss: 4518.6772 - val_mae: 4518.6772\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4475.7192 - mae: 4475.7192 - val_loss: 4337.3608 - val_mae: 4337.3608\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 4294.4238 - mae: 4294.4238 - val_loss: 4156.0869 - val_mae: 4156.0869\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4113.1660 - mae: 4113.1660 - val_loss: 3974.8452 - val_mae: 3974.8452\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 3931.9365 - mae: 3931.9365 - val_loss: 3793.6274 - val_mae: 3793.6274\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 3750.7290 - mae: 3750.7290 - val_loss: 3612.4309 - val_mae: 3612.4309\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 3569.5403 - mae: 3569.5403 - val_loss: 3431.2502 - val_mae: 3431.2502\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 3388.3674 - mae: 3388.3674 - val_loss: 3250.0842 - val_mae: 3250.0842\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 3207.2070 - mae: 3207.2070 - val_loss: 3068.9382 - val_mae: 3068.9382\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 3026.2034 - mae: 3026.2034 - val_loss: 2888.3438 - val_mae: 2888.3438\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 2845.7688 - mae: 2845.7688 - val_loss: 2708.9158 - val_mae: 2708.9158\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 2666.4778 - mae: 2666.4778 - val_loss: 2532.2571 - val_mae: 2532.2571\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 2490.5676 - mae: 2490.5676 - val_loss: 2358.7937 - val_mae: 2358.7937\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 2318.7336 - mae: 2318.7336 - val_loss: 2190.5947 - val_mae: 2190.5947\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 2157.6089 - mae: 2157.6089 - val_loss: 2038.1892 - val_mae: 2038.1892\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit64_lr1_sigmoid = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit64_lr1_sigmoid.summary()\n",
    "\n",
    "simple_model_three_asii_unit64_lr1_sigmoid.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit64_lr1_sigmoid = simple_model_three_asii_unit64_lr1_sigmoid.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit64_lr1_sigmoid = simple_model_three_asii_unit64_lr1_sigmoid.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score asii: 2053.26\n",
      "mape score asii: 0.57\n",
      "r2 score asii: -15025393258.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit64_lr1_sigmoid, y_test_asii).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit64_lr1_sigmoid, y_test_asii).round(2)))\n",
    "print(\"r2 score asii: \"+str(r2_score(preds_three_asii_unit64_lr1_sigmoid, y_test_asii).round(2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_end_icbp = len(ylist_icbp)\n",
    "idx_start_icbp = idx_end_icbp - total_period\n",
    "\n",
    "X_new_icbp = []\n",
    "y_new_icbp = []\n",
    "\n",
    "while idx_start_icbp > 0:\n",
    "  x_line_icbp = ylist_icbp[idx_start_icbp:idx_start_icbp+n_past]\n",
    "  y_line_icbp = ylist_icbp[idx_start_icbp+n_past:idx_start_icbp+total_period]\n",
    "\n",
    "  X_new_icbp.append(x_line_icbp)\n",
    "  y_new_icbp.append(y_line_icbp)\n",
    "\n",
    "  idx_start_icbp = idx_start_icbp - 1\n",
    "\n",
    "X_new_icbp = np.array(X_new_icbp)\n",
    "y_new_icbp = np.array(y_new_icbp)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_icbp, X_test_icbp, y_train_icbp, y_test_icbp = train_test_split(X_new_icbp, y_new_icbp, test_size=0.33, random_state=42)\n",
    "\n",
    "# reshape data into the right format for RNNs\n",
    "n_samples = X_train_icbp.shape[0]\n",
    "n_timesteps = X_train_icbp.shape[1]\n",
    "n_steps = y_train_icbp.shape[1]\n",
    "n_features = 1\n",
    "\n",
    "X_train_rs_icbp = X_train_icbp.reshape(n_samples, n_timesteps, n_features )\n",
    "X_test_rs_icbp = X_test_icbp.reshape(X_test_icbp.shape[0], n_timesteps, n_features )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 8s 100ms/step - loss: 6124.2354 - mae: 6124.2354 - val_loss: 5893.0205 - val_mae: 5893.0205\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 5931.4561 - mae: 5931.4561 - val_loss: 5700.6943 - val_mae: 5700.6943\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 5739.3926 - mae: 5739.3926 - val_loss: 5508.8262 - val_mae: 5508.8262\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 5547.6274 - mae: 5547.6274 - val_loss: 5317.1489 - val_mae: 5317.1489\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 5356.0054 - mae: 5356.0054 - val_loss: 5125.5771 - val_mae: 5125.5771\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 5164.4688 - mae: 5164.4688 - val_loss: 4934.0708 - val_mae: 4934.0708\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 4972.9858 - mae: 4972.9858 - val_loss: 4742.6372 - val_mae: 4742.6372\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 4782.3394 - mae: 4782.3394 - val_loss: 4554.9922 - val_mae: 4554.9922\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 4598.1436 - mae: 4598.1436 - val_loss: 4375.2607 - val_mae: 4375.2607\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 4424.1118 - mae: 4424.1118 - val_loss: 4214.8921 - val_mae: 4214.8921\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 4265.5659 - mae: 4265.5659 - val_loss: 4071.9448 - val_mae: 4071.9448\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 4131.3843 - mae: 4131.3843 - val_loss: 3966.9175 - val_mae: 3966.9175\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 4026.7986 - mae: 4026.7986 - val_loss: 3879.6895 - val_mae: 3879.6895\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 3936.9370 - mae: 3936.9370 - val_loss: 3798.8364 - val_mae: 3798.8364\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3848.7734 - mae: 3848.7734 - val_loss: 3716.6526 - val_mae: 3716.6526\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 3762.3440 - mae: 3762.3440 - val_loss: 3637.3689 - val_mae: 3637.3689\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 3679.8540 - mae: 3679.8540 - val_loss: 3563.0298 - val_mae: 3563.0298\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3598.1997 - mae: 3598.1997 - val_loss: 3487.2246 - val_mae: 3487.2246\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 3518.4575 - mae: 3518.4575 - val_loss: 3414.2646 - val_mae: 3414.2646\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 3440.0571 - mae: 3440.0571 - val_loss: 3343.2925 - val_mae: 3343.2925\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid.summary()\n",
    "\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit64_lr1_sigmoid = simple_model_three_icbp_unit64_lr1_sigmoid.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit64_lr1_sigmoid = simple_model_three_icbp_unit64_lr1_sigmoid.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score icbp: 3485.68\n",
      "mape score icbp: 1.05\n",
      "r2 score icbp: -264129180019.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit64_lr1_sigmoid, y_test_icbp).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit64_lr1_sigmoid, y_test_icbp).round(2)))\n",
    "print(\"r2 score icbp: \"+str(r2_score(preds_three_icbp_unit64_lr1_sigmoid, y_test_icbp).round(2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_end_jsmr = len(ylist_jsmr)\n",
    "idx_start_jsmr = idx_end_jsmr - total_period\n",
    "\n",
    "X_new_jsmr = []\n",
    "y_new_jsmr = []\n",
    "\n",
    "while idx_start_jsmr > 0:\n",
    "  x_line_jsmr = ylist_jsmr[idx_start_jsmr:idx_start_jsmr+n_past]\n",
    "  y_line_jsmr = ylist_jsmr[idx_start_jsmr+n_past:idx_start_jsmr+total_period]\n",
    "\n",
    "  X_new_jsmr.append(x_line_jsmr)\n",
    "  y_new_jsmr.append(y_line_jsmr)\n",
    "\n",
    "  idx_start_jsmr = idx_start_jsmr - 1\n",
    "\n",
    "X_new_jsmr = np.array(X_new_jsmr)\n",
    "y_new_jsmr = np.array(y_new_jsmr)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_jsmr, X_test_jsmr, y_train_jsmr, y_test_jsmr = train_test_split(X_new_jsmr, y_new_jsmr, test_size=0.33, random_state=42)\n",
    "\n",
    "# reshape data into the right format for RNNs\n",
    "n_samples = X_train_jsmr.shape[0]\n",
    "n_timesteps = X_train_jsmr.shape[1]\n",
    "n_steps = y_train_jsmr.shape[1]\n",
    "n_features = 1\n",
    "\n",
    "X_train_rs_jsmr = X_train_jsmr.reshape(n_samples, n_timesteps, n_features )\n",
    "X_test_rs_jsmr = X_test_jsmr.reshape(X_test_jsmr.shape[0], n_timesteps, n_features )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 8s 88ms/step - loss: 4531.8008 - mae: 4531.8008 - val_loss: 4438.8354 - val_mae: 4438.8354\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 4343.9824 - mae: 4343.9824 - val_loss: 4251.4795 - val_mae: 4251.4795\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 4156.9199 - mae: 4156.9199 - val_loss: 4064.6370 - val_mae: 4064.6370\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 3970.1946 - mae: 3970.1946 - val_loss: 3878.0103 - val_mae: 3878.0103\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3783.6289 - mae: 3783.6289 - val_loss: 3691.5000 - val_mae: 3691.5000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 3597.1572 - mae: 3597.1572 - val_loss: 3505.0637 - val_mae: 3505.0637\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 3410.7476 - mae: 3410.7476 - val_loss: 3318.6785 - val_mae: 3318.6785\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 3224.3843 - mae: 3224.3843 - val_loss: 3132.3677 - val_mae: 3132.3677\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 3038.5398 - mae: 3038.5398 - val_loss: 2948.4583 - val_mae: 2948.4583\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 6s 111ms/step - loss: 2857.9077 - mae: 2857.9077 - val_loss: 2771.7827 - val_mae: 2771.7827\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 2684.3735 - mae: 2684.3735 - val_loss: 2601.2847 - val_mae: 2601.2847\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 2512.7671 - mae: 2512.7671 - val_loss: 2431.1948 - val_mae: 2431.1948\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 106ms/step - loss: 2341.3145 - mae: 2341.3145 - val_loss: 2264.1787 - val_mae: 2264.1787\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2172.1470 - mae: 2172.1470 - val_loss: 2100.6189 - val_mae: 2100.6189\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 2006.1053 - mae: 2006.1053 - val_loss: 1944.1471 - val_mae: 1944.1471\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 1850.3063 - mae: 1850.3063 - val_loss: 1798.6967 - val_mae: 1798.6967\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 1706.4729 - mae: 1706.4729 - val_loss: 1670.6748 - val_mae: 1670.6748\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 1575.5510 - mae: 1575.5510 - val_loss: 1553.9120 - val_mae: 1553.9120\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 1452.0555 - mae: 1452.0555 - val_loss: 1440.9672 - val_mae: 1440.9672\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 1339.3231 - mae: 1339.3231 - val_loss: 1339.2450 - val_mae: 1339.2450\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit64_lr1_sigmoid = simple_model_three_jsmr_unit64_lr1_sigmoid.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit64_lr1_sigmoid = simple_model_three_jsmr_unit64_lr1_sigmoid.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score jsmr: 1280.3\n",
      "mape score jsmr: 0.36\n",
      "r2 score jsmr: -11664832002.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit64_lr1_sigmoid, y_test_jsmr).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit64_lr1_sigmoid, y_test_jsmr).round(2)))\n",
    "print(\"r2 score jsmr: \"+str(r2_score(preds_three_jsmr_unit64_lr1_sigmoid, y_test_jsmr).round(2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 9s 102ms/step - loss: 996.0273 - mae: 996.0273 - val_loss: 887.8474 - val_mae: 887.8474\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 826.0676 - mae: 826.0676 - val_loss: 720.0027 - val_mae: 720.0027\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 669.2927 - mae: 669.2927 - val_loss: 578.5298 - val_mae: 578.5298\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 538.5150 - mae: 538.5150 - val_loss: 461.6644 - val_mae: 461.6644\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 443.4857 - mae: 443.4857 - val_loss: 402.2701 - val_mae: 402.2701\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 402.7099 - mae: 402.7099 - val_loss: 381.4666 - val_mae: 381.4666\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 391.9751 - mae: 391.9751 - val_loss: 377.3076 - val_mae: 377.3076\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 389.9693 - mae: 389.9693 - val_loss: 376.4509 - val_mae: 376.4509\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 389.4421 - mae: 389.4421 - val_loss: 376.3088 - val_mae: 376.3088\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 389.3335 - mae: 389.3335 - val_loss: 376.2940 - val_mae: 376.2940\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 389.2605 - mae: 389.2605 - val_loss: 376.2931 - val_mae: 376.2931\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 389.2146 - mae: 389.2146 - val_loss: 376.3123 - val_mae: 376.3123\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 389.1651 - mae: 389.1651 - val_loss: 376.3241 - val_mae: 376.3241\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 389.1621 - mae: 389.1621 - val_loss: 376.3418 - val_mae: 376.3418\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 389.1451 - mae: 389.1451 - val_loss: 376.3814 - val_mae: 376.3814\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 389.1389 - mae: 389.1389 - val_loss: 376.3608 - val_mae: 376.3608\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 389.1917 - mae: 389.1917 - val_loss: 376.3551 - val_mae: 376.3551\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 389.1703 - mae: 389.1703 - val_loss: 376.4236 - val_mae: 376.4236\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 389.1997 - mae: 389.1997 - val_loss: 376.3286 - val_mae: 376.3286\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 389.1702 - mae: 389.1702 - val_loss: 376.4489 - val_mae: 376.4489\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 389.1915 - mae: 389.1915 - val_loss: 376.3429 - val_mae: 376.3429\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 389.2071 - mae: 389.2071 - val_loss: 376.4022 - val_mae: 376.4022\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 389.2538 - mae: 389.2538 - val_loss: 376.3629 - val_mae: 376.3629\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 389.2488 - mae: 389.2488 - val_loss: 376.4433 - val_mae: 376.4433\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 389.1388 - mae: 389.1388 - val_loss: 376.3811 - val_mae: 376.3811\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 389.1801 - mae: 389.1801 - val_loss: 376.3349 - val_mae: 376.3349\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 389.2152 - mae: 389.2152 - val_loss: 376.3754 - val_mae: 376.3754\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 389.2052 - mae: 389.2052 - val_loss: 376.3799 - val_mae: 376.3799\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 389.2408 - mae: 389.2408 - val_loss: 376.4022 - val_mae: 376.4022\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 389.1428 - mae: 389.1428 - val_loss: 376.3336 - val_mae: 376.3336\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 389.1713 - mae: 389.1713 - val_loss: 376.3076 - val_mae: 376.3076\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 389.1856 - mae: 389.1856 - val_loss: 376.3983 - val_mae: 376.3983\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 389.1697 - mae: 389.1697 - val_loss: 376.3690 - val_mae: 376.3690\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 389.2473 - mae: 389.2473 - val_loss: 376.3141 - val_mae: 376.3141\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2151 - mae: 389.2151 - val_loss: 376.3509 - val_mae: 376.3509\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2057 - mae: 389.2057 - val_loss: 376.3990 - val_mae: 376.3990\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.4118 - mae: 389.4118 - val_loss: 376.3256 - val_mae: 376.3256\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2318 - mae: 389.2318 - val_loss: 376.3460 - val_mae: 376.3460\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.1994 - mae: 389.1994 - val_loss: 376.3662 - val_mae: 376.3662 393.8180 - mae: 3\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 389.2483 - mae: 389.2483 - val_loss: 376.4629 - val_mae: 376.4629\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.1588 - mae: 389.1588 - val_loss: 376.3057 - val_mae: 376.3057\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 389.3463 - mae: 389.3463 - val_loss: 376.3047 - val_mae: 376.3047\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 389.2293 - mae: 389.2293 - val_loss: 376.3551 - val_mae: 376.3551\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 389.2643 - mae: 389.2643 - val_loss: 376.3286 - val_mae: 376.3286\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 389.2858 - mae: 389.2858 - val_loss: 376.3724 - val_mae: 376.3724\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 389.2909 - mae: 389.2909 - val_loss: 376.3328 - val_mae: 376.3328\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 389.2449 - mae: 389.2449 - val_loss: 376.3417 - val_mae: 376.3417\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2420 - mae: 389.2420 - val_loss: 376.3239 - val_mae: 376.3239\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 389.2023 - mae: 389.2023 - val_loss: 376.3698 - val_mae: 376.3698: 0s - loss: 389.4633 - mae: 3\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.2386 - mae: 389.2386 - val_loss: 376.4294 - val_mae: 376.4294\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit64_lr1_sigmoid_50 = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit64_lr1_sigmoid_50.summary()\n",
    "\n",
    "simple_model_three_antm_unit64_lr1_sigmoid_50.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit64_lr1_sigmoid_50 = simple_model_three_antm_unit64_lr1_sigmoid_50.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit64_lr1_sigmoid_50 = simple_model_three_antm_unit64_lr1_sigmoid_50.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 6s 76ms/step - loss: 996.7971 - mae: 996.7971 - val_loss: 890.2014 - val_mae: 890.2014\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 829.7682 - mae: 829.7682 - val_loss: 724.8591 - val_mae: 724.8591\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 673.9470 - mae: 673.9470 - val_loss: 584.5355 - val_mae: 584.5355\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 543.7194 - mae: 543.7194 - val_loss: 466.2473 - val_mae: 466.2473\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 447.2247 - mae: 447.2247 - val_loss: 404.8253 - val_mae: 404.8253\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 404.3980 - mae: 404.3980 - val_loss: 382.7122 - val_mae: 382.7122\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 392.5422 - mae: 392.5422 - val_loss: 377.5048 - val_mae: 377.5048\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.9655 - mae: 389.9655 - val_loss: 376.4769 - val_mae: 376.4769\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.4148 - mae: 389.4148 - val_loss: 376.3099 - val_mae: 376.3099\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.2802 - mae: 389.2802 - val_loss: 376.2898 - val_mae: 376.2898\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 389.2032 - mae: 389.2032 - val_loss: 376.3000 - val_mae: 376.3000\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.1737 - mae: 389.1737 - val_loss: 376.3274 - val_mae: 376.3274\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 389.1542 - mae: 389.1542 - val_loss: 376.3827 - val_mae: 376.3827\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.1394 - mae: 389.1394 - val_loss: 376.3845 - val_mae: 376.3845\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.1473 - mae: 389.1473 - val_loss: 376.3781 - val_mae: 376.3781\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 389.1525 - mae: 389.1525 - val_loss: 376.3931 - val_mae: 376.3931\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.1396 - mae: 389.1396 - val_loss: 376.3631 - val_mae: 376.3631\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.1565 - mae: 389.1565 - val_loss: 376.3443 - val_mae: 376.3443\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.1395 - mae: 389.1395 - val_loss: 376.3565 - val_mae: 376.3565\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.1457 - mae: 389.1457 - val_loss: 376.4119 - val_mae: 376.4119\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.1918 - mae: 389.1918 - val_loss: 376.4065 - val_mae: 376.4065\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.2187 - mae: 389.2187 - val_loss: 376.3690 - val_mae: 376.3690\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 389.1677 - mae: 389.1677 - val_loss: 376.3601 - val_mae: 376.3601\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 389.2781 - mae: 389.2781 - val_loss: 376.3390 - val_mae: 376.3390\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.1572 - mae: 389.1572 - val_loss: 376.3742 - val_mae: 376.3742\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.1793 - mae: 389.1793 - val_loss: 376.3717 - val_mae: 376.3717\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2070 - mae: 389.2070 - val_loss: 376.3546 - val_mae: 376.3546\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2434 - mae: 389.2434 - val_loss: 376.3722 - val_mae: 376.3722\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2037 - mae: 389.2037 - val_loss: 376.3773 - val_mae: 376.3773\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3622 - mae: 389.3622 - val_loss: 376.3916 - val_mae: 376.3916\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.1877 - mae: 389.1877 - val_loss: 376.5043 - val_mae: 376.5043\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 389.3723 - mae: 389.3723 - val_loss: 376.3494 - val_mae: 376.3494\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.2287 - mae: 389.2287 - val_loss: 376.3091 - val_mae: 376.3091\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3786 - mae: 389.3786 - val_loss: 376.3406 - val_mae: 376.3406\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2049 - mae: 389.2049 - val_loss: 376.3914 - val_mae: 376.3914\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.3673 - mae: 389.3673 - val_loss: 376.3569 - val_mae: 376.3569\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 389.2621 - mae: 389.2621 - val_loss: 376.3842 - val_mae: 376.3842\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.1669 - mae: 389.1669 - val_loss: 376.3595 - val_mae: 376.3595\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 389.1666 - mae: 389.1666 - val_loss: 376.3662 - val_mae: 376.3662\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 389.3802 - mae: 389.3802 - val_loss: 376.3445 - val_mae: 376.3445\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 389.1808 - mae: 389.1808 - val_loss: 376.3530 - val_mae: 376.3530\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 389.1884 - mae: 389.1884 - val_loss: 376.4052 - val_mae: 376.4052\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 389.2017 - mae: 389.2017 - val_loss: 376.3455 - val_mae: 376.3455\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.1837 - mae: 389.1837 - val_loss: 376.3975 - val_mae: 376.3975\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 389.3048 - mae: 389.3048 - val_loss: 376.3716 - val_mae: 376.3716\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 389.1833 - mae: 389.1833 - val_loss: 376.3837 - val_mae: 376.3837\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 389.3193 - mae: 389.3193 - val_loss: 376.5468 - val_mae: 376.5468\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.1794 - mae: 389.1794 - val_loss: 376.3458 - val_mae: 376.3458\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 389.2715 - mae: 389.2715 - val_loss: 376.3348 - val_mae: 376.3348\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 389.1932 - mae: 389.1932 - val_loss: 376.3504 - val_mae: 376.3504\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.2498 - mae: 389.2498 - val_loss: 376.3136 - val_mae: 376.3136\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 389.3948 - mae: 389.3948 - val_loss: 376.3651 - val_mae: 376.3651\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 389.3486 - mae: 389.3486 - val_loss: 376.3719 - val_mae: 376.3719\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 389.2685 - mae: 389.2685 - val_loss: 376.3478 - val_mae: 376.3478\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.1714 - mae: 389.1714 - val_loss: 376.4155 - val_mae: 376.4155\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 389.1999 - mae: 389.1999 - val_loss: 376.3737 - val_mae: 376.3737\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 389.2332 - mae: 389.2332 - val_loss: 376.3175 - val_mae: 376.3175\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 389.3137 - mae: 389.3137 - val_loss: 376.3834 - val_mae: 376.3834\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 389.2152 - mae: 389.2152 - val_loss: 376.3888 - val_mae: 376.3888\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3236 - mae: 389.3236 - val_loss: 376.3350 - val_mae: 376.3350\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 389.3239 - mae: 389.3239 - val_loss: 376.3040 - val_mae: 376.3040\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2018 - mae: 389.2018 - val_loss: 376.5736 - val_mae: 376.5736\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2691 - mae: 389.2691 - val_loss: 376.3532 - val_mae: 376.3532\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2289 - mae: 389.2289 - val_loss: 376.3898 - val_mae: 376.3898\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 389.2155 - mae: 389.2155 - val_loss: 376.4062 - val_mae: 376.4062\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2676 - mae: 389.2676 - val_loss: 376.3394 - val_mae: 376.3394\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 389.2415 - mae: 389.2415 - val_loss: 376.4239 - val_mae: 376.4239\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 389.3611 - mae: 389.3611 - val_loss: 376.3200 - val_mae: 376.3200\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 389.2200 - mae: 389.2200 - val_loss: 376.3385 - val_mae: 376.3385\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 389.3344 - mae: 389.3344 - val_loss: 376.3741 - val_mae: 376.3741\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 389.2645 - mae: 389.2645 - val_loss: 376.3741 - val_mae: 376.3741\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 389.2614 - mae: 389.2614 - val_loss: 376.3775 - val_mae: 376.3775\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 389.3011 - mae: 389.3011 - val_loss: 376.3358 - val_mae: 376.3358\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 5s 106ms/step - loss: 389.3077 - mae: 389.3077 - val_loss: 376.4329 - val_mae: 376.4329\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 389.3401 - mae: 389.3401 - val_loss: 376.3216 - val_mae: 376.3216\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 6s 107ms/step - loss: 389.1742 - mae: 389.1742 - val_loss: 376.4138 - val_mae: 376.4138\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 389.2302 - mae: 389.2302 - val_loss: 376.3152 - val_mae: 376.3152\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 389.2541 - mae: 389.2541 - val_loss: 376.3964 - val_mae: 376.3964\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.2253 - mae: 389.2253 - val_loss: 376.3067 - val_mae: 376.3067\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3243 - mae: 389.3243 - val_loss: 376.3374 - val_mae: 376.3374\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3480 - mae: 389.3480 - val_loss: 376.2995 - val_mae: 376.2995\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 389.4930 - mae: 389.4930 - val_loss: 376.3468 - val_mae: 376.3468 0s - loss: 389.3870 - mae: 389\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2554 - mae: 389.2554 - val_loss: 376.2973 - val_mae: 376.2973\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3754 - mae: 389.3754 - val_loss: 376.3910 - val_mae: 376.3910\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2961 - mae: 389.2961 - val_loss: 376.3255 - val_mae: 376.3255\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 389.2411 - mae: 389.2411 - val_loss: 376.3368 - val_mae: 376.3368\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 389.2882 - mae: 389.2882 - val_loss: 376.3289 - val_mae: 376.3289\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3079 - mae: 389.3079 - val_loss: 376.3370 - val_mae: 376.3370\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2601 - mae: 389.2601 - val_loss: 376.3764 - val_mae: 376.3764\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3777 - mae: 389.3777 - val_loss: 376.3931 - val_mae: 376.3931\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 389.3022 - mae: 389.3022 - val_loss: 376.3029 - val_mae: 376.3029\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 389.1573 - mae: 389.1573 - val_loss: 376.4790 - val_mae: 376.4790\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2905 - mae: 389.2905 - val_loss: 376.3474 - val_mae: 376.3474\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2398 - mae: 389.2398 - val_loss: 376.5416 - val_mae: 376.5416\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3709 - mae: 389.3709 - val_loss: 376.3586 - val_mae: 376.3586\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2393 - mae: 389.2393 - val_loss: 376.4481 - val_mae: 376.4481\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.3376 - mae: 389.3376 - val_loss: 376.3500 - val_mae: 376.3500\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.2843 - mae: 389.2843 - val_loss: 376.4015 - val_mae: 376.4015\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 389.5482 - mae: 389.5482 - val_loss: 376.3385 - val_mae: 376.3385\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 389.2312 - mae: 389.2312 - val_loss: 376.3177 - val_mae: 376.3177\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit64_lr1_sigmoid_100 = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit64_lr1_sigmoid_100.summary()\n",
    "\n",
    "simple_model_three_antm_unit64_lr1_sigmoid_100.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit64_lr1_sigmoid_100 = simple_model_three_antm_unit64_lr1_sigmoid_100.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit64_lr1_sigmoid_100 = simple_model_three_antm_unit64_lr1_sigmoid_100.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 7s 76ms/step - loss: 5570.9395 - mae: 5570.9395 - val_loss: 5437.0625 - val_mae: 5437.0625\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 5398.6040 - mae: 5398.6040 - val_loss: 5265.1533 - val_mae: 5265.1533\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 5226.9517 - mae: 5226.9517 - val_loss: 5093.6948 - val_mae: 5093.6948\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 5055.5957 - mae: 5055.5957 - val_loss: 4922.4248 - val_mae: 4922.4248\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 4884.3809 - mae: 4884.3809 - val_loss: 4751.2588 - val_mae: 4751.2588\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 4713.2476 - mae: 4713.2476 - val_loss: 4580.1572 - val_mae: 4580.1572\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 4542.1694 - mae: 4542.1694 - val_loss: 4409.1001 - val_mae: 4409.1001\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 4371.1294 - mae: 4371.1294 - val_loss: 4238.0752 - val_mae: 4238.0752\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 4200.1167 - mae: 4200.1167 - val_loss: 4067.0762 - val_mae: 4067.0762\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 4029.1272 - mae: 4029.1272 - val_loss: 3896.0957 - val_mae: 3896.0957\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 3858.1550 - mae: 3858.1550 - val_loss: 3725.1316 - val_mae: 3725.1316\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 3687.1963 - mae: 3687.1963 - val_loss: 3554.1794 - val_mae: 3554.1794\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3516.2507 - mae: 3516.2507 - val_loss: 3383.2385 - val_mae: 3383.2385\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3345.3152 - mae: 3345.3152 - val_loss: 3212.3071 - val_mae: 3212.3071\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 3174.3860 - mae: 3174.3860 - val_loss: 3041.4214 - val_mae: 3041.4214\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3003.6406 - mae: 3003.6406 - val_loss: 2871.1396 - val_mae: 2871.1396\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 2833.4846 - mae: 2833.4846 - val_loss: 2701.8254 - val_mae: 2701.8254\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 2664.5991 - mae: 2664.5991 - val_loss: 2535.2759 - val_mae: 2535.2759\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 2498.7908 - mae: 2498.7908 - val_loss: 2371.6050 - val_mae: 2371.6050\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 2336.0488 - mae: 2336.0488 - val_loss: 2212.3833 - val_mae: 2212.3833\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2182.2285 - mae: 2182.2285 - val_loss: 2065.5061 - val_mae: 2065.5061\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2039.6556 - mae: 2039.6556 - val_loss: 1928.8508 - val_mae: 1928.8508\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1902.8140 - mae: 1902.8140 - val_loss: 1797.8767 - val_mae: 1797.8767\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1771.3203 - mae: 1771.3206 - val_loss: 1675.6329 - val_mae: 1675.6329\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1648.4623 - mae: 1648.4623 - val_loss: 1562.2864 - val_mae: 1562.2864\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1531.8087 - mae: 1531.8087 - val_loss: 1456.1046 - val_mae: 1456.1046\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1420.7529 - mae: 1420.7529 - val_loss: 1354.4971 - val_mae: 1354.4971\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1314.0988 - mae: 1314.0988 - val_loss: 1258.7213 - val_mae: 1258.7213\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1214.1292 - mae: 1214.1292 - val_loss: 1170.4091 - val_mae: 1170.4091\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1121.2034 - mae: 1121.2034 - val_loss: 1091.0837 - val_mae: 1091.0837\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 1039.9879 - mae: 1039.9879 - val_loss: 1022.6172 - val_mae: 1022.6172\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 974.9522 - mae: 974.9522 - val_loss: 972.2417 - val_mae: 972.2417\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 927.3101 - mae: 927.3101 - val_loss: 935.8706 - val_mae: 935.8706\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 892.8630 - mae: 892.8630 - val_loss: 909.4563 - val_mae: 909.4563\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 868.0454 - mae: 868.0454 - val_loss: 892.3065 - val_mae: 892.3065\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 851.0982 - mae: 851.0982 - val_loss: 880.2827 - val_mae: 880.2827\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 839.2160 - mae: 839.2160 - val_loss: 872.0599 - val_mae: 872.0599\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 830.5927 - mae: 830.5927 - val_loss: 866.0202 - val_mae: 866.0202\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 824.5755 - mae: 824.5755 - val_loss: 861.9528 - val_mae: 861.9528\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 819.9684 - mae: 819.9684 - val_loss: 858.8992 - val_mae: 858.8992\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 816.7134 - mae: 816.7134 - val_loss: 856.8930 - val_mae: 856.8930\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 814.6161 - mae: 814.6161 - val_loss: 855.7404 - val_mae: 855.7404\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 813.1969 - mae: 813.1969 - val_loss: 855.1475 - val_mae: 855.1475\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 812.1823 - mae: 812.1823 - val_loss: 854.7492 - val_mae: 854.7492\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 811.4577 - mae: 811.4577 - val_loss: 854.5239 - val_mae: 854.5239\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 810.9462 - mae: 810.9462 - val_loss: 854.4100 - val_mae: 854.4100\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 810.5917 - mae: 810.5917 - val_loss: 854.3631 - val_mae: 854.3631\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 810.3044 - mae: 810.3044 - val_loss: 854.4056 - val_mae: 854.4056\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 810.1808 - mae: 810.1808 - val_loss: 854.4708 - val_mae: 854.4708\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 810.1014 - mae: 810.1014 - val_loss: 854.4564 - val_mae: 854.4564\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit64_lr1_sigmoid_50 = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit64_lr1_sigmoid_50.summary()\n",
    "\n",
    "simple_model_three_asii_unit64_lr1_sigmoid_50.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit64_lr1_sigmoid_50_50 = simple_model_three_asii_unit64_lr1_sigmoid_50.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit64_lr1_sigmoid_50 = simple_model_three_asii_unit64_lr1_sigmoid_50.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 6s 75ms/step - loss: 5565.2729 - mae: 5565.2729 - val_loss: 5424.6636 - val_mae: 5424.6636\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 5379.8950 - mae: 5379.8950 - val_loss: 5239.7588 - val_mae: 5239.7588\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 5195.3091 - mae: 5195.3091 - val_loss: 5055.4126 - val_mae: 5055.4126\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 5011.0889 - mae: 5011.0889 - val_loss: 4871.2979 - val_mae: 4871.2979\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 4827.0410 - mae: 4827.0410 - val_loss: 4687.3096 - val_mae: 4687.3096\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 4643.0938 - mae: 4643.0938 - val_loss: 4503.4019 - val_mae: 4503.4019\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 4459.2153 - mae: 4459.2153 - val_loss: 4319.5488 - val_mae: 4319.5488\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 4275.3813 - mae: 4275.3813 - val_loss: 4135.7354 - val_mae: 4135.7354\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 4091.5840 - mae: 4091.5840 - val_loss: 3951.9524 - val_mae: 3951.9524\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 3907.8125 - mae: 3907.8125 - val_loss: 3768.1934 - val_mae: 3768.1934\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 3724.0630 - mae: 3724.0630 - val_loss: 3584.4529 - val_mae: 3584.4529\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 3540.3308 - mae: 3540.3308 - val_loss: 3400.7288 - val_mae: 3400.7288\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3356.6138 - mae: 3356.6138 - val_loss: 3217.0186 - val_mae: 3217.0186\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3172.9128 - mae: 3172.9128 - val_loss: 3033.3716 - val_mae: 3033.3716\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2989.4216 - mae: 2989.4216 - val_loss: 2850.3914 - val_mae: 2850.3914\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2806.6150 - mae: 2806.6150 - val_loss: 2668.6646 - val_mae: 2668.6646\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2625.3782 - mae: 2625.3782 - val_loss: 2490.8118 - val_mae: 2490.8118\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2447.9712 - mae: 2447.9712 - val_loss: 2315.2617 - val_mae: 2315.2617\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2275.3870 - mae: 2275.3870 - val_loss: 2148.5002 - val_mae: 2148.5002\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2115.8894 - mae: 2115.8894 - val_loss: 1996.7927 - val_mae: 1996.7927\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 1966.8850 - mae: 1966.8850 - val_loss: 1853.8840 - val_mae: 1853.8840\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 1824.0161 - mae: 1824.0161 - val_loss: 1718.9064 - val_mae: 1718.9064\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1689.0345 - mae: 1689.0345 - val_loss: 1595.9541 - val_mae: 1595.9541\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1562.7102 - mae: 1562.7102 - val_loss: 1479.7078 - val_mae: 1479.7078\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1441.5024 - mae: 1441.5024 - val_loss: 1370.2985 - val_mae: 1370.2985\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1326.5303 - mae: 1326.5303 - val_loss: 1266.1650 - val_mae: 1266.1650\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1218.2875 - mae: 1218.2875 - val_loss: 1170.7260 - val_mae: 1170.7260\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 1118.7278 - mae: 1118.7278 - val_loss: 1084.8578 - val_mae: 1084.8578\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 1032.0182 - mae: 1032.0182 - val_loss: 1014.3192 - val_mae: 1014.3192\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 964.7055 - mae: 964.7055 - val_loss: 962.7084 - val_mae: 962.7084\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 916.6078 - mae: 916.6078 - val_loss: 926.0599 - val_mae: 926.0599\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 882.1671 - mae: 882.1671 - val_loss: 901.8415 - val_mae: 901.8415\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 859.4009 - mae: 859.4009 - val_loss: 885.5853 - val_mae: 885.5853\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 843.9804 - mae: 843.9804 - val_loss: 875.0604 - val_mae: 875.0604\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 833.7002 - mae: 833.7002 - val_loss: 867.9988 - val_mae: 867.9988\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 826.3948 - mae: 826.3948 - val_loss: 862.9655 - val_mae: 862.9655\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 821.0954 - mae: 821.0954 - val_loss: 859.4600 - val_mae: 859.4600\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 817.3500 - mae: 817.3500 - val_loss: 857.3129 - val_mae: 857.3129\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 814.9794 - mae: 814.9794 - val_loss: 856.0093 - val_mae: 856.0093\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 813.3604 - mae: 813.3604 - val_loss: 855.1957 - val_mae: 855.1957\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 812.2359 - mae: 812.2359 - val_loss: 854.7734 - val_mae: 854.7734\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 811.4491 - mae: 811.4491 - val_loss: 854.5009 - val_mae: 854.5009\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 810.8727 - mae: 810.8727 - val_loss: 854.3991 - val_mae: 854.3991\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 810.4836 - mae: 810.4836 - val_loss: 854.3820 - val_mae: 854.3820\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 810.3029 - mae: 810.3029 - val_loss: 854.4074 - val_mae: 854.4074\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 810.1931 - mae: 810.1931 - val_loss: 854.4345 - val_mae: 854.4345\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 810.1450 - mae: 810.1450 - val_loss: 854.4907 - val_mae: 854.4907\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 810.0221 - mae: 810.0221 - val_loss: 854.5112 - val_mae: 854.5112\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 810.0593 - mae: 810.0593 - val_loss: 854.5329 - val_mae: 854.5329\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 810.0549 - mae: 810.0549 - val_loss: 854.7462 - val_mae: 854.7462\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 810.0186 - mae: 810.0186 - val_loss: 854.7084 - val_mae: 854.7084\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 810.0345 - mae: 810.0345 - val_loss: 854.7588 - val_mae: 854.7588\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 809.9844 - mae: 809.9844 - val_loss: 854.7471 - val_mae: 854.7471\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 809.9707 - mae: 809.9707 - val_loss: 854.6760 - val_mae: 854.6760\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 810.0015 - mae: 810.0015 - val_loss: 854.7448 - val_mae: 854.7448\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 809.9351 - mae: 809.9351 - val_loss: 854.7555 - val_mae: 854.7555\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 809.9166 - mae: 809.9166 - val_loss: 854.7665 - val_mae: 854.7665\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 809.9314 - mae: 809.9314 - val_loss: 854.9019 - val_mae: 854.9019\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 809.9389 - mae: 809.9389 - val_loss: 854.8248 - val_mae: 854.8248\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 809.9368 - mae: 809.9368 - val_loss: 854.8710 - val_mae: 854.8710\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 809.8979 - mae: 809.8979 - val_loss: 854.8085 - val_mae: 854.8085\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 809.9255 - mae: 809.9255 - val_loss: 854.7614 - val_mae: 854.7614\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 809.9121 - mae: 809.9121 - val_loss: 854.8549 - val_mae: 854.8549\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 809.9194 - mae: 809.9194 - val_loss: 854.8963 - val_mae: 854.8963\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 809.9202 - mae: 809.9202 - val_loss: 854.8962 - val_mae: 854.8962\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 809.9500 - mae: 809.9500 - val_loss: 854.9757 - val_mae: 854.9757\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 809.9319 - mae: 809.9319 - val_loss: 854.9949 - val_mae: 854.9949\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 809.9443 - mae: 809.9443 - val_loss: 854.8618 - val_mae: 854.8618\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 809.9813 - mae: 809.9813 - val_loss: 854.8694 - val_mae: 854.8694\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 809.9666 - mae: 809.9666 - val_loss: 854.7972 - val_mae: 854.7972\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 810.0490 - mae: 810.0490 - val_loss: 854.8099 - val_mae: 854.8099\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 809.9347 - mae: 809.9347 - val_loss: 854.9331 - val_mae: 854.9331\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 809.9971 - mae: 809.9971 - val_loss: 854.9247 - val_mae: 854.9247\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 809.9121 - mae: 809.9121 - val_loss: 854.9318 - val_mae: 854.9318\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 809.9223 - mae: 809.9223 - val_loss: 854.8042 - val_mae: 854.8042\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 810.0212 - mae: 810.0212 - val_loss: 854.7800 - val_mae: 854.7800\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 810.0400 - mae: 810.0400 - val_loss: 854.8787 - val_mae: 854.8787\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 809.9707 - mae: 809.9707 - val_loss: 854.8842 - val_mae: 854.8842\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 809.9451 - mae: 809.9451 - val_loss: 854.7988 - val_mae: 854.7988\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 809.9568 - mae: 809.9568 - val_loss: 854.8163 - val_mae: 854.8163\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 810.0498 - mae: 810.0498 - val_loss: 854.8904 - val_mae: 854.8904\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 809.9702 - mae: 809.9702 - val_loss: 854.7402 - val_mae: 854.7402\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 810.1271 - mae: 810.1271 - val_loss: 854.9251 - val_mae: 854.9251\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 810.1191 - mae: 810.1191 - val_loss: 855.0080 - val_mae: 855.0080\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 810.0217 - mae: 810.0217 - val_loss: 854.8978 - val_mae: 854.8978\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 809.9736 - mae: 809.9736 - val_loss: 854.8713 - val_mae: 854.8713\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 809.9849 - mae: 809.9849 - val_loss: 854.9408 - val_mae: 854.9408\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 809.9342 - mae: 809.9342 - val_loss: 854.8831 - val_mae: 854.8831\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 809.9896 - mae: 809.9896 - val_loss: 854.9497 - val_mae: 854.9497\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 810.0221 - mae: 810.0221 - val_loss: 854.8619 - val_mae: 854.8619\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 809.9830 - mae: 809.9830 - val_loss: 854.8475 - val_mae: 854.8475\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 809.9883 - mae: 809.9883 - val_loss: 854.8586 - val_mae: 854.8586\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 810.0440 - mae: 810.0440 - val_loss: 854.9523 - val_mae: 854.9523\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 810.0366 - mae: 810.0366 - val_loss: 855.0677 - val_mae: 855.0677\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 810.2267 - mae: 810.2267 - val_loss: 854.7638 - val_mae: 854.7638\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 809.9906 - mae: 809.9906 - val_loss: 854.8524 - val_mae: 854.8524\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 810.1701 - mae: 810.1701 - val_loss: 854.9016 - val_mae: 854.9016\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 810.1081 - mae: 810.1081 - val_loss: 854.6689 - val_mae: 854.6689\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 810.0270 - mae: 810.0270 - val_loss: 854.8085 - val_mae: 854.8085\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 810.1123 - mae: 810.1123 - val_loss: 854.6860 - val_mae: 854.6860\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit64_lr1_sigmoid_100 = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit64_lr1_sigmoid_100.summary()\n",
    "\n",
    "simple_model_three_asii_unit64_lr1_sigmoid_100.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit64_lr1_sigmoid_100_100 = simple_model_three_asii_unit64_lr1_sigmoid_100.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit64_lr1_sigmoid_100 = simple_model_three_asii_unit64_lr1_sigmoid_100.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 8s 94ms/step - loss: 6130.6235 - mae: 6130.6235 - val_loss: 5906.0146 - val_mae: 5906.0146\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 5950.6416 - mae: 5950.6416 - val_loss: 5726.4639 - val_mae: 5726.4639\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 5771.3452 - mae: 5771.3452 - val_loss: 5547.3604 - val_mae: 5547.3604\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 5592.3447 - mae: 5592.3447 - val_loss: 5368.4438 - val_mae: 5368.4438\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 5413.4810 - mae: 5413.4810 - val_loss: 5189.6294 - val_mae: 5189.6294\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 5234.7012 - mae: 5234.7012 - val_loss: 5010.8799 - val_mae: 5010.8799\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 5055.9722 - mae: 5055.9722 - val_loss: 4832.1743 - val_mae: 4832.1743\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 4877.3643 - mae: 4877.3643 - val_loss: 4654.2925 - val_mae: 4654.2925\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 4701.8022 - mae: 4701.8022 - val_loss: 4482.7754 - val_mae: 4482.7754\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 4533.5234 - mae: 4533.5234 - val_loss: 4320.4805 - val_mae: 4320.4805\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 4376.0962 - mae: 4376.0962 - val_loss: 4175.3032 - val_mae: 4175.3032\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 4232.0811 - mae: 4232.0811 - val_loss: 4049.1863 - val_mae: 4049.1863\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 4114.0889 - mae: 4114.0889 - val_loss: 3955.0437 - val_mae: 3955.0437\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 4018.7205 - mae: 4018.7205 - val_loss: 3875.2095 - val_mae: 3875.2095\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 3936.0073 - mae: 3936.0073 - val_loss: 3799.5012 - val_mae: 3799.5012\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 3853.3376 - mae: 3853.3376 - val_loss: 3723.3796 - val_mae: 3723.3796\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3772.2886 - mae: 3772.2886 - val_loss: 3649.9592 - val_mae: 3649.9592\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 3694.1138 - mae: 3694.1138 - val_loss: 3578.0686 - val_mae: 3578.0686\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 3616.7285 - mae: 3616.7285 - val_loss: 3506.9326 - val_mae: 3506.9326\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3541.2515 - mae: 3541.2515 - val_loss: 3438.6914 - val_mae: 3438.6914\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 3467.9436 - mae: 3467.9436 - val_loss: 3369.9390 - val_mae: 3369.9390\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3396.6343 - mae: 3396.6343 - val_loss: 3307.2913 - val_mae: 3307.2913\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3328.8813 - mae: 3328.8813 - val_loss: 3245.6057 - val_mae: 3245.6057\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 3260.6184 - mae: 3260.6184 - val_loss: 3184.6201 - val_mae: 3184.6201\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3192.2617 - mae: 3192.2617 - val_loss: 3124.1030 - val_mae: 3124.1030\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 3124.3345 - mae: 3124.3345 - val_loss: 3061.1995 - val_mae: 3061.1995\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 3055.6528 - mae: 3055.6528 - val_loss: 3000.5303 - val_mae: 3000.5303\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2987.4854 - mae: 2987.4854 - val_loss: 2938.4556 - val_mae: 2938.455686.46\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2923.0703 - mae: 2923.0703 - val_loss: 2884.1794 - val_mae: 2884.1794\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2870.9529 - mae: 2870.9529 - val_loss: 2839.5454 - val_mae: 2839.5454\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2826.6399 - mae: 2826.6399 - val_loss: 2799.2419 - val_mae: 2799.2419\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 2786.9246 - mae: 2786.9246 - val_loss: 2763.2642 - val_mae: 2763.2642\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2753.4128 - mae: 2753.4128 - val_loss: 2732.9429 - val_mae: 2732.9429\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2725.5073 - mae: 2725.5073 - val_loss: 2709.5332 - val_mae: 2709.5332\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2702.9084 - mae: 2702.9084 - val_loss: 2689.9397 - val_mae: 2689.9397\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2683.1082 - mae: 2683.1082 - val_loss: 2672.5344 - val_mae: 2672.5344\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2664.9099 - mae: 2664.9099 - val_loss: 2655.0776 - val_mae: 2655.0776\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2646.9663 - mae: 2646.9663 - val_loss: 2638.7754 - val_mae: 2638.7754\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2629.2366 - mae: 2629.2366 - val_loss: 2622.2881 - val_mae: 2622.2881\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 2612.0852 - mae: 2612.0852 - val_loss: 2605.5205 - val_mae: 2605.5205\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2595.0298 - mae: 2595.0298 - val_loss: 2589.8423 - val_mae: 2589.8423\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2579.4990 - mae: 2579.4990 - val_loss: 2577.0647 - val_mae: 2577.0647\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2565.7014 - mae: 2565.7014 - val_loss: 2565.6094 - val_mae: 2565.6094\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2553.5342 - mae: 2553.5342 - val_loss: 2555.8823 - val_mae: 2555.8823\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2543.0300 - mae: 2543.0300 - val_loss: 2548.3052 - val_mae: 2548.3052\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2533.6416 - mae: 2533.6416 - val_loss: 2542.0503 - val_mae: 2542.0503\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2524.7673 - mae: 2524.7673 - val_loss: 2535.7163 - val_mae: 2535.7163\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2517.0383 - mae: 2517.0383 - val_loss: 2529.8823 - val_mae: 2529.8823\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2509.7571 - mae: 2509.7571 - val_loss: 2525.0117 - val_mae: 2525.0117\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 2502.9607 - mae: 2502.9607 - val_loss: 2520.4756 - val_mae: 2520.4756\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid_50 = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid_50.summary()\n",
    "\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid_50.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit64_lr1_sigmoid_50_50 = simple_model_three_icbp_unit64_lr1_sigmoid_50.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit64_lr1_sigmoid_50 = simple_model_three_icbp_unit64_lr1_sigmoid_50.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 6s 76ms/step - loss: 6134.4131 - mae: 6134.4131 - val_loss: 5913.7729 - val_mae: 5913.7729\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 5962.1128 - mae: 5962.1128 - val_loss: 5741.8857 - val_mae: 5741.8857\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 5790.4780 - mae: 5790.4780 - val_loss: 5570.4414 - val_mae: 5570.4414\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 5619.1333 - mae: 5619.1333 - val_loss: 5399.1802 - val_mae: 5399.1802\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 5447.9263 - mae: 5447.9263 - val_loss: 5228.0210 - val_mae: 5228.0210\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 5276.8003 - mae: 5276.8003 - val_loss: 5056.9248 - val_mae: 5056.9248\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 5105.7251 - mae: 5105.7251 - val_loss: 4885.8721 - val_mae: 4885.8721\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 4934.6929 - mae: 4934.6929 - val_loss: 4714.9312 - val_mae: 4714.9312\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 4764.8271 - mae: 4764.8271 - val_loss: 4548.2739 - val_mae: 4548.2739\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 4600.6235 - mae: 4600.6235 - val_loss: 4387.5083 - val_mae: 4387.5083\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 4444.2397 - mae: 4444.2397 - val_loss: 4241.4624 - val_mae: 4241.4624\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 4300.0684 - mae: 4300.0684 - val_loss: 4109.5449 - val_mae: 4109.5449\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 4172.6631 - mae: 4172.6631 - val_loss: 4005.3943 - val_mae: 4005.3943\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 4072.3494 - mae: 4072.3494 - val_loss: 3922.1450 - val_mae: 3922.1450\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 3987.3220 - mae: 3987.3220 - val_loss: 3848.4697 - val_mae: 3848.4697\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 3908.9619 - mae: 3908.9619 - val_loss: 3776.2258 - val_mae: 3776.2258\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 3829.9539 - mae: 3829.9539 - val_loss: 3704.1843 - val_mae: 3704.1843\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3752.9653 - mae: 3752.9653 - val_loss: 3633.4316 - val_mae: 3633.4316\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 3678.7688 - mae: 3678.7688 - val_loss: 3565.7693 - val_mae: 3565.7693\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 3605.0388 - mae: 3605.0388 - val_loss: 3497.9604 - val_mae: 3497.9604\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 3533.1233 - mae: 3533.1233 - val_loss: 3432.1257 - val_mae: 3432.1257\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 3462.8589 - mae: 3462.8589 - val_loss: 3366.4089 - val_mae: 3366.4089\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 3393.8606 - mae: 3393.8606 - val_loss: 3307.2944 - val_mae: 3307.2944\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 3329.5154 - mae: 3329.5154 - val_loss: 3246.7822 - val_mae: 3246.7822\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 3264.1257 - mae: 3264.1257 - val_loss: 3188.8308 - val_mae: 3188.8308\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 3199.2598 - mae: 3199.2598 - val_loss: 3129.0391 - val_mae: 3129.0391\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 3133.5117 - mae: 3133.5117 - val_loss: 3071.3711 - val_mae: 3071.3711\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 3068.2388 - mae: 3068.2388 - val_loss: 3012.0303 - val_mae: 3012.0303\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 3002.5642 - mae: 3002.5642 - val_loss: 2953.7549 - val_mae: 2953.7549\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2938.4246 - mae: 2938.4246 - val_loss: 2899.1184 - val_mae: 2899.1184\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2885.2817 - mae: 2885.2817 - val_loss: 2853.9143 - val_mae: 2853.9143\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2840.3577 - mae: 2840.3577 - val_loss: 2811.9756 - val_mae: 2811.9756\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2799.9199 - mae: 2799.9199 - val_loss: 2774.4644 - val_mae: 2774.4644\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2764.9758 - mae: 2764.9758 - val_loss: 2743.7461 - val_mae: 2743.7461\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 2735.6792 - mae: 2735.6792 - val_loss: 2719.1062 - val_mae: 2719.1062\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2712.3611 - mae: 2712.3611 - val_loss: 2698.2974 - val_mae: 2698.2974\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2691.6526 - mae: 2691.6526 - val_loss: 2680.1995 - val_mae: 2680.1995\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2673.2690 - mae: 2673.2690 - val_loss: 2663.4724 - val_mae: 2663.4724\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2655.5583 - mae: 2655.5583 - val_loss: 2647.3066 - val_mae: 2647.3066\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2638.7034 - mae: 2638.7034 - val_loss: 2631.3457 - val_mae: 2631.3457\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2622.4585 - mae: 2622.4585 - val_loss: 2615.5173 - val_mae: 2615.5173\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2606.0874 - mae: 2606.0874 - val_loss: 2600.4192 - val_mae: 2600.4192\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 2590.3926 - mae: 2590.3926 - val_loss: 2586.1895 - val_mae: 2586.1895\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2576.1846 - mae: 2576.1846 - val_loss: 2574.6836 - val_mae: 2574.6836\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 2563.2798 - mae: 2563.2798 - val_loss: 2563.2664 - val_mae: 2563.2664\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2551.4382 - mae: 2551.4382 - val_loss: 2554.6907 - val_mae: 2554.6907\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2541.8503 - mae: 2541.8503 - val_loss: 2547.5669 - val_mae: 2547.5669\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2532.8674 - mae: 2532.8674 - val_loss: 2540.9077 - val_mae: 2540.9077\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 2524.4031 - mae: 2524.4031 - val_loss: 2535.5417 - val_mae: 2535.5417\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2517.1577 - mae: 2517.1577 - val_loss: 2530.6760 - val_mae: 2530.6760\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2510.3491 - mae: 2510.3491 - val_loss: 2525.5652 - val_mae: 2525.5652\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2503.6272 - mae: 2503.6272 - val_loss: 2520.8171 - val_mae: 2520.8171\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 2497.4099 - mae: 2497.4099 - val_loss: 2516.5283 - val_mae: 2516.5283\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2491.6724 - mae: 2491.6724 - val_loss: 2512.1328 - val_mae: 2512.1328\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 2485.9089 - mae: 2485.9089 - val_loss: 2508.2507 - val_mae: 2508.2507\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 2480.2888 - mae: 2480.2888 - val_loss: 2504.7996 - val_mae: 2504.7996\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2475.4036 - mae: 2475.4036 - val_loss: 2501.5994 - val_mae: 2501.5994\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2470.7490 - mae: 2470.7490 - val_loss: 2499.0056 - val_mae: 2499.0056\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2466.9907 - mae: 2466.9907 - val_loss: 2497.1223 - val_mae: 2497.1223\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2463.8718 - mae: 2463.8718 - val_loss: 2495.9934 - val_mae: 2495.9934\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2461.1843 - mae: 2461.1843 - val_loss: 2494.8284 - val_mae: 2494.8284\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2458.8015 - mae: 2458.8015 - val_loss: 2493.8643 - val_mae: 2493.8643\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2456.1985 - mae: 2456.1985 - val_loss: 2493.1912 - val_mae: 2493.1912\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2454.0322 - mae: 2454.0322 - val_loss: 2492.5259 - val_mae: 2492.5259\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2452.0171 - mae: 2452.0171 - val_loss: 2492.0945 - val_mae: 2492.0945\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2449.9358 - mae: 2449.9358 - val_loss: 2491.8367 - val_mae: 2491.8367\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2448.1660 - mae: 2448.1660 - val_loss: 2491.5725 - val_mae: 2491.5725\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2446.4536 - mae: 2446.4536 - val_loss: 2491.4441 - val_mae: 2491.4441\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2444.7302 - mae: 2444.7302 - val_loss: 2491.3518 - val_mae: 2491.3518\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2443.2117 - mae: 2443.2117 - val_loss: 2491.3301 - val_mae: 2491.3301\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2441.7083 - mae: 2441.7083 - val_loss: 2491.3770 - val_mae: 2491.3770\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2440.1704 - mae: 2440.1704 - val_loss: 2491.5076 - val_mae: 2491.5076\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2438.9590 - mae: 2438.9590 - val_loss: 2491.7175 - val_mae: 2491.7175\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2437.9785 - mae: 2437.9785 - val_loss: 2492.0398 - val_mae: 2492.0398\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2437.3086 - mae: 2437.3086 - val_loss: 2492.3745 - val_mae: 2492.3745\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2436.6589 - mae: 2436.6589 - val_loss: 2492.5818 - val_mae: 2492.5818\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 2436.1772 - mae: 2436.1772 - val_loss: 2492.8665 - val_mae: 2492.8665\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2435.5234 - mae: 2435.5234 - val_loss: 2493.4714 - val_mae: 2493.4714\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2435.1995 - mae: 2435.1995 - val_loss: 2493.9204 - val_mae: 2493.9204\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2434.9148 - mae: 2434.9148 - val_loss: 2493.9961 - val_mae: 2493.9961\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2434.7026 - mae: 2434.7026 - val_loss: 2494.2393 - val_mae: 2494.2393\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2434.4360 - mae: 2434.4360 - val_loss: 2494.8843 - val_mae: 2494.8840\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2434.2476 - mae: 2434.2476 - val_loss: 2495.2229 - val_mae: 2495.2229\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2434.1152 - mae: 2434.1152 - val_loss: 2495.5601 - val_mae: 2495.5601\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2434.0703 - mae: 2434.0703 - val_loss: 2495.6848 - val_mae: 2495.6848\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 2433.7847 - mae: 2433.7847 - val_loss: 2496.2578 - val_mae: 2496.2578\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2433.6626 - mae: 2433.6626 - val_loss: 2496.7349 - val_mae: 2496.7349\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2433.6887 - mae: 2433.6887 - val_loss: 2497.2456 - val_mae: 2497.2456\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2433.6025 - mae: 2433.6025 - val_loss: 2497.1746 - val_mae: 2497.1746\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 2433.3975 - mae: 2433.3975 - val_loss: 2497.2764 - val_mae: 2497.2764\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2433.3687 - mae: 2433.3687 - val_loss: 2497.9714 - val_mae: 2497.9714\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2433.2244 - mae: 2433.2244 - val_loss: 2498.0376 - val_mae: 2498.0376\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 2433.1641 - mae: 2433.1641 - val_loss: 2498.2312 - val_mae: 2498.2312\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2433.2515 - mae: 2433.2515 - val_loss: 2498.3694 - val_mae: 2498.3694\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2433.1755 - mae: 2433.1755 - val_loss: 2498.6951 - val_mae: 2498.6951\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2433.0056 - mae: 2433.0056 - val_loss: 2499.0010 - val_mae: 2499.0010\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2432.9861 - mae: 2432.9861 - val_loss: 2499.3301 - val_mae: 2499.3301\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 2432.8879 - mae: 2432.8879 - val_loss: 2499.3682 - val_mae: 2499.3682\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 2433.0403 - mae: 2433.0403 - val_loss: 2499.4692 - val_mae: 2499.4692\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2432.9287 - mae: 2432.9287 - val_loss: 2499.5725 - val_mae: 2499.5725\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid_100 = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid_100.summary()\n",
    "\n",
    "simple_model_three_icbp_unit64_lr1_sigmoid_100.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit64_lr1_sigmoid_100_100 = simple_model_three_icbp_unit64_lr1_sigmoid_100.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit64_lr1_sigmoid_100 = simple_model_three_icbp_unit64_lr1_sigmoid_100.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 7s 90ms/step - loss: 4520.0503 - mae: 4520.0503 - val_loss: 4415.2134 - val_mae: 4415.2134\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 4309.2358 - mae: 4309.2358 - val_loss: 4204.8931 - val_mae: 4204.8931\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 4099.2119 - mae: 4099.2119 - val_loss: 3995.0925 - val_mae: 3995.0925\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 3889.5295 - mae: 3889.5295 - val_loss: 3785.5090 - val_mae: 3785.5090\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 3680.0088 - mae: 3680.0088 - val_loss: 3576.0437 - val_mae: 3576.0437\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 3470.5820 - mae: 3470.5820 - val_loss: 3366.6536 - val_mae: 3366.6536\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 3261.2183 - mae: 3261.2183 - val_loss: 3157.3196 - val_mae: 3157.3196\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3052.3101 - mae: 3052.3101 - val_loss: 2950.3459 - val_mae: 2950.3459\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 2848.9968 - mae: 2848.9968 - val_loss: 2752.1531 - val_mae: 2752.1531\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2654.6023 - mae: 2654.6023 - val_loss: 2561.3054 - val_mae: 2561.3054\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2461.8318 - mae: 2461.8318 - val_loss: 2370.4163 - val_mae: 2370.4163\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 2269.8428 - mae: 2269.8428 - val_loss: 2184.5518 - val_mae: 2184.5518\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 2080.9153 - mae: 2080.9153 - val_loss: 2003.5845 - val_mae: 2003.5845\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 1901.1709 - mae: 1901.1709 - val_loss: 1836.6963 - val_mae: 1836.6963\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 1735.7115 - mae: 1735.7115 - val_loss: 1688.3768 - val_mae: 1688.3768\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 1586.2443 - mae: 1586.2443 - val_loss: 1555.5687 - val_mae: 1555.5687\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 1447.7937 - mae: 1447.7937 - val_loss: 1430.1967 - val_mae: 1430.1967\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 1322.7510 - mae: 1322.7510 - val_loss: 1319.6794 - val_mae: 1319.6794\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 1214.9569 - mae: 1214.9569 - val_loss: 1221.3837 - val_mae: 1221.3837\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 1120.0428 - mae: 1120.0427 - val_loss: 1136.5924 - val_mae: 1136.5924\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 1042.4138 - mae: 1042.4138 - val_loss: 1073.0376 - val_mae: 1073.0376\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 983.4625 - mae: 983.4625 - val_loss: 1024.1378 - val_mae: 1024.1378\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 939.2797 - mae: 939.2797 - val_loss: 988.0189 - val_mae: 988.0189\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 907.0820 - mae: 907.0820 - val_loss: 958.2936 - val_mae: 958.2936\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 882.1509 - mae: 882.1509 - val_loss: 937.3150 - val_mae: 937.3150\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 865.2093 - mae: 865.2093 - val_loss: 921.6743 - val_mae: 921.6743\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 854.1785 - mae: 854.1785 - val_loss: 911.6115 - val_mae: 911.6115\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 847.2028 - mae: 847.2028 - val_loss: 905.0303 - val_mae: 905.0303\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 842.7377 - mae: 842.7377 - val_loss: 900.6461 - val_mae: 900.6461\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 840.0383 - mae: 840.0383 - val_loss: 897.4063 - val_mae: 897.4063\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 838.6672 - mae: 838.6672 - val_loss: 895.6168 - val_mae: 895.6168\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 837.9223 - mae: 837.9223 - val_loss: 894.1924 - val_mae: 894.1924\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 837.5452 - mae: 837.5452 - val_loss: 893.0182 - val_mae: 893.0182\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 837.1680 - mae: 837.1679 - val_loss: 892.4444 - val_mae: 892.4444\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 836.9855 - mae: 836.9855 - val_loss: 892.1625 - val_mae: 892.1625\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 836.7198 - mae: 836.7198 - val_loss: 891.6440 - val_mae: 891.6440\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 836.5806 - mae: 836.5806 - val_loss: 891.0825 - val_mae: 891.0825\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 836.6407 - mae: 836.6407 - val_loss: 890.9724 - val_mae: 890.9724\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 836.4888 - mae: 836.4888 - val_loss: 890.6324 - val_mae: 890.6324\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 836.4996 - mae: 836.4996 - val_loss: 890.4803 - val_mae: 890.4803\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 836.5825 - mae: 836.5825 - val_loss: 890.3421 - val_mae: 890.3421\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 836.4328 - mae: 836.4328 - val_loss: 890.3976 - val_mae: 890.3976\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 836.4611 - mae: 836.4611 - val_loss: 890.2816 - val_mae: 890.2816\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 836.5328 - mae: 836.5328 - val_loss: 890.0807 - val_mae: 890.0807\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 836.4537 - mae: 836.4537 - val_loss: 890.5289 - val_mae: 890.5289\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 836.5558 - mae: 836.5558 - val_loss: 890.2029 - val_mae: 890.2029\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 836.4692 - mae: 836.4692 - val_loss: 890.2086 - val_mae: 890.2086\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 836.5159 - mae: 836.5159 - val_loss: 890.0173 - val_mae: 890.0173\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 836.4271 - mae: 836.4271 - val_loss: 890.0521 - val_mae: 890.0521\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 836.4699 - mae: 836.4699 - val_loss: 890.0491 - val_mae: 890.0491\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid_50 = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid_50.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid_50.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit64_lr1_sigmoid_50_50 = simple_model_three_jsmr_unit64_lr1_sigmoid_50.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit64_lr1_sigmoid_50 = simple_model_three_jsmr_unit64_lr1_sigmoid_50.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 7s 91ms/step - loss: 4534.2334 - mae: 4534.2334 - val_loss: 4443.9463 - val_mae: 4443.9463\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 4351.5669 - mae: 4351.5669 - val_loss: 4261.6982 - val_mae: 4261.6982\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 4169.6128 - mae: 4169.6128 - val_loss: 4079.9634 - val_mae: 4079.9634\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 3987.9946 - mae: 3987.9946 - val_loss: 3898.4436 - val_mae: 3898.4436\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3806.5359 - mae: 3806.5359 - val_loss: 3717.0393 - val_mae: 3717.0393\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 3625.1692 - mae: 3625.1692 - val_loss: 3535.7073 - val_mae: 3535.7073\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3443.0242 - mae: 3443.0242 - val_loss: 3350.4688 - val_mae: 3350.4688\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3255.1804 - mae: 3255.1804 - val_loss: 3162.5632 - val_mae: 3162.5632\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 3068.5928 - mae: 3068.5928 - val_loss: 2977.8899 - val_mae: 2977.8899\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 2887.3411 - mae: 2887.3411 - val_loss: 2801.3000 - val_mae: 2801.3000\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2713.4324 - mae: 2713.4324 - val_loss: 2631.0176 - val_mae: 2631.0176\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2543.0664 - mae: 2543.0664 - val_loss: 2461.7493 - val_mae: 2461.7493\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2373.1814 - mae: 2373.1814 - val_loss: 2295.8494 - val_mae: 2295.8494\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 2204.8303 - mae: 2204.8303 - val_loss: 2132.8118 - val_mae: 2132.8118\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 2039.1322 - mae: 2039.1322 - val_loss: 1975.1260 - val_mae: 1975.1260\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 1882.3214 - mae: 1882.3214 - val_loss: 1828.3730 - val_mae: 1828.3730\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 1737.1708 - mae: 1737.1708 - val_loss: 1698.7054 - val_mae: 1698.7054\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1605.7161 - mae: 1605.7161 - val_loss: 1581.8416 - val_mae: 1581.8416\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 1481.9093 - mae: 1481.9093 - val_loss: 1469.6718 - val_mae: 1469.6718\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1367.1746 - mae: 1367.1746 - val_loss: 1365.1783 - val_mae: 1365.1783\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1265.6771 - mae: 1265.6771 - val_loss: 1273.6514 - val_mae: 1273.6514\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 1175.1941 - mae: 1175.1941 - val_loss: 1190.8691 - val_mae: 1190.8691\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 1096.2041 - mae: 1096.2041 - val_loss: 1121.5062 - val_mae: 1121.5062\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 1032.0436 - mae: 1032.0436 - val_loss: 1067.9142 - val_mae: 1067.9142\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 981.3374 - mae: 981.3374 - val_loss: 1025.2104 - val_mae: 1025.2104\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 941.8513 - mae: 941.8513 - val_loss: 992.8936 - val_mae: 992.8936\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 912.1213 - mae: 912.1213 - val_loss: 966.0323 - val_mae: 966.0323\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 888.0891 - mae: 888.0891 - val_loss: 943.7361 - val_mae: 943.7361\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 870.7719 - mae: 870.7719 - val_loss: 927.6057 - val_mae: 927.6057\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 858.8951 - mae: 858.8951 - val_loss: 917.1945 - val_mae: 917.1945\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 851.1448 - mae: 851.1448 - val_loss: 909.1140 - val_mae: 909.1140\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 845.7712 - mae: 845.7712 - val_loss: 903.9763 - val_mae: 903.9763\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 842.2874 - mae: 842.2874 - val_loss: 899.9189 - val_mae: 899.9189\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 840.2454 - mae: 840.2454 - val_loss: 897.3640 - val_mae: 897.3640\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 838.9918 - mae: 838.9918 - val_loss: 896.1902 - val_mae: 896.1902\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 838.3801 - mae: 838.3801 - val_loss: 894.8400 - val_mae: 894.8400\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 837.6685 - mae: 837.6685 - val_loss: 893.6346 - val_mae: 893.6346\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 837.3273 - mae: 837.3273 - val_loss: 892.9461 - val_mae: 892.9461\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 837.0300 - mae: 837.0300 - val_loss: 892.1027 - val_mae: 892.1027\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.9200 - mae: 836.9200 - val_loss: 891.9028 - val_mae: 891.9028\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.6776 - mae: 836.6776 - val_loss: 891.3721 - val_mae: 891.3721\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.6120 - mae: 836.6120 - val_loss: 891.1799 - val_mae: 891.1799\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.6083 - mae: 836.6083 - val_loss: 890.9688 - val_mae: 890.9688\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.6201 - mae: 836.6201 - val_loss: 890.3987 - val_mae: 890.3987\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4810 - mae: 836.4810 - val_loss: 890.5721 - val_mae: 890.5721\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4869 - mae: 836.4869 - val_loss: 890.4892 - val_mae: 890.4892\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4702 - mae: 836.4702 - val_loss: 890.3783 - val_mae: 890.3783\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.5157 - mae: 836.5157 - val_loss: 890.2454 - val_mae: 890.2454\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4927 - mae: 836.4927 - val_loss: 890.3715 - val_mae: 890.3715\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4598 - mae: 836.4598 - val_loss: 890.2291 - val_mae: 890.2291\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4316 - mae: 836.4316 - val_loss: 890.0495 - val_mae: 890.0495\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4524 - mae: 836.4524 - val_loss: 889.9952 - val_mae: 889.9952\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4299 - mae: 836.4299 - val_loss: 889.9558 - val_mae: 889.9558\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4095 - mae: 836.4095 - val_loss: 890.0183 - val_mae: 890.0183\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4177 - mae: 836.4177 - val_loss: 890.2607 - val_mae: 890.2607\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4932 - mae: 836.4932 - val_loss: 890.2882 - val_mae: 890.2882\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.5771 - mae: 836.5771 - val_loss: 889.9291 - val_mae: 889.9291\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4107 - mae: 836.4107 - val_loss: 889.9662 - val_mae: 889.9662\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4998 - mae: 836.4998 - val_loss: 890.1251 - val_mae: 890.1251\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4424 - mae: 836.4424 - val_loss: 890.0536 - val_mae: 890.0536\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4499 - mae: 836.4499 - val_loss: 890.0287 - val_mae: 890.0287\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4481 - mae: 836.4481 - val_loss: 890.1509 - val_mae: 890.1509\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4750 - mae: 836.4750 - val_loss: 889.8790 - val_mae: 889.8790\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5576 - mae: 836.5576 - val_loss: 889.6375 - val_mae: 889.6375\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 836.6600 - mae: 836.6600 - val_loss: 890.1996 - val_mae: 890.1996\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4448 - mae: 836.4448 - val_loss: 890.1999 - val_mae: 890.1999\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5195 - mae: 836.5195 - val_loss: 890.2142 - val_mae: 890.2142\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5101 - mae: 836.5101 - val_loss: 890.1401 - val_mae: 890.1401\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4595 - mae: 836.4595 - val_loss: 890.2477 - val_mae: 890.2477\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4420 - mae: 836.4420 - val_loss: 890.0906 - val_mae: 890.0906\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4457 - mae: 836.4457 - val_loss: 890.2392 - val_mae: 890.2392\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4755 - mae: 836.4755 - val_loss: 890.0889 - val_mae: 890.0889\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4290 - mae: 836.4290 - val_loss: 889.8309 - val_mae: 889.8309\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4538 - mae: 836.4538 - val_loss: 889.8270 - val_mae: 889.8270\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5894 - mae: 836.5894 - val_loss: 889.7952 - val_mae: 889.7952\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5476 - mae: 836.5476 - val_loss: 889.7769 - val_mae: 889.7769\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4449 - mae: 836.4449 - val_loss: 889.8486 - val_mae: 889.8486\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4807 - mae: 836.4807 - val_loss: 889.9595 - val_mae: 889.9595\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.6109 - mae: 836.6109 - val_loss: 889.7966 - val_mae: 889.7966\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4780 - mae: 836.4780 - val_loss: 890.2162 - val_mae: 890.2162\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4879 - mae: 836.4879 - val_loss: 890.0078 - val_mae: 890.0078\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.5461 - mae: 836.5461 - val_loss: 890.4804 - val_mae: 890.4804\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4128 - mae: 836.4128 - val_loss: 889.7977 - val_mae: 889.7977\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4515 - mae: 836.4515 - val_loss: 889.9005 - val_mae: 889.9005\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5322 - mae: 836.5322 - val_loss: 889.9430 - val_mae: 889.9430\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.5207 - mae: 836.5207 - val_loss: 890.2326 - val_mae: 890.2326\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5121 - mae: 836.5121 - val_loss: 890.2288 - val_mae: 890.2288\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4790 - mae: 836.4790 - val_loss: 890.2330 - val_mae: 890.2330\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.4571 - mae: 836.4571 - val_loss: 890.5176 - val_mae: 890.5176\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5003 - mae: 836.5003 - val_loss: 890.2408 - val_mae: 890.2408\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.5576 - mae: 836.5576 - val_loss: 889.8970 - val_mae: 889.8970\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5771 - mae: 836.5771 - val_loss: 890.2955 - val_mae: 890.2955\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4528 - mae: 836.4528 - val_loss: 889.6063 - val_mae: 889.6063\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5262 - mae: 836.5262 - val_loss: 890.1210 - val_mae: 890.1210\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.5815 - mae: 836.5815 - val_loss: 889.9095 - val_mae: 889.9095\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4794 - mae: 836.4794 - val_loss: 890.0162 - val_mae: 890.0162\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.6614 - mae: 836.6614 - val_loss: 889.9328 - val_mae: 889.9328\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.4642 - mae: 836.4642 - val_loss: 889.8565 - val_mae: 889.8565\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 836.7961 - mae: 836.7961 - val_loss: 889.8511 - val_mae: 889.8511\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 836.6253 - mae: 836.6253 - val_loss: 889.4273 - val_mae: 889.4273\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid_100 = Sequential([\n",
    "  LSTM(64, activation='sigmoid',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid',return_sequences=True),\n",
    "  LSTM(64, activation='sigmoid'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid_100.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr1_sigmoid_100.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit64_lr1_sigmoid_100_100 = simple_model_three_jsmr_unit64_lr1_sigmoid_100.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit64_lr1_sigmoid_100 = simple_model_three_jsmr_unit64_lr1_sigmoid_100.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAtriks evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50\n",
      "mae score antm: 405.59\n",
      "mape score antm: 0.45\n",
      "r2 score antm: -12984294681.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "print('epoch 50')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit64_lr1_sigmoid_50, y_test_antm).round(2)))\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit64_lr1_sigmoid_50, y_test_antm).round(2)))\n",
    "print(\"r2 score antm: \"+str(r2_score(preds_three_antm_unit64_lr1_sigmoid_50, y_test_antm).round(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score asii: 838.63\n",
      "mape score asii: 0.15\n",
      "r2 score asii: -8191468492.45\n"
     ]
    }
   ],
   "source": [
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit64_lr1_sigmoid_50, y_test_asii).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit64_lr1_sigmoid_50, y_test_asii).round(2)))\n",
    "print(\"r2 score asii: \"+str(r2_score(preds_three_asii_unit64_lr1_sigmoid_50, y_test_asii).round(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score icbp: 2578.36\n",
      "mape score icbp: 0.44\n",
      "r2 score icbp: -26195976059.98\n"
     ]
    }
   ],
   "source": [
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit64_lr1_sigmoid_50, y_test_icbp).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit64_lr1_sigmoid_50, y_test_icbp).round(2)))\n",
    "print(\"r2 score icbp: \"+str(r2_score(preds_three_icbp_unit64_lr1_sigmoid_50, y_test_icbp).round(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score jsmr: 874.42\n",
      "mape score jsmr: 0.19\n",
      "r2 score jsmr: -176745391530.0\n"
     ]
    }
   ],
   "source": [
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit64_lr1_sigmoid_50, y_test_jsmr).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit64_lr1_sigmoid_50, y_test_jsmr).round(2)))\n",
    "print(\"r2 score jsmr: \"+str(r2_score(preds_three_jsmr_unit64_lr1_sigmoid_50, y_test_jsmr).round(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n",
      "mae score antm: 405.71\n",
      "mape score antm: 0.45\n",
      "r2 score antm: -52824657596.16\n"
     ]
    }
   ],
   "source": [
    "print('epoch 100')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit64_lr1_sigmoid_100, y_test_antm).round(2)))\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit64_lr1_sigmoid_100, y_test_antm).round(2)))\n",
    "print(\"r2 score antm: \"+str(r2_score(preds_three_antm_unit64_lr1_sigmoid_100, y_test_antm).round(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score asii: 838.63\n",
      "mape score asii: 0.15\n",
      "r2 score asii: -10625501934.11\n"
     ]
    }
   ],
   "source": [
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit64_lr1_sigmoid_100, y_test_asii).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit64_lr1_sigmoid_100, y_test_asii).round(2)))\n",
    "print(\"r2 score asii: \"+str(r2_score(preds_three_asii_unit64_lr1_sigmoid_100, y_test_asii).round(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score icbp: 2485.69\n",
      "mape score icbp: 0.36\n",
      "r2 score icbp: -10050772263.24\n"
     ]
    }
   ],
   "source": [
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit64_lr1_sigmoid_100, y_test_icbp).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit64_lr1_sigmoid_100, y_test_icbp).round(2)))\n",
    "print(\"r2 score icbp: \"+str(r2_score(preds_three_icbp_unit64_lr1_sigmoid_100, y_test_icbp).round(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae score jsmr: 874.66\n",
      "mape score jsmr: 0.19\n",
      "r2 score jsmr: -265214429641.12\n"
     ]
    }
   ],
   "source": [
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit64_lr1_sigmoid_100, y_test_jsmr).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit64_lr1_sigmoid_100, y_test_jsmr).round(2)))\n",
    "print(\"r2 score jsmr: \"+str(r2_score(preds_three_jsmr_unit64_lr1_sigmoid_100, y_test_jsmr).round(2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3816365fdcd687a07caedfe721e5894fb1dd0a24482efb967fc5a605423a1021"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
