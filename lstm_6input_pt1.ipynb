{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import date, datetime\n",
    "from multiprocessing.spawn import import_main_path\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "# print(today)\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2022-06-27'\n",
    "\n",
    "panel_data_antm = data.DataReader('ANTM.JK','yahoo',start_date, end_date)\n",
    "panel_data_asii = data.DataReader('ASII.JK','yahoo',start_date, end_date)\n",
    "panel_data_icbp = data.DataReader('ICBP.JK','yahoo',start_date, end_date)\n",
    "panel_data_jsmr = data.DataReader('JSMR.JK','yahoo',start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDING NEW VARIABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#antm\n",
    "panel_data_antm['average'] = panel_data_antm[['Open','Close','High','Low']].mean(axis=1).round(2)\n",
    "panel_data_antm['daily_return'] = panel_data_antm['Open'] - panel_data_antm['Close']\n",
    "#asii\n",
    "panel_data_asii['average'] = panel_data_asii[['Open','Close','High','Low']].mean(axis=1).round(2)\n",
    "panel_data_asii['daily_return'] = panel_data_asii['Open'] - panel_data_asii['Close']\n",
    "#icbp\n",
    "panel_data_icbp['average'] = panel_data_icbp[['Open','Close','High','Low']].mean(axis=1).round(2)\n",
    "panel_data_icbp['daily_return'] = panel_data_icbp['Open'] - panel_data_icbp['Close']\n",
    "#jsmr\n",
    "panel_data_jsmr['average'] = panel_data_jsmr[['Open','Close','High','Low']].mean(axis=1).round(2)\n",
    "panel_data_jsmr['daily_return'] = panel_data_jsmr['Open'] - panel_data_jsmr['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm = pd.DataFrame(panel_data_antm)\n",
    "df_asii = pd.DataFrame(panel_data_asii)\n",
    "df_icbp = pd.DataFrame(panel_data_icbp)\n",
    "df_jsmr = pd.DataFrame(panel_data_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a min max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_antm = pd.DataFrame(scaler.fit_transform(panel_data_antm),columns=['high','low','open','close','volume','adj_close','average','daily_return'])\n",
    "df_asii = pd.DataFrame(scaler.fit_transform(panel_data_asii),columns=['high','low','open','close','volume','adj_close','average','daily_return'])\n",
    "df_icbp = pd.DataFrame(scaler.fit_transform(panel_data_icbp),columns=['high','low','open','close','volume','adj_close','average','daily_return'])\n",
    "df_jsmr = pd.DataFrame(scaler.fit_transform(panel_data_jsmr),columns=['high','low','open','close','volume','adj_close','average','daily_return'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antm.drop(columns=['adj_close','volume'], inplace=True)\n",
    "df_asii.drop(columns=['adj_close','volume'], inplace=True)\n",
    "df_icbp.drop(columns=['adj_close','volume'], inplace=True)\n",
    "df_jsmr.drop(columns=['adj_close','volume'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to windowed data sets\n",
    "ylist_antm = panel_data_antm['Adj Close']\n",
    "ylist_asii = panel_data_asii['Adj Close']\n",
    "ylist_icbp = panel_data_icbp['Adj Close']\n",
    "ylist_jsmr = panel_data_jsmr['Adj Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAGS and PERIOD\n",
    "n_future = 20\n",
    "n_past = 3*20\n",
    "total_period = 4*20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANTM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_end_antm = len(ylist_antm)\n",
    "idx_start_antm = idx_end_antm - total_period\n",
    "\n",
    "X_new_antm = []\n",
    "y_new_antm = []\n",
    "\n",
    "while idx_start_antm > 0:\n",
    "  x_line_antm = ylist_antm[idx_start_antm:idx_start_antm+n_past]\n",
    "  y_line_antm = ylist_antm[idx_start_antm+n_past:idx_start_antm+total_period]\n",
    "\n",
    "  X_new_antm.append(x_line_antm)\n",
    "  y_new_antm.append(y_line_antm)\n",
    "\n",
    "  idx_start_antm = idx_start_antm - 1\n",
    "\n",
    "X_new_antm = np.array(X_new_antm)\n",
    "y_new_antm = np.array(y_new_antm)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_antm, X_test_antm, y_train_antm, y_test_antm = train_test_split(X_new_antm, y_new_antm, test_size=0.33, random_state=42)\n",
    "\n",
    "# reshape data into the right format for RNNs\n",
    "n_samples = X_train_antm.shape[0]\n",
    "n_timesteps = X_train_antm.shape[1]\n",
    "n_steps = y_train_antm.shape[1]\n",
    "n_features = 1\n",
    "\n",
    "X_train_rs_antm = X_train_antm.reshape(n_samples, n_timesteps, n_features )\n",
    "X_test_rs_antm = X_test_antm.reshape(X_test_antm.shape[0], n_timesteps, n_features )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASII DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_end_asii = len(ylist_asii)\n",
    "idx_start_asii = idx_end_asii - total_period\n",
    "\n",
    "X_new_asii = []\n",
    "y_new_asii = []\n",
    "\n",
    "while idx_start_asii > 0:\n",
    "  x_line_asii = ylist_asii[idx_start_asii:idx_start_asii+n_past]\n",
    "  y_line_asii = ylist_asii[idx_start_asii+n_past:idx_start_asii+total_period]\n",
    "\n",
    "  X_new_asii.append(x_line_asii)\n",
    "  y_new_asii.append(y_line_asii)\n",
    "\n",
    "  idx_start_asii = idx_start_asii - 1\n",
    "\n",
    "X_new_asii = np.array(X_new_asii)\n",
    "y_new_asii = np.array(y_new_asii)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_asii, X_test_asii, y_train_asii, y_test_asii = train_test_split(X_new_asii, y_new_asii, test_size=0.33, random_state=42)\n",
    "\n",
    "# reshape data into the right format for RNNs\n",
    "n_samples = X_train_asii.shape[0]\n",
    "n_timesteps = X_train_asii.shape[1]\n",
    "n_steps = y_train_asii.shape[1]\n",
    "n_features = 1\n",
    "\n",
    "X_train_rs_asii = X_train_asii.reshape(n_samples, n_timesteps, n_features )\n",
    "X_test_rs_asii = X_test_asii.reshape(X_test_asii.shape[0], n_timesteps, n_features )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICBP DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_end_icbp = len(ylist_icbp)\n",
    "idx_start_icbp = idx_end_icbp - total_period\n",
    "\n",
    "X_new_icbp = []\n",
    "y_new_icbp = []\n",
    "\n",
    "while idx_start_icbp > 0:\n",
    "  x_line_icbp = ylist_icbp[idx_start_icbp:idx_start_icbp+n_past]\n",
    "  y_line_icbp = ylist_icbp[idx_start_icbp+n_past:idx_start_icbp+total_period]\n",
    "\n",
    "  X_new_icbp.append(x_line_icbp)\n",
    "  y_new_icbp.append(y_line_icbp)\n",
    "\n",
    "  idx_start_icbp = idx_start_icbp - 1\n",
    "\n",
    "X_new_icbp = np.array(X_new_icbp)\n",
    "y_new_icbp = np.array(y_new_icbp)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_icbp, X_test_icbp, y_train_icbp, y_test_icbp = train_test_split(X_new_icbp, y_new_icbp, test_size=0.33, random_state=42)\n",
    "\n",
    "# reshape data into the right format for RNNs\n",
    "n_samples = X_train_icbp.shape[0]\n",
    "n_timesteps = X_train_icbp.shape[1]\n",
    "n_steps = y_train_icbp.shape[1]\n",
    "n_features = 1\n",
    "\n",
    "X_train_rs_icbp = X_train_icbp.reshape(n_samples, n_timesteps, n_features )\n",
    "X_test_rs_icbp = X_test_icbp.reshape(X_test_icbp.shape[0], n_timesteps, n_features )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSMR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_end_jsmr = len(ylist_jsmr)\n",
    "idx_start_jsmr = idx_end_jsmr - total_period\n",
    "\n",
    "X_new_jsmr = []\n",
    "y_new_jsmr = []\n",
    "\n",
    "while idx_start_jsmr > 0:\n",
    "  x_line_jsmr = ylist_jsmr[idx_start_jsmr:idx_start_jsmr+n_past]\n",
    "  y_line_jsmr = ylist_jsmr[idx_start_jsmr+n_past:idx_start_jsmr+total_period]\n",
    "\n",
    "  X_new_jsmr.append(x_line_jsmr)\n",
    "  y_new_jsmr.append(y_line_jsmr)\n",
    "\n",
    "  idx_start_jsmr = idx_start_jsmr - 1\n",
    "\n",
    "X_new_jsmr = np.array(X_new_jsmr)\n",
    "y_new_jsmr = np.array(y_new_jsmr)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_jsmr, X_test_jsmr, y_train_jsmr, y_test_jsmr = train_test_split(X_new_jsmr, y_new_jsmr, test_size=0.33, random_state=42)\n",
    "\n",
    "# reshape data into the right format for RNNs\n",
    "n_samples = X_train_jsmr.shape[0]\n",
    "n_timesteps = X_train_jsmr.shape[1]\n",
    "n_steps = y_train_jsmr.shape[1]\n",
    "n_features = 1\n",
    "\n",
    "X_train_rs_jsmr = X_train_jsmr.reshape(n_samples, n_timesteps, n_features )\n",
    "X_test_rs_jsmr = X_test_jsmr.reshape(X_test_jsmr.shape[0], n_timesteps, n_features )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUNING PARAMETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_68 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500\n",
      "Trainable params: 500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 6s 50ms/step - loss: 1073.5249 - mae: 1073.5249 - val_loss: 1048.5721 - val_mae: 1048.5721\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 1064.5402 - mae: 1064.5402 - val_loss: 1039.5880 - val_mae: 1039.5880\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 1055.5559 - mae: 1055.5559 - val_loss: 1030.6040 - val_mae: 1030.6040\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 1046.5720 - mae: 1046.5720 - val_loss: 1021.6199 - val_mae: 1021.6199\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 1037.5878 - mae: 1037.5878 - val_loss: 1012.6358 - val_mae: 1012.6358\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 1028.6036 - mae: 1028.6036 - val_loss: 1003.6516 - val_mae: 1003.6516\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 1019.6196 - mae: 1019.6196 - val_loss: 994.6676 - val_mae: 994.6676\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 1010.6356 - mae: 1010.6356 - val_loss: 985.6837 - val_mae: 985.6837\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 1001.6517 - mae: 1001.6517 - val_loss: 976.6997 - val_mae: 976.6997\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 992.6676 - mae: 992.6676 - val_loss: 967.7156 - val_mae: 967.7156\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 983.6836 - mae: 983.6836 - val_loss: 958.7316 - val_mae: 958.7316\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 974.6995 - mae: 974.6995 - val_loss: 949.7477 - val_mae: 949.7477\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 965.7155 - mae: 965.7155 - val_loss: 940.7637 - val_mae: 940.7637\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 956.7316 - mae: 956.7316 - val_loss: 931.7796 - val_mae: 931.7796\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 947.7477 - mae: 947.7477 - val_loss: 922.7957 - val_mae: 922.7957\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 938.7637 - mae: 938.7637 - val_loss: 913.8116 - val_mae: 913.8116\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 929.7797 - mae: 929.7797 - val_loss: 904.8278 - val_mae: 904.8278\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 920.7958 - mae: 920.7958 - val_loss: 895.8437 - val_mae: 895.8437\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 911.8117 - mae: 911.8117 - val_loss: 886.8596 - val_mae: 886.8596\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 902.8276 - mae: 902.8276 - val_loss: 877.8757 - val_mae: 877.8757\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "simple_model_one_antm = Sequential([\n",
    "  LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features)),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_one_antm.summary()\n",
    "\n",
    "simple_model_one_antm.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_one_antm = simple_model_one_antm.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_one_antm = simple_model_one_antm.predict(X_test_rs_antm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_69 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_70 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,044\n",
      "Trainable params: 1,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 9s 78ms/step - loss: 1060.8381 - mae: 1060.8381 - mape: 98.0136 - mse: 1441082.3750 - val_loss: 1021.0776 - val_mae: 1021.0776 - val_mape: 95.6859 - val_mse: 1330058.1250\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 1023.4502 - mae: 1023.4502 - mape: 93.6380 - mse: 1363598.5000 - val_loss: 984.1779 - val_mae: 984.1779 - val_mape: 91.3267 - val_mse: 1256064.5000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 3s 55ms/step - loss: 986.8531 - mae: 986.8531 - mape: 89.3719 - mse: 1289801.0000 - val_loss: 947.8062 - val_mae: 947.8062 - val_mape: 87.0300 - val_mse: 1185795.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 950.5978 - mae: 950.5978 - mape: 85.1526 - mse: 1219581.1250 - val_loss: 911.6476 - val_mae: 911.6476 - val_mape: 82.7584 - val_mse: 1118559.8750\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 914.4996 - mae: 914.4996 - mape: 80.9331 - mse: 1152514.5000 - val_loss: 875.6035 - val_mae: 875.6035 - val_mape: 78.5004 - val_mse: 1054140.1250\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 878.4928 - mae: 878.4928 - mape: 76.7394 - mse: 1088239.5000 - val_loss: 839.6309 - val_mae: 839.6309 - val_mape: 74.2507 - val_mse: 992438.7500\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 3s 53ms/step - loss: 842.5451 - mae: 842.5451 - mape: 72.5708 - mse: 1025860.0625 - val_loss: 803.7073 - val_mae: 803.7073 - val_mape: 70.0069 - val_mse: 933403.8125\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 806.6445 - mae: 806.6445 - mape: 68.3593 - mse: 966773.1250 - val_loss: 767.8486 - val_mae: 767.8486 - val_mape: 65.7741 - val_mse: 877027.5000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 3s 53ms/step - loss: 771.3875 - mae: 771.3875 - mape: 64.3545 - mse: 910085.5625 - val_loss: 733.4021 - val_mae: 733.4021 - val_mape: 61.8720 - val_mse: 824193.1250\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 737.7015 - mae: 737.7015 - mape: 60.6645 - mse: 857675.1250 - val_loss: 700.5669 - val_mae: 700.5669 - val_mape: 58.3422 - val_mse: 774753.5000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 705.4152 - mae: 705.4152 - mape: 57.3006 - mse: 808283.4375 - val_loss: 669.1024 - val_mae: 669.1024 - val_mape: 55.0942 - val_mse: 728514.5625\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 674.7385 - mae: 674.7385 - mape: 54.2185 - mse: 762638.1875 - val_loss: 639.9727 - val_mae: 639.9727 - val_mape: 52.2942 - val_mse: 685898.8750\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 645.5787 - mae: 645.5787 - mape: 51.4370 - mse: 720065.6250 - val_loss: 611.7045 - val_mae: 611.7045 - val_mape: 49.6654 - val_mse: 645771.8750\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 3s 54ms/step - loss: 617.1704 - mae: 617.1704 - mape: 48.7931 - mse: 679565.8750 - val_loss: 583.9497 - val_mae: 583.9497 - val_mape: 47.1110 - val_mse: 608163.5625\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 3s 52ms/step - loss: 589.5706 - mae: 589.5706 - mape: 46.2829 - mse: 642042.5625 - val_loss: 556.8978 - val_mae: 556.8978 - val_mape: 44.6718 - val_mse: 572949.5000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 562.8787 - mae: 562.8787 - mape: 43.9127 - mse: 606885.8750 - val_loss: 530.4131 - val_mae: 530.4131 - val_mape: 42.3174 - val_mse: 540064.0625\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 536.7380 - mae: 536.7380 - mape: 41.6180 - mse: 573738.7500 - val_loss: 504.5750 - val_mae: 504.5750 - val_mape: 40.0533 - val_mse: 509509.7500\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 3s 55ms/step - loss: 511.4935 - mae: 511.4935 - mape: 39.4625 - mse: 542876.5625 - val_loss: 480.4810 - val_mae: 480.4810 - val_mape: 38.0353 - val_mse: 481567.8125\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 488.5338 - mae: 488.5338 - mape: 37.6137 - mse: 515062.6250 - val_loss: 459.6562 - val_mae: 459.6562 - val_mape: 36.4527 - val_mse: 456751.1562\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 3s 52ms/step - loss: 468.4983 - mae: 468.4983 - mape: 36.1199 - mse: 490784.5625 - val_loss: 442.3612 - val_mae: 442.3612 - val_mape: 35.3096 - val_mse: 435087.7188\n",
      "-326172289768.8364\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_two_antm = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_two_antm.summary()\n",
    "\n",
    "simple_model_two_antm.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_two_antm = simple_model_two_antm.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_two_antm = simple_model_two_antm.predict(X_test_rs_antm)\n",
    "\n",
    "print(r2_score(preds_two_antm, y_test_antm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_71 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_72 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_73 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 13s 106ms/step - loss: 1061.4814 - mae: 1061.4814 - mape: 98.0664 - mse: 1442894.8750 - val_loss: 1021.5974 - val_mae: 1021.5974 - val_mape: 95.7473 - val_mse: 1331118.7500\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 1023.8145 - mae: 1023.8145 - mape: 93.7026 - mse: 1363918.7500 - val_loss: 984.4150 - val_mae: 984.4150 - val_mape: 91.3548 - val_mse: 1256530.5000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 987.0116 - mae: 987.0116 - mape: 89.4001 - mse: 1289915.6250 - val_loss: 947.8929 - val_mae: 947.8929 - val_mape: 87.0403 - val_mse: 1185958.6250\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 950.6332 - mae: 950.6332 - mape: 85.1485 - mse: 1219585.0000 - val_loss: 911.6345 - val_mae: 911.6345 - val_mape: 82.7569 - val_mse: 1118534.7500\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 914.1989 - mae: 914.1989 - mape: 80.9285 - mse: 1151392.5000 - val_loss: 872.4590 - val_mae: 872.4590 - val_mape: 78.1289 - val_mse: 1048642.5000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 868.3167 - mae: 868.3167 - mape: 75.5699 - mse: 1069745.7500 - val_loss: 823.0381 - val_mae: 823.0381 - val_mape: 72.2906 - val_mse: 964849.8125\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 821.1542 - mae: 821.1542 - mape: 70.0318 - mse: 990347.0000 - val_loss: 777.5767 - val_mae: 777.5767 - val_mape: 66.9200 - val_mse: 892083.5625\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 776.9348 - mae: 776.9348 - mape: 64.9808 - mse: 918970.3750 - val_loss: 734.8671 - val_mae: 734.8671 - val_mape: 62.0338 - val_mse: 826419.3125\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 735.8614 - mae: 735.8614 - mape: 60.4747 - mse: 855176.1875 - val_loss: 695.2294 - val_mae: 695.2294 - val_mape: 57.7824 - val_mse: 766829.2500\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 696.3550 - mae: 696.3550 - mape: 56.3564 - mse: 795693.5625 - val_loss: 652.2805 - val_mae: 652.2805 - val_mape: 53.4604 - val_mse: 703805.3750\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 647.6861 - mae: 647.6861 - mape: 51.6339 - mse: 722686.4375 - val_loss: 604.5776 - val_mae: 604.5776 - val_mape: 49.0052 - val_mse: 635963.8125\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 602.6033 - mae: 602.6033 - mape: 47.4327 - mse: 660043.0625 - val_loss: 562.7716 - val_mae: 562.7716 - val_mape: 45.1978 - val_mse: 580463.8125\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 562.5650 - mae: 562.5650 - mape: 43.8668 - mse: 606412.8125 - val_loss: 524.2038 - val_mae: 524.2038 - val_mape: 41.7692 - val_mse: 532597.1250\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 525.2307 - mae: 525.2307 - mape: 40.6319 - mse: 559848.5625 - val_loss: 488.3271 - val_mae: 488.3271 - val_mape: 38.6781 - val_mse: 490657.5938\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 491.7378 - mae: 491.7378 - mape: 37.8883 - mse: 519174.4375 - val_loss: 458.3232 - val_mae: 458.3232 - val_mape: 36.3587 - val_mse: 455113.8125\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 464.2378 - mae: 464.2378 - mape: 35.8633 - mse: 485318.5312 - val_loss: 435.6211 - val_mae: 435.6211 - val_mape: 34.9251 - val_mse: 426185.7500\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 443.0562 - mae: 443.0562 - mape: 34.5086 - mse: 457868.5312 - val_loss: 419.4226 - val_mae: 419.4226 - val_mape: 34.1779 - val_mse: 403514.5000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 427.2134 - mae: 427.2134 - mape: 33.7613 - mse: 436252.7188 - val_loss: 406.6227 - val_mae: 406.6227 - val_mape: 33.7753 - val_mse: 384570.7188\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 414.6244 - mae: 414.6244 - mape: 33.2883 - mse: 417873.0312 - val_loss: 396.9037 - val_mae: 396.9037 - val_mape: 33.6197 - val_mse: 369403.1250\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 406.1251 - mae: 406.1251 - mape: 33.1983 - mse: 403487.2812 - val_loss: 390.1237 - val_mae: 390.1237 - val_mape: 33.6491 - val_mse: 357897.9062\n",
      "-22539986560.846367\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_three_antm = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm.summary()\n",
    "\n",
    "simple_model_three_antm.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_three_antm = simple_model_three_antm.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm = simple_model_three_antm.predict(X_test_rs_antm)\n",
    "\n",
    "print(r2_score(preds_three_antm, y_test_antm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_74 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_75 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_76 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_77 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,132\n",
      "Trainable params: 2,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 21s 188ms/step - loss: 1060.8657 - mae: 1060.8657 - mape: 98.0126 - mse: 1441235.7500 - val_loss: 1019.9499 - val_mae: 1019.9499 - val_mape: 95.5528 - val_mse: 1327753.8750\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 1018.8272 - mae: 1018.8272 - mape: 93.1242 - mse: 1353786.3750 - val_loss: 976.0650 - val_mae: 976.0650 - val_mape: 90.3684 - val_mse: 1240159.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 975.7917 - mae: 975.7917 - mape: 88.1156 - mse: 1267897.1250 - val_loss: 933.7004 - val_mae: 933.7004 - val_mape: 85.3637 - val_mse: 1159253.1250\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 933.7409 - mae: 933.7409 - mape: 83.1799 - mse: 1187941.1250 - val_loss: 891.8997 - val_mae: 891.8997 - val_mape: 80.4256 - val_mse: 1082941.2500\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 892.0854 - mae: 892.0854 - mape: 78.3282 - mse: 1111711.0000 - val_loss: 850.3713 - val_mae: 850.3713 - val_mape: 75.5197 - val_mse: 1010587.5000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 850.6417 - mae: 850.6417 - mape: 73.4697 - mse: 1040059.6250 - val_loss: 809.0044 - val_mae: 809.0044 - val_mape: 70.6328 - val_mse: 941944.3125\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 809.3342 - mae: 809.3342 - mape: 68.6776 - mse: 970979.0625 - val_loss: 767.7691 - val_mae: 767.7691 - val_mape: 65.7652 - val_mse: 876900.7500\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 768.7756 - mae: 768.7756 - mape: 64.0401 - mse: 906379.7500 - val_loss: 728.2780 - val_mae: 728.2780 - val_mape: 61.3090 - val_mse: 816418.0625\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 730.2719 - mae: 730.2719 - mape: 59.8834 - mse: 846356.0000 - val_loss: 690.9117 - val_mae: 690.9117 - val_mape: 57.3308 - val_mse: 760454.4375\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 6s 126ms/step - loss: 693.7239 - mae: 693.7239 - mape: 56.1288 - mse: 790841.9375 - val_loss: 655.6449 - val_mae: 655.6449 - val_mape: 53.7821 - val_mse: 708737.8125\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 659.2600 - mae: 659.2600 - mape: 52.7218 - mse: 739938.6875 - val_loss: 622.9836 - val_mae: 622.9836 - val_mape: 50.7100 - val_mse: 661571.1875\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 626.3775 - mae: 626.3775 - mape: 49.6556 - mse: 692451.1250 - val_loss: 590.7786 - val_mae: 590.7786 - val_mape: 47.7343 - val_mse: 617280.1875\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 6s 115ms/step - loss: 594.4103 - mae: 594.4103 - mape: 46.6978 - mse: 648412.8750 - val_loss: 559.7075 - val_mae: 559.7075 - val_mape: 44.9230 - val_mse: 576534.3750\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 9s 174ms/step - loss: 563.8709 - mae: 563.8709 - mape: 43.9808 - mse: 608372.3750 - val_loss: 529.5053 - val_mae: 529.5053 - val_mape: 42.2370 - val_mse: 538966.1875\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 6s 113ms/step - loss: 533.9846 - mae: 533.9846 - mape: 41.3739 - mse: 570444.5625 - val_loss: 499.9810 - val_mae: 499.9810 - val_mape: 39.6578 - val_mse: 504184.1875\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 6s 108ms/step - loss: 505.4132 - mae: 505.4132 - mape: 38.9817 - mse: 535487.2500 - val_loss: 473.1709 - val_mae: 473.1709 - val_mape: 37.4595 - val_mse: 472954.4688\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 480.1982 - mae: 480.1982 - mape: 36.9858 - mse: 504999.4062 - val_loss: 450.9261 - val_mae: 450.9261 - val_mape: 35.8534 - val_mse: 445953.0312\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 108ms/step - loss: 459.0685 - mae: 459.0685 - mape: 35.4818 - mse: 479203.9062 - val_loss: 433.3915 - val_mae: 433.3915 - val_mape: 34.8066 - val_mse: 423173.5312\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 442.3200 - mae: 442.3200 - mape: 34.4815 - mse: 457003.8438 - val_loss: 419.8409 - val_mae: 419.8409 - val_mape: 34.1943 - val_mse: 404112.6875\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 107ms/step - loss: 429.0786 - mae: 429.0786 - mape: 33.8483 - mse: 438559.4688 - val_loss: 408.9919 - val_mae: 408.9919 - val_mape: 33.8358 - val_mse: 388140.7812\n",
      "-6465379666379.043\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_four_antm = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_four_antm.summary()\n",
    "\n",
    "simple_model_four_antm.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_four_antm = simple_model_four_antm.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_four_antm = simple_model_four_antm.predict(X_test_rs_antm)\n",
    "\n",
    "print(r2_score(preds_four_antm, y_test_antm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_78 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_79 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_80 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_81 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_82 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,676\n",
      "Trainable params: 2,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 35s 216ms/step - loss: 1059.3784 - mae: 1059.3784 - mape: 97.8181 - mse: 1438825.5000 - val_loss: 1017.1167 - val_mae: 1017.1167 - val_mape: 95.2180 - val_mse: 1321985.6250\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 7s 141ms/step - loss: 1016.9854 - mae: 1016.9854 - mape: 92.8933 - mse: 1350424.5000 - val_loss: 975.0558 - val_mae: 975.0558 - val_mape: 90.2491 - val_mse: 1238192.7500\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 8s 166ms/step - loss: 975.2431 - mae: 975.2431 - mape: 88.0617 - mse: 1266675.8750 - val_loss: 933.5505 - val_mae: 933.5505 - val_mape: 85.3459 - val_mse: 1158975.7500\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 933.8602 - mae: 933.8602 - mape: 83.2268 - mse: 1187635.6250 - val_loss: 892.2697 - val_mae: 892.2697 - val_mape: 80.4692 - val_mse: 1083604.3750\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 6s 116ms/step - loss: 892.6428 - mae: 892.6428 - mape: 78.3952 - mse: 1113004.2500 - val_loss: 851.1091 - val_mae: 851.1091 - val_mape: 75.6067 - val_mse: 1011845.8750\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 6s 124ms/step - loss: 851.5212 - mae: 851.5212 - mape: 73.6060 - mse: 1041069.2500 - val_loss: 810.0234 - val_mae: 810.0234 - val_mape: 70.7530 - val_mse: 943597.1250\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 810.4624 - mae: 810.4624 - mape: 68.8392 - mse: 972220.8750 - val_loss: 769.0015 - val_mae: 769.0015 - val_mape: 65.9092 - val_mse: 878807.3750\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 770.2115 - mae: 770.2115 - mape: 64.2056 - mse: 908862.1875 - val_loss: 729.6054 - val_mae: 729.6054 - val_mape: 61.4542 - val_mse: 818432.9375\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 6s 124ms/step - loss: 731.8300 - mae: 731.8300 - mape: 60.0270 - mse: 848989.5000 - val_loss: 692.6434 - val_mae: 692.6434 - val_mape: 57.5118 - val_mse: 763008.1875\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 7s 135ms/step - loss: 695.4908 - mae: 695.4908 - mape: 56.3005 - mse: 793368.7500 - val_loss: 657.4598 - val_mae: 657.4598 - val_mape: 53.9574 - val_mse: 711396.9375\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 8s 154ms/step - loss: 661.2969 - mae: 661.2969 - mape: 52.9440 - mse: 742717.0000 - val_loss: 624.8184 - val_mae: 624.8184 - val_mape: 50.8810 - val_mse: 664166.5000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 7s 131ms/step - loss: 628.4299 - mae: 628.4299 - mape: 49.8475 - mse: 695400.6875 - val_loss: 592.6985 - val_mae: 592.6985 - val_mape: 47.9107 - val_mse: 619858.1250\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 7s 145ms/step - loss: 596.3943 - mae: 596.3943 - mape: 46.8758 - mse: 651679.7500 - val_loss: 561.5671 - val_mae: 561.5671 - val_mape: 45.0901 - val_mse: 578916.9375\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 7s 140ms/step - loss: 565.7654 - mae: 565.7654 - mape: 44.1742 - mse: 610270.9375 - val_loss: 531.2357 - val_mae: 531.2357 - val_mape: 42.3904 - val_mse: 541059.7500\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 6s 126ms/step - loss: 535.8111 - mae: 535.8111 - mape: 41.5464 - mse: 572696.2500 - val_loss: 501.8120 - val_mae: 501.8120 - val_mape: 39.8154 - val_mse: 506303.5625\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 507.3937 - mae: 507.3937 - mape: 39.1472 - mse: 538064.5625 - val_loss: 474.8459 - val_mae: 474.8459 - val_mape: 37.5906 - val_mse: 474926.5625\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 6s 126ms/step - loss: 481.9760 - mae: 481.9760 - mape: 37.1136 - mse: 507299.9375 - val_loss: 452.4815 - val_mae: 452.4815 - val_mape: 35.9581 - val_mse: 447886.0625\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 460.6487 - mae: 460.6487 - mape: 35.5869 - mse: 481236.7812 - val_loss: 434.6617 - val_mae: 434.6617 - val_mape: 34.8729 - val_mse: 424907.0938\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 443.5707 - mae: 443.5707 - mape: 34.5359 - mse: 458821.0000 - val_loss: 420.9132 - val_mae: 420.9132 - val_mape: 34.2352 - val_mse: 405680.2500\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 6s 127ms/step - loss: 429.9642 - mae: 429.9642 - mape: 33.8680 - mse: 439662.3125 - val_loss: 409.9886 - val_mae: 409.9886 - val_mape: 33.8628 - val_mse: 389642.3750\n",
      "-118875513455.75107\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_five_antm = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_five_antm.summary()\n",
    "\n",
    "simple_model_five_antm.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_five_antm = simple_model_five_antm.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_five_antm = simple_model_five_antm.predict(X_test_rs_antm)\n",
    "\n",
    "print(r2_score(preds_five_antm, y_test_antm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_83 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500\n",
      "Trainable params: 500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 8s 69ms/step - loss: 5652.0640 - mae: 5652.0640 - mape: 99.9546 - mse: 32996480.0000 - val_loss: 5604.5552 - val_mae: 5604.5552 - val_mape: 99.9051 - val_mse: 32566204.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 5646.9639 - mae: 5646.9639 - mape: 99.8609 - mse: 32938872.0000 - val_loss: 5599.4556 - val_mae: 5599.4556 - val_mape: 99.8102 - val_mse: 32509064.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 5641.8628 - mae: 5641.8628 - mape: 99.7673 - mse: 32881178.0000 - val_loss: 5594.3550 - val_mae: 5594.3550 - val_mape: 99.7153 - val_mse: 32451974.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 5636.7632 - mae: 5636.7632 - mape: 99.6733 - mse: 32823838.0000 - val_loss: 5589.2549 - val_mae: 5589.2549 - val_mape: 99.6204 - val_mse: 32394938.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 5631.6641 - mae: 5631.6641 - mape: 99.5794 - mse: 32766410.0000 - val_loss: 5584.1553 - val_mae: 5584.1553 - val_mape: 99.5255 - val_mse: 32337952.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 5626.5649 - mae: 5626.5649 - mape: 99.4861 - mse: 32708790.0000 - val_loss: 5579.0552 - val_mae: 5579.0552 - val_mape: 99.4306 - val_mse: 32281020.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 5621.4639 - mae: 5621.4639 - mape: 99.3920 - mse: 32651586.0000 - val_loss: 5573.9556 - val_mae: 5573.9556 - val_mape: 99.3357 - val_mse: 32224144.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 5616.3633 - mae: 5616.3633 - mape: 99.2986 - mse: 32594176.0000 - val_loss: 5568.8550 - val_mae: 5568.8550 - val_mape: 99.2408 - val_mse: 32167312.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 5611.2637 - mae: 5611.2637 - mape: 99.2046 - mse: 32537002.0000 - val_loss: 5563.7549 - val_mae: 5563.7549 - val_mape: 99.1459 - val_mse: 32110536.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 5606.1636 - mae: 5606.1636 - mape: 99.1107 - mse: 32479848.0000 - val_loss: 5558.6558 - val_mae: 5558.6558 - val_mape: 99.0510 - val_mse: 32053816.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 5601.0640 - mae: 5601.0640 - mape: 99.0171 - mse: 32422680.0000 - val_loss: 5553.5552 - val_mae: 5553.5552 - val_mape: 98.9561 - val_mse: 31997140.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 5595.9634 - mae: 5595.9634 - mape: 98.9236 - mse: 32365422.0000 - val_loss: 5548.4556 - val_mae: 5548.4556 - val_mape: 98.8612 - val_mse: 31940520.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 5590.8643 - mae: 5590.8643 - mape: 98.8297 - mse: 32308444.0000 - val_loss: 5543.3560 - val_mae: 5543.3560 - val_mape: 98.7663 - val_mse: 31883956.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5585.7646 - mae: 5585.7646 - mape: 98.7360 - mse: 32251442.0000 - val_loss: 5538.2549 - val_mae: 5538.2549 - val_mape: 98.6714 - val_mse: 31827438.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 5580.6641 - mae: 5580.6641 - mape: 98.6427 - mse: 32194276.0000 - val_loss: 5533.1558 - val_mae: 5533.1558 - val_mape: 98.5765 - val_mse: 31770982.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 5575.5640 - mae: 5575.5640 - mape: 98.5486 - mse: 32137568.0000 - val_loss: 5528.0557 - val_mae: 5528.0557 - val_mape: 98.4816 - val_mse: 31714568.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 5570.4629 - mae: 5570.4629 - mape: 98.4546 - mse: 32080816.0000 - val_loss: 5522.9561 - val_mae: 5522.9561 - val_mape: 98.3867 - val_mse: 31658208.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 5565.3647 - mae: 5565.3647 - mape: 98.3612 - mse: 32023914.0000 - val_loss: 5517.8560 - val_mae: 5517.8560 - val_mape: 98.2918 - val_mse: 31601902.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 5560.2642 - mae: 5560.2642 - mape: 98.2673 - mse: 31967180.0000 - val_loss: 5512.7563 - val_mae: 5512.7563 - val_mape: 98.1969 - val_mse: 31545644.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 5555.1650 - mae: 5555.1650 - mape: 98.1736 - mse: 31910524.0000 - val_loss: 5507.6558 - val_mae: 5507.6558 - val_mape: 98.1020 - val_mse: 31489440.0000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_one_asii = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features)),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_one_asii.summary()\n",
    "\n",
    "simple_model_one_asii.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_one_asii = simple_model_one_asii.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_one_asii = simple_model_one_asii.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_84 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_85 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,044\n",
      "Trainable params: 1,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 23s 75ms/step - loss: 5636.9951 - mae: 5636.9951 - mape: 99.6777 - mse: 32826670.0000 - val_loss: 5569.6533 - val_mae: 5569.6533 - val_mape: 99.2557 - val_mse: 32176210.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 5593.5039 - mae: 5593.5039 - mape: 98.8762 - mse: 32339314.0000 - val_loss: 5526.5439 - val_mae: 5526.5439 - val_mape: 98.4535 - val_mse: 31697860.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 5550.9985 - mae: 5550.9985 - mape: 98.0970 - mse: 31864458.0000 - val_loss: 5484.4834 - val_mae: 5484.4834 - val_mape: 97.6708 - val_mse: 31234728.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 5509.1611 - mae: 5509.1611 - mape: 97.3309 - mse: 31400432.0000 - val_loss: 5442.8325 - val_mae: 5442.8325 - val_mape: 96.8958 - val_mse: 30779592.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 5467.6270 - mae: 5467.6270 - mape: 96.5650 - mse: 30945722.0000 - val_loss: 5401.3979 - val_mae: 5401.3979 - val_mape: 96.1248 - val_mse: 30330266.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 5426.2598 - mae: 5426.2598 - mape: 95.8037 - mse: 30495302.0000 - val_loss: 5360.0967 - val_mae: 5360.0967 - val_mape: 95.3563 - val_mse: 29885808.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 5385.0063 - mae: 5385.0063 - mape: 95.0469 - mse: 30048360.0000 - val_loss: 5318.8867 - val_mae: 5318.8867 - val_mape: 94.5894 - val_mse: 29445726.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 5343.8296 - mae: 5343.8296 - mape: 94.2891 - mse: 29607698.0000 - val_loss: 5277.7427 - val_mae: 5277.7427 - val_mape: 93.8238 - val_mse: 29009732.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 5302.7109 - mae: 5302.7109 - mape: 93.5318 - mse: 29170364.0000 - val_loss: 5236.6479 - val_mae: 5236.6479 - val_mape: 93.0591 - val_mse: 28577644.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 5261.6353 - mae: 5261.6353 - mape: 92.7794 - mse: 28735232.0000 - val_loss: 5195.5918 - val_mae: 5195.5918 - val_mape: 92.2952 - val_mse: 28149342.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 5220.5952 - mae: 5220.5952 - mape: 92.0244 - mse: 28305356.0000 - val_loss: 5154.5664 - val_mae: 5154.5664 - val_mape: 91.5318 - val_mse: 27724732.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 5179.5825 - mae: 5179.5825 - mape: 91.2688 - mse: 27879756.0000 - val_loss: 5113.5674 - val_mae: 5113.5674 - val_mape: 90.7689 - val_mse: 27303744.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 5138.5947 - mae: 5138.5947 - mape: 90.5197 - mse: 27454314.0000 - val_loss: 5072.5898 - val_mae: 5072.5898 - val_mape: 90.0064 - val_mse: 26886334.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 5097.6250 - mae: 5097.6250 - mape: 89.7653 - mse: 27036174.0000 - val_loss: 5031.6299 - val_mae: 5031.6299 - val_mape: 89.2442 - val_mse: 26472468.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 5056.6729 - mae: 5056.6729 - mape: 89.0130 - mse: 26619982.0000 - val_loss: 4990.6851 - val_mae: 4990.6851 - val_mape: 88.4823 - val_mse: 26062108.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 5015.7358 - mae: 5015.7358 - mape: 88.2580 - mse: 26208702.0000 - val_loss: 4949.7539 - val_mae: 4949.7539 - val_mape: 87.7207 - val_mse: 25655232.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 4974.8086 - mae: 4974.8086 - mape: 87.5081 - mse: 25798784.0000 - val_loss: 4908.8340 - val_mae: 4908.8340 - val_mape: 86.9593 - val_mse: 25251820.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 4933.8950 - mae: 4933.8950 - mape: 86.7563 - mse: 25393342.0000 - val_loss: 4867.9248 - val_mae: 4867.9248 - val_mape: 86.1980 - val_mse: 24851860.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 4892.9893 - mae: 4892.9893 - mape: 86.0027 - mse: 24991976.0000 - val_loss: 4827.0234 - val_mae: 4827.0234 - val_mape: 85.4370 - val_mse: 24455330.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 4852.0928 - mae: 4852.0928 - mape: 85.2503 - mse: 24594190.0000 - val_loss: 4786.1313 - val_mae: 4786.1313 - val_mape: 84.6760 - val_mse: 24062226.0000\n",
      "-2610888312568.861\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_two_asii = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_two_asii.summary()\n",
    "\n",
    "simple_model_two_asii.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_two_asii = simple_model_two_asii.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_two_asii = simple_model_two_asii.predict(X_test_rs_asii)\n",
    "\n",
    "print(r2_score(preds_two_asii, y_test_asii))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_86 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_87 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_88 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 20s 157ms/step - loss: 5634.4629 - mae: 5634.4629 - mape: 99.6294 - mse: 32798874.0000 - val_loss: 5568.0884 - val_mae: 5568.0884 - val_mape: 99.2266 - val_mse: 32158780.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 5592.9292 - mae: 5592.9292 - mape: 98.8693 - mse: 32331002.0000 - val_loss: 5526.7822 - val_mae: 5526.7822 - val_mape: 98.4579 - val_mse: 31700488.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - ETA: 0s - loss: 5551.7451 - mae: 5551.7451 - mape: 98.1100 - mse: 31873170.0000 ETA: 1s - loss: 5562.8535 - mae: 5562.8535 - mape: 98.2048 - mse: 31989658.00 - ETA: 0s - loss: 5568.4766 - mae: 5568.4766 - mape: 98 - 4s 81ms/step - loss: 5551.7451 - mae: 5551.7451 - mape: 98.1100 - mse: 31873170.0000 - val_loss: 5485.6924 - val_mae: 5485.6924 - val_mape: 97.6933 - val_mse: 31247992.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 5510.7061 - mae: 5510.7061 - mape: 97.3564 - mse: 31418700.0000 - val_loss: 5444.6929 - val_mae: 5444.6929 - val_mape: 96.9304 - val_mse: 30799846.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 5469.7319 - mae: 5469.7319 - mape: 96.6045 - mse: 30967772.0000 - val_loss: 5403.7427 - val_mae: 5403.7427 - val_mape: 96.1684 - val_mse: 30355600.0000- mae: 5456.4253 - mape\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 5428.7974 - mae: 5428.7974 - mape: 95.8508 - mse: 30522698.0000 - val_loss: 5362.8223 - val_mae: 5362.8223 - val_mape: 95.4070 - val_mse: 29915038.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 5387.8896 - mae: 5387.8896 - mape: 95.0988 - mse: 30080170.0000 - val_loss: 5321.9243 - val_mae: 5321.9243 - val_mape: 94.6460 - val_mse: 29478050.00005404.0356 - mae: 5404.0356 - mape: 95.1566 - ms\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 5346.9976 - mae: 5346.9976 - mape: 94.3483 - mse: 29640618.0000 - val_loss: 5281.0420 - val_mae: 5281.0420 - val_mape: 93.8852 - val_mse: 29044568.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 5306.1221 - mae: 5306.1221 - mape: 93.5969 - mse: 29205386.0000 - val_loss: 5240.1709 - val_mae: 5240.1709 - val_mape: 93.1247 - val_mse: 28614560.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 5265.2549 - mae: 5265.2549 - mape: 92.8469 - mse: 28772796.0000 - val_loss: 5199.3086 - val_mae: 5199.3086 - val_mape: 92.3644 - val_mse: 28187980.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 5222.6255 - mae: 5222.6255 - mape: 92.0626 - mse: 28325990.0000 - val_loss: 5149.0107 - val_mae: 5149.0107 - val_mape: 91.4284 - val_mse: 27667476.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 5165.2925 - mae: 5165.2925 - mape: 91.0088 - mse: 27730704.0000 - val_loss: 5091.4126 - val_mae: 5091.4126 - val_mape: 90.3567 - val_mse: 27077648.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 5110.5762 - mae: 5110.5762 - mape: 90.0018 - mse: 27168560.0000 - val_loss: 5038.8047 - val_mae: 5038.8047 - val_mape: 89.3777 - val_mse: 26544718.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 7s 138ms/step - loss: 5059.0327 - mae: 5059.0327 - mape: 89.0548 - mse: 26644480.0000 - val_loss: 4988.1519 - val_mae: 4988.1519 - val_mape: 88.4352 - val_mse: 26036824.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 5008.9414 - mae: 5008.9414 - mape: 88.1338 - mse: 26140746.0000 - val_loss: 4938.5698 - val_mae: 4938.5698 - val_mape: 87.5126 - val_mse: 25544636.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 4959.7163 - mae: 4959.7163 - mape: 87.2299 - mse: 25649286.0000 - val_loss: 4889.6763 - val_mae: 4889.6763 - val_mape: 86.6028 - val_mse: 25064104.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 4911.0698 - mae: 4911.0698 - mape: 86.3345 - mse: 25169740.0000 - val_loss: 4841.2681 - val_mae: 4841.2681 - val_mape: 85.7020 - val_mse: 24593044.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 4862.8457 - mae: 4862.8457 - mape: 85.4498 - mse: 24697662.0000 - val_loss: 4793.2207 - val_mae: 4793.2207 - val_mape: 84.8080 - val_mse: 24130140.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 4814.9409 - mae: 4814.9409 - mape: 84.5675 - mse: 24234904.0000 - val_loss: 4745.4556 - val_mae: 4745.4556 - val_mape: 83.9192 - val_mse: 23674516.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 4767.2881 - mae: 4767.2881 - mape: 83.6926 - mse: 23777754.0000 - val_loss: 4697.9141 - val_mae: 4697.9141 - val_mape: 83.0345 - val_mse: 23225560.0000\n",
      "-316915073704335.9\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_three_asii = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii.summary()\n",
    "\n",
    "simple_model_three_asii.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_three_asii = simple_model_three_asii.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii = simple_model_three_asii.predict(X_test_rs_asii)\n",
    "\n",
    "print(r2_score(preds_three_asii, y_test_asii))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_89 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_90 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_91 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_92 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,132\n",
      "Trainable params: 2,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 29s 181ms/step - loss: 5634.5542 - mae: 5634.5542 - mape: 99.6316 - mse: 32799726.0000 - val_loss: 5568.1299 - val_mae: 5568.1299 - val_mape: 99.2273 - val_mse: 32159244.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 6s 117ms/step - loss: 5592.9336 - mae: 5592.9336 - mape: 98.8676 - mse: 32331816.0000 - val_loss: 5526.7573 - val_mae: 5526.7573 - val_mape: 98.4574 - val_mse: 31700218.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 7s 144ms/step - loss: 5551.7012 - mae: 5551.7012 - mape: 98.1112 - mse: 31871688.0000 - val_loss: 5485.6299 - val_mae: 5485.6299 - val_mape: 97.6922 - val_mse: 31247314.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 6s 119ms/step - loss: 5510.6304 - mae: 5510.6304 - mape: 97.3538 - mse: 31418550.0000 - val_loss: 5444.6050 - val_mae: 5444.6050 - val_mape: 96.9288 - val_mse: 30798896.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 5469.6343 - mae: 5469.6343 - mape: 96.6019 - mse: 30967350.0000 - val_loss: 5403.6348 - val_mae: 5403.6348 - val_mape: 96.1664 - val_mse: 30354448.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 5428.6846 - mae: 5428.6846 - mape: 95.8488 - mse: 30521460.0000 - val_loss: 5362.6997 - val_mae: 5362.6997 - val_mape: 95.4047 - val_mse: 29913730.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 106ms/step - loss: 5387.7593 - mae: 5387.7593 - mape: 95.0963 - mse: 30078950.0000 - val_loss: 5321.7896 - val_mae: 5321.7896 - val_mape: 94.6434 - val_mse: 29476618.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 6s 110ms/step - loss: 5346.8579 - mae: 5346.8579 - mape: 94.3432 - mse: 29640792.0000 - val_loss: 5280.8960 - val_mae: 5280.8960 - val_mape: 93.8825 - val_mse: 29043038.000057 - mae: 5346.3257 - mape: 94.3576 - mse: 29640\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 6s 111ms/step - loss: 5305.9717 - mae: 5305.9717 - mape: 93.5935 - mse: 29203942.0000 - val_loss: 5240.0161 - val_mae: 5240.0161 - val_mape: 93.1218 - val_mse: 28612940.00006.66\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 108ms/step - loss: 5265.0962 - mae: 5265.0962 - mape: 92.8433 - mse: 28771604.0000 - val_loss: 5199.1465 - val_mae: 5199.1465 - val_mape: 92.3613 - val_mse: 28186298.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 6s 116ms/step - loss: 5224.2305 - mae: 5224.2305 - mape: 92.0912 - mse: 28343170.0000 - val_loss: 5158.2852 - val_mae: 5158.2852 - val_mape: 91.6010 - val_mse: 27763080.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 5183.3740 - mae: 5183.3740 - mape: 91.3415 - mse: 27917310.0000 - val_loss: 5117.4307 - val_mae: 5117.4307 - val_mape: 90.8408 - val_mse: 27343272.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 6s 126ms/step - loss: 5142.5220 - mae: 5142.5220 - mape: 90.5897 - mse: 27496054.0000 - val_loss: 5076.5825 - val_mae: 5076.5825 - val_mape: 90.0807 - val_mse: 26926860.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 5101.6763 - mae: 5101.6763 - mape: 89.8392 - mse: 27077580.0000 - val_loss: 5035.7388 - val_mae: 5035.7388 - val_mape: 89.3207 - val_mse: 26513836.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 10s 194ms/step - loss: 5060.8340 - mae: 5060.8340 - mape: 89.0889 - mse: 26662226.0000 - val_loss: 4994.8984 - val_mae: 4994.8984 - val_mape: 88.5607 - val_mse: 26104190.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 8s 154ms/step - loss: 5019.9971 - mae: 5019.9971 - mape: 88.3361 - mse: 26251836.0000 - val_loss: 4954.0630 - val_mae: 4954.0630 - val_mape: 87.8009 - val_mse: 25697914.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 7s 129ms/step - loss: 4979.1616 - mae: 4979.1616 - mape: 87.5884 - mse: 25842134.0000 - val_loss: 4913.2310 - val_mae: 4913.2310 - val_mape: 87.0411 - val_mse: 25295008.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 6s 109ms/step - loss: 4938.3306 - mae: 4938.3306 - mape: 86.8339 - mse: 25438976.0000 - val_loss: 4872.4004 - val_mae: 4872.4004 - val_mape: 86.2813 - val_mse: 24895462.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 107ms/step - loss: 4897.5020 - mae: 4897.5020 - mape: 86.0851 - mse: 25036974.0000 - val_loss: 4831.5732 - val_mae: 4831.5732 - val_mape: 85.5216 - val_mse: 24499274.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 6s 111ms/step - loss: 4856.6758 - mae: 4856.6758 - mape: 85.3368 - mse: 24637434.0000 - val_loss: 4790.7476 - val_mae: 4790.7476 - val_mape: 84.7619 - val_mse: 24106438.0000\n",
      "-4146636568567.2173\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_four_asii = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_four_asii.summary()\n",
    "\n",
    "simple_model_four_asii.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_four_asii = simple_model_four_asii.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_four_asii = simple_model_four_asii.predict(X_test_rs_asii)\n",
    "\n",
    "print(r2_score(preds_four_asii, y_test_asii))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_93 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_94 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_95 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_96 (LSTM)              (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_97 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,676\n",
      "Trainable params: 2,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 30s 232ms/step - loss: 5632.9810 - mae: 5632.9810 - mape: 99.6047 - mse: 32780898.0000 - val_loss: 5563.7661 - val_mae: 5563.7661 - val_mape: 99.1461 - val_mse: 32110656.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 5585.9556 - mae: 5585.9556 - mape: 98.7385 - mse: 32254304.0000 - val_loss: 5517.0278 - val_mae: 5517.0278 - val_mape: 98.2764 - val_mse: 31592762.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 6s 118ms/step - loss: 5539.4224 - mae: 5539.4224 - mape: 97.8857 - mse: 31735148.0000 - val_loss: 5470.6489 - val_mae: 5470.6489 - val_mape: 97.4134 - val_mse: 31083172.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 5493.1265 - mae: 5493.1265 - mape: 97.0323 - mse: 31226300.0000 - val_loss: 5424.4209 - val_mae: 5424.4209 - val_mape: 96.5532 - val_mse: 30579506.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 6s 127ms/step - loss: 5446.9399 - mae: 5446.9399 - mape: 96.1876 - mse: 30718428.0000 - val_loss: 5378.2729 - val_mae: 5378.2729 - val_mape: 95.6945 - val_mse: 30080988.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 5400.8184 - mae: 5400.8184 - mape: 95.3355 - mse: 30220488.0000 - val_loss: 5332.1758 - val_mae: 5332.1758 - val_mape: 94.8367 - val_mse: 29587270.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 6s 125ms/step - loss: 5354.7397 - mae: 5354.7397 - mape: 94.4927 - mse: 29722770.0000 - val_loss: 5286.1138 - val_mae: 5286.1138 - val_mape: 93.9796 - val_mse: 29098174.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 8s 154ms/step - loss: 5308.6914 - mae: 5308.6914 - mape: 93.6443 - mse: 29232530.0000 - val_loss: 5240.0786 - val_mae: 5240.0786 - val_mape: 93.1230 - val_mse: 28613586.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 6s 117ms/step - loss: 5262.6646 - mae: 5262.6646 - mape: 92.7987 - mse: 28745634.0000 - val_loss: 5194.0620 - val_mae: 5194.0620 - val_mape: 92.2667 - val_mse: 28133444.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 7s 127ms/step - loss: 5216.6548 - mae: 5216.6548 - mape: 91.9510 - mse: 28264492.0000 - val_loss: 5148.0596 - val_mae: 5148.0596 - val_mape: 91.4107 - val_mse: 27657688.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 7s 132ms/step - loss: 5170.6602 - mae: 5170.6602 - mape: 91.1076 - mse: 27786184.0000 - val_loss: 5102.0703 - val_mae: 5102.0703 - val_mape: 90.5550 - val_mse: 27186292.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 5124.6753 - mae: 5124.6753 - mape: 90.2622 - mse: 27312344.0000 - val_loss: 5056.0913 - val_mae: 5056.0913 - val_mape: 89.6994 - val_mse: 26719226.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 7s 141ms/step - loss: 5078.7007 - mae: 5078.7007 - mape: 89.4170 - mse: 26843302.0000 - val_loss: 5010.1201 - val_mae: 5010.1201 - val_mape: 88.8440 - val_mse: 26256478.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 6s 126ms/step - loss: 5032.7329 - mae: 5032.7329 - mape: 88.5694 - mse: 26380226.0000 - val_loss: 4964.1567 - val_mae: 4964.1567 - val_mape: 87.9887 - val_mse: 25798018.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 7s 128ms/step - loss: 4986.7729 - mae: 4986.7729 - mape: 87.7266 - mse: 25918822.0000 - val_loss: 4918.1992 - val_mae: 4918.1992 - val_mape: 87.1335 - val_mse: 25343848.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 6s 126ms/step - loss: 4940.8179 - mae: 4940.8179 - mape: 86.8842 - mse: 25461332.0000 - val_loss: 4872.2471 - val_mae: 4872.2471 - val_mape: 86.2785 - val_mse: 24893954.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 7s 128ms/step - loss: 4894.8677 - mae: 4894.8677 - mape: 86.0372 - mse: 25010890.0000 - val_loss: 4826.2988 - val_mae: 4826.2988 - val_mape: 85.4235 - val_mse: 24448326.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 6s 123ms/step - loss: 4848.9209 - mae: 4848.9209 - mape: 85.1917 - mse: 24563504.0000 - val_loss: 4780.3550 - val_mae: 4780.3550 - val_mape: 84.5686 - val_mse: 24006962.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 7s 141ms/step - loss: 4802.9795 - mae: 4802.9795 - mape: 84.3486 - mse: 24119244.0000 - val_loss: 4734.4150 - val_mae: 4734.4150 - val_mape: 83.7137 - val_mse: 23569854.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 4757.0405 - mae: 4757.0405 - mape: 83.5049 - mse: 23680106.0000 - val_loss: 4688.4775 - val_mae: 4688.4775 - val_mape: 82.8589 - val_mse: 23136996.0000\n",
      "-21412351604304.24\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_five_asii = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_five_asii.summary()\n",
    "\n",
    "simple_model_five_asii.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_five_asii = simple_model_five_asii.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_five_asii = simple_model_five_asii.predict(X_test_rs_asii)\n",
    "\n",
    "print(r2_score(preds_five_asii, y_test_asii))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_98 (LSTM)              (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500\n",
      "Trainable params: 500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 7s 44ms/step - loss: 6213.6372 - mae: 6213.6372 - val_loss: 6077.3403 - val_mae: 6077.3403\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 6204.6543 - mae: 6204.6543 - val_loss: 6068.3560 - val_mae: 6068.3560\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 6195.6704 - mae: 6195.6704 - val_loss: 6059.3721 - val_mae: 6059.3721\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 6186.6851 - mae: 6186.6851 - val_loss: 6050.3872 - val_mae: 6050.3872\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 6177.7017 - mae: 6177.7017 - val_loss: 6041.4033 - val_mae: 6041.4033\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 6168.7173 - mae: 6168.7173 - val_loss: 6032.4194 - val_mae: 6032.4194\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 6159.7329 - mae: 6159.7329 - val_loss: 6023.4351 - val_mae: 6023.4351\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 6150.7490 - mae: 6150.7490 - val_loss: 6014.4517 - val_mae: 6014.4517\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 6141.7646 - mae: 6141.7646 - val_loss: 6005.4678 - val_mae: 6005.4678\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 6132.7808 - mae: 6132.7808 - val_loss: 5996.4834 - val_mae: 5996.4834\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 6123.7969 - mae: 6123.7969 - val_loss: 5987.4995 - val_mae: 5987.4995\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 2s 29ms/step - loss: 6114.8135 - mae: 6114.8135 - val_loss: 5978.5161 - val_mae: 5978.5161\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 6105.8296 - mae: 6105.8296 - val_loss: 5969.5317 - val_mae: 5969.5317\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 6096.8452 - mae: 6096.8452 - val_loss: 5960.5469 - val_mae: 5960.5469\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 6087.8604 - mae: 6087.8604 - val_loss: 5951.5640 - val_mae: 5951.5640\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 6078.8765 - mae: 6078.8765 - val_loss: 5942.5796 - val_mae: 5942.57960s - loss: 5953.9399 - mae: 59 - ETA: 0s - loss: 6046.7871 - mae: 6046\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 6069.8936 - mae: 6069.8936 - val_loss: 5933.5952 - val_mae: 5933.5952\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - ETA: 0s - loss: 6062.1318 - mae: 6062.131 - 1s 28ms/step - loss: 6060.9102 - mae: 6060.9102 - val_loss: 5924.6118 - val_mae: 5924.6118\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 6051.9263 - mae: 6051.9263 - val_loss: 5915.6279 - val_mae: 5915.6279\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 1s 29ms/step - loss: 6042.9419 - mae: 6042.9419 - val_loss: 5906.6436 - val_mae: 5906.6436\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_one_icbp = Sequential([\n",
    "  LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features)),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_one_icbp.summary()\n",
    "\n",
    "simple_model_one_icbp.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_one_icbp = simple_model_one_icbp.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_one_icbp = simple_model_one_icbp.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_99 (LSTM)              (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_100 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,044\n",
      "Trainable params: 1,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 10s 95ms/step - loss: 6203.3936 - mae: 6203.3936 - mape: 99.6694 - mse: 46227556.0000 - val_loss: 6055.0278 - val_mae: 6055.0278 - val_mape: 99.2783 - val_mse: 44784720.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 3s 53ms/step - loss: 6168.0176 - mae: 6168.0176 - mape: 98.8931 - mse: 45789364.0000 - val_loss: 6015.6577 - val_mae: 6015.6577 - val_mape: 98.3708 - val_mse: 44309504.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 6128.6362 - mae: 6128.6362 - mape: 98.0244 - mse: 45304544.0000 - val_loss: 5977.3638 - val_mae: 5977.3638 - val_mape: 97.4882 - val_mse: 43850244.00006144.8901 - mae: 6144\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 3s 54ms/step - loss: 6090.9272 - mae: 6090.9272 - mape: 97.2005 - mse: 44842708.0000 - val_loss: 5940.1064 - val_mae: 5940.1064 - val_mape: 96.6295 - val_mse: 43406236.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 6053.9170 - mae: 6053.9170 - mape: 96.3787 - mse: 44395100.0000 - val_loss: 5903.3027 - val_mae: 5903.3027 - val_mape: 95.7813 - val_mse: 42970356.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 6017.2476 - mae: 6017.2476 - mape: 95.5695 - mse: 43953268.0000 - val_loss: 5866.7563 - val_mae: 5866.7563 - val_mape: 94.9389 - val_mse: 42540200.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 3s 63ms/step - loss: 5980.7861 - mae: 5980.7861 - mape: 94.7740 - mse: 43511740.0000 - val_loss: 5830.3750 - val_mae: 5830.3755 - val_mape: 94.1004 - val_mse: 42114648.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 3s 54ms/step - loss: 5944.4658 - mae: 5944.4658 - mape: 93.9663 - mse: 43081864.0000 - val_loss: 5794.1108 - val_mae: 5794.1108 - val_mape: 93.2646 - val_mse: 41693092.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 3s 54ms/step - loss: 5908.2441 - mae: 5908.2441 - mape: 93.1627 - mse: 42653616.0000 - val_loss: 5757.9326 - val_mae: 5757.9326 - val_mape: 92.4307 - val_mse: 41275152.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 3s 65ms/step - loss: 5872.0991 - mae: 5872.0991 - mape: 92.3694 - mse: 42225696.0000 - val_loss: 5721.8198 - val_mae: 5721.8198 - val_mape: 91.5984 - val_mse: 40860588.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 5836.0137 - mae: 5836.0137 - mape: 91.5826 - mse: 41800808.0000 - val_loss: 5685.7593 - val_mae: 5685.7593 - val_mape: 90.7673 - val_mse: 40449232.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 3s 57ms/step - loss: 5799.9741 - mae: 5799.9741 - mape: 90.7818 - mse: 41383596.0000 - val_loss: 5649.7422 - val_mae: 5649.7422 - val_mape: 89.9371 - val_mse: 40040944.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 3s 52ms/step - loss: 5763.9741 - mae: 5763.9741 - mape: 89.9883 - mse: 40966300.0000 - val_loss: 5613.7588 - val_mae: 5613.7588 - val_mape: 89.1077 - val_mse: 39635656.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 3s 54ms/step - loss: 5728.0049 - mae: 5728.0049 - mape: 89.1937 - mse: 40554784.0000 - val_loss: 5577.8052 - val_mae: 5577.8052 - val_mape: 88.2791 - val_mse: 39233280.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 5692.0640 - mae: 5692.0640 - mape: 88.4016 - mse: 40142096.0000 - val_loss: 5541.8770 - val_mae: 5541.8770 - val_mape: 87.4510 - val_mse: 38833760.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 3s 54ms/step - loss: 5656.1450 - mae: 5656.1450 - mape: 87.6121 - mse: 39735608.0000 - val_loss: 5505.9692 - val_mae: 5505.9692 - val_mape: 86.6234 - val_mse: 38437064.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 5620.2500 - mae: 5620.2500 - mape: 86.8274 - mse: 39327772.0000 - val_loss: 5470.0811 - val_mae: 5470.0811 - val_mape: 85.7962 - val_mse: 38043152.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 5584.3682 - mae: 5584.3682 - mape: 86.0342 - mse: 38927232.0000 - val_loss: 5434.2085 - val_mae: 5434.2085 - val_mape: 84.9694 - val_mse: 37651992.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 3s 53ms/step - loss: 5548.5020 - mae: 5548.5020 - mape: 85.2386 - mse: 38529252.0000 - val_loss: 5398.3511 - val_mae: 5398.3511 - val_mape: 84.1429 - val_mse: 37263556.00005537 - mape: 85.3495 - mse: 387\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 3s 52ms/step - loss: 5512.6509 - mae: 5512.6509 - mape: 84.4471 - mse: 38133012.0000 - val_loss: 5362.5054 - val_mae: 5362.5054 - val_mape: 83.3168 - val_mse: 36877836.0000\n",
      "-16852658550471.129\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_two_icbp = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_two_icbp.summary()\n",
    "\n",
    "simple_model_two_icbp.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_two_icbp = simple_model_two_icbp.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_two_icbp = simple_model_two_icbp.predict(X_test_rs_icbp)\n",
    "\n",
    "print(r2_score(preds_two_icbp, y_test_icbp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_101 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_102 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_103 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 15s 128ms/step - loss: 6200.5962 - mae: 6200.5962 - mape: 99.6196 - mse: 46189976.0000 - val_loss: 6050.0029 - val_mae: 6050.0029 - val_mape: 99.1624 - val_mse: 44723916.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 6164.0503 - mae: 6164.0503 - mape: 98.8135 - mse: 45738248.0000 - val_loss: 6013.7061 - val_mae: 6013.7061 - val_mape: 98.3258 - val_mse: 44286032.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6127.9014 - mae: 6127.9014 - mape: 98.0165 - mse: 45293380.0000 - val_loss: 5977.6670 - val_mae: 5977.6670 - val_mape: 97.4952 - val_mse: 43853880.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 6091.9199 - mae: 6091.9199 - mape: 97.2186 - mse: 44855760.0000 - val_loss: 5941.7334 - val_mae: 5941.7334 - val_mape: 96.6670 - val_mse: 43425576.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 6056.0161 - mae: 6056.0161 - mape: 96.4272 - mse: 44419396.0000 - val_loss: 5905.8584 - val_mae: 5905.8584 - val_mape: 95.8401 - val_mse: 43000536.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6020.1592 - mae: 6020.1592 - mape: 95.6328 - mse: 43987724.0000 - val_loss: 5870.0190 - val_mae: 5870.0190 - val_mape: 95.0141 - val_mse: 42578496.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 5984.3340 - mae: 5984.3340 - mape: 94.8473 - mse: 43555548.0000 - val_loss: 5834.2046 - val_mae: 5834.2046 - val_mape: 94.1886 - val_mse: 42159320.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 5948.5283 - mae: 5948.5283 - mape: 94.0616 - mse: 43127608.0000 - val_loss: 5798.4077 - val_mae: 5798.4077 - val_mape: 93.3636 - val_mse: 41742912.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 5912.7383 - mae: 5912.7383 - mape: 93.2743 - mse: 42702424.0000 - val_loss: 5762.6250 - val_mae: 5762.6255 - val_mape: 92.5389 - val_mse: 41329232.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 5876.9629 - mae: 5876.9629 - mape: 92.4815 - mse: 42282260.0000 - val_loss: 5726.8545 - val_mae: 5726.8545 - val_mape: 91.7144 - val_mse: 40918228.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 5841.1938 - mae: 5841.1938 - mape: 91.6889 - mse: 41864048.0000 - val_loss: 5691.0908 - val_mae: 5691.0908 - val_mape: 90.8901 - val_mse: 40509892.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 5805.4360 - mae: 5805.4360 - mape: 90.9090 - mse: 41444368.0000 - val_loss: 5655.3350 - val_mae: 5655.3350 - val_mape: 90.0660 - val_mse: 40104188.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 5769.6831 - mae: 5769.6831 - mape: 90.1172 - mse: 41032240.0000 - val_loss: 5619.5850 - val_mae: 5619.5850 - val_mape: 89.2420 - val_mse: 39701108.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 5733.9336 - mae: 5733.9336 - mape: 89.3293 - mse: 40620380.0000 - val_loss: 5583.8398 - val_mae: 5583.8398 - val_mape: 88.4181 - val_mse: 39300640.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 5698.1904 - mae: 5698.1904 - mape: 88.5417 - mse: 40211352.0000 - val_loss: 5548.0986 - val_mae: 5548.0986 - val_mape: 87.5944 - val_mse: 38902780.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 5662.4521 - mae: 5662.4521 - mape: 87.7534 - mse: 39806788.0000 - val_loss: 5512.3618 - val_mae: 5512.3618 - val_mape: 86.7707 - val_mse: 38507508.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 5626.7178 - mae: 5626.7178 - mape: 86.9704 - mse: 39401512.0000 - val_loss: 5476.6279 - val_mae: 5476.6279 - val_mape: 85.9471 - val_mse: 38114828.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 5590.9839 - mae: 5590.9839 - mape: 86.1735 - mse: 39002640.0000 - val_loss: 5440.8975 - val_mae: 5440.8975 - val_mape: 85.1236 - val_mse: 37724736.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 5555.2544 - mae: 5555.2544 - mape: 85.3872 - mse: 38604768.0000 - val_loss: 5405.1689 - val_mae: 5405.1689 - val_mape: 84.3001 - val_mse: 37337224.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 5519.5278 - mae: 5519.5278 - mape: 84.6058 - mse: 38206872.0000 - val_loss: 5369.4424 - val_mae: 5369.4424 - val_mape: 83.4766 - val_mse: 36952288.0000\n",
      "-4191618131683.005\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_three_icbp = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp.summary()\n",
    "\n",
    "simple_model_three_icbp.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp = simple_model_three_icbp.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp = simple_model_three_icbp.predict(X_test_rs_icbp)\n",
    "\n",
    "print(r2_score(preds_three_icbp, y_test_icbp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_104 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_105 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_106 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_107 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,132\n",
      "Trainable params: 2,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 20s 173ms/step - loss: 6203.5332 - mae: 6203.5332 - mape: 99.6785 - mse: 46228856.0000 - val_loss: 6055.4307 - val_mae: 6055.4307 - val_mape: 99.2875 - val_mse: 44789620.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 6171.8179 - mae: 6171.8179 - mape: 98.9793 - mse: 45835540.0000 - val_loss: 6023.9937 - val_mae: 6023.9937 - val_mape: 98.5630 - val_mse: 44409880.0000 6187.6245 - mae: 6187.6245 - \n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 6140.5928 - mae: 6140.5928 - mape: 98.2935 - mse: 45450264.0000 - val_loss: 5992.9282 - val_mae: 5992.9282 - val_mape: 97.8470 - val_mse: 44036564.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 6109.6074 - mae: 6109.6074 - mape: 97.6056 - mse: 45072064.0000 - val_loss: 5962.0107 - val_mae: 5962.0107 - val_mape: 97.1344 - val_mse: 43666948.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 6078.7319 - mae: 6078.7319 - mape: 96.9316 - mse: 44693684.0000 - val_loss: 5931.1729 - val_mae: 5931.1729 - val_mape: 96.4236 - val_mse: 43300188.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 107ms/step - loss: 6047.9199 - mae: 6047.9199 - mape: 96.2510 - mse: 44321360.0000 - val_loss: 5900.3843 - val_mae: 5900.3843 - val_mape: 95.7140 - val_mse: 42935916.0000 ETA: 0s - loss: 6075.5757 - mae: 6075.5757 - mape: 96.3174 \n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 6017.1494 - mae: 6017.1494 - mape: 95.5692 - mse: 43950464.0000 - val_loss: 5869.6304 - val_mae: 5869.6304 - val_mape: 95.0051 - val_mse: 42573936.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 5986.4087 - mae: 5986.4087 - mape: 94.8934 - mse: 43580576.0000 - val_loss: 5838.9004 - val_mae: 5838.9004 - val_mape: 94.2969 - val_mse: 42214140.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 6s 112ms/step - loss: 5955.6880 - mae: 5955.6880 - mape: 94.2155 - mse: 43214116.0000 - val_loss: 5808.1895 - val_mae: 5808.1895 - val_mape: 93.5890 - val_mse: 41856440.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 5924.9844 - mae: 5924.9844 - mape: 93.5389 - mse: 42849700.0000 - val_loss: 5777.4927 - val_mae: 5777.4927 - val_mape: 92.8815 - val_mse: 41500792.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 5894.2939 - mae: 5894.2939 - mape: 92.8627 - mse: 42486096.0000 - val_loss: 5746.8076 - val_mae: 5746.8076 - val_mape: 92.1743 - val_mse: 41147172.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 5863.6118 - mae: 5863.6118 - mape: 92.1865 - mse: 42124936.0000 - val_loss: 5716.1318 - val_mae: 5716.1318 - val_mape: 91.4673 - val_mse: 40795540.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 5832.9409 - mae: 5832.9409 - mape: 91.5141 - mse: 41765428.0000 - val_loss: 5685.4653 - val_mae: 5685.4653 - val_mape: 90.7604 - val_mse: 40445888.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 5802.2773 - mae: 5802.2773 - mape: 90.8273 - mse: 41413124.0000 - val_loss: 5654.8047 - val_mae: 5654.8047 - val_mape: 90.0538 - val_mse: 40098188.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 5771.6201 - mae: 5771.6201 - mape: 90.1618 - mse: 41055524.0000 - val_loss: 5624.1499 - val_mae: 5624.1499 - val_mape: 89.3472 - val_mse: 39752436.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 5740.9692 - mae: 5740.9692 - mape: 89.4818 - mse: 40701756.0000 - val_loss: 5593.5000 - val_mae: 5593.5000 - val_mape: 88.6408 - val_mse: 39408620.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 5710.3198 - mae: 5710.3198 - mape: 88.8056 - mse: 40351892.0000 - val_loss: 5562.8545 - val_mae: 5562.8545 - val_mape: 87.9345 - val_mse: 39066732.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 5679.6763 - mae: 5679.6763 - mape: 88.1329 - mse: 40001984.0000 - val_loss: 5532.2134 - val_mae: 5532.2134 - val_mape: 87.2282 - val_mse: 38726760.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 5649.0376 - mae: 5649.0376 - mape: 87.4525 - mse: 39656752.0000 - val_loss: 5501.5757 - val_mae: 5501.5757 - val_mape: 86.5221 - val_mse: 38388704.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 5618.3999 - mae: 5618.3999 - mape: 86.7734 - mse: 39312880.0000 - val_loss: 5470.9404 - val_mae: 5470.9404 - val_mape: 85.8160 - val_mse: 38052568.0000\n",
      "-542864071097658.8\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_four_icbp = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_four_icbp.summary()\n",
    "\n",
    "simple_model_four_icbp.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_four_icbp = simple_model_four_icbp.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_four_icbp = simple_model_four_icbp.predict(X_test_rs_icbp)\n",
    "\n",
    "print(r2_score(preds_four_icbp, y_test_icbp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_108 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_109 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_110 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_111 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_112 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,676\n",
      "Trainable params: 2,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 22s 195ms/step - loss: 6200.4385 - mae: 6200.4385 - mape: 99.6132 - mse: 46188644.0000 - val_loss: 6049.9858 - val_mae: 6049.9858 - val_mape: 99.1621 - val_mse: 44723712.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 6s 116ms/step - loss: 6164.1240 - mae: 6164.1240 - mape: 98.8133 - mse: 45740188.0000 - val_loss: 6013.8550 - val_mae: 6013.8550 - val_mape: 98.3293 - val_mse: 44287824.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 6128.0986 - mae: 6128.0986 - mape: 98.0212 - mse: 45295260.0000 - val_loss: 5977.9077 - val_mae: 5977.9077 - val_mape: 97.5008 - val_mse: 43856760.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 6088.5234 - mae: 6088.5234 - mape: 97.1422 - mse: 44814672.0000 - val_loss: 5932.0493 - val_mae: 5932.0493 - val_mape: 96.4438 - val_mse: 43310580.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 6041.4062 - mae: 6041.4062 - mape: 96.1096 - mse: 44241576.0000 - val_loss: 5886.5317 - val_mae: 5886.5317 - val_mape: 95.3947 - val_mse: 42772628.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 6s 119ms/step - loss: 5996.9756 - mae: 5996.9756 - mape: 95.1293 - mse: 43707120.0000 - val_loss: 5842.9189 - val_mae: 5842.9189 - val_mape: 94.3895 - val_mse: 42261064.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 5953.8037 - mae: 5953.8037 - mape: 94.1762 - mse: 43189696.0000 - val_loss: 5800.1201 - val_mae: 5800.1201 - val_mape: 93.4031 - val_mse: 41762768.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 5911.2451 - mae: 5911.2451 - mape: 93.2349 - mse: 42686944.0000 - val_loss: 5757.7808 - val_mae: 5757.7808 - val_mape: 92.4272 - val_mse: 41273412.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 7s 129ms/step - loss: 5869.0591 - mae: 5869.0591 - mape: 92.3002 - mse: 42190564.0000 - val_loss: 5715.7388 - val_mae: 5715.7388 - val_mape: 91.4582 - val_mse: 40791036.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 6s 128ms/step - loss: 5827.1240 - mae: 5827.1240 - mape: 91.3805 - mse: 41698124.0000 - val_loss: 5673.9053 - val_mae: 5673.9053 - val_mape: 90.4940 - val_mse: 40314564.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 6s 119ms/step - loss: 5785.3687 - mae: 5785.3687 - mape: 90.4613 - mse: 41213672.0000 - val_loss: 5632.2261 - val_mae: 5632.2261 - val_mape: 89.5334 - val_mse: 39843344.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 6s 118ms/step - loss: 5743.7500 - mae: 5743.7500 - mape: 89.5479 - mse: 40731996.0000 - val_loss: 5590.6660 - val_mae: 5590.6660 - val_mape: 88.5755 - val_mse: 39376924.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 5702.2373 - mae: 5702.2373 - mape: 88.6268 - mse: 40259424.0000 - val_loss: 5549.2021 - val_mae: 5549.2021 - val_mape: 87.6198 - val_mse: 38915012.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 6s 124ms/step - loss: 5660.8120 - mae: 5660.8120 - mape: 87.7065 - mse: 39790180.0000 - val_loss: 5507.8145 - val_mae: 5507.8145 - val_mape: 86.6659 - val_mse: 38457388.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 6s 118ms/step - loss: 5619.4570 - mae: 5619.4570 - mape: 86.7960 - mse: 39323768.0000 - val_loss: 5466.4902 - val_mae: 5466.4902 - val_mape: 85.7135 - val_mse: 38003888.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 5578.1602 - mae: 5578.1602 - mape: 85.8944 - mse: 38859464.0000 - val_loss: 5425.2207 - val_mae: 5425.2207 - val_mape: 84.7622 - val_mse: 37554392.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 7s 134ms/step - loss: 5536.9141 - mae: 5536.9141 - mape: 84.9813 - mse: 38402696.0000 - val_loss: 5383.9961 - val_mae: 5383.9961 - val_mape: 83.8121 - val_mse: 37108788.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 7s 141ms/step - loss: 5495.7075 - mae: 5495.7075 - mape: 84.0762 - mse: 37944788.0000 - val_loss: 5342.8120 - val_mae: 5342.8120 - val_mape: 82.8628 - val_mse: 36667008.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 6s 117ms/step - loss: 5454.5400 - mae: 5454.5400 - mape: 83.1645 - mse: 37497220.0000 - val_loss: 5301.6611 - val_mae: 5301.6611 - val_mape: 81.9144 - val_mse: 36228980.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 6s 118ms/step - loss: 5413.4048 - mae: 5413.4048 - mape: 82.2513 - mse: 37051548.0000 - val_loss: 5260.5410 - val_mae: 5260.5410 - val_mape: 80.9667 - val_mse: 35794656.0000\n",
      "-524611357850307.9\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_five_icbp = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_five_icbp.summary()\n",
    "\n",
    "simple_model_five_icbp.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_five_icbp = simple_model_five_icbp.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_five_icbp = simple_model_five_icbp.predict(X_test_rs_icbp)\n",
    "\n",
    "print(r2_score(preds_five_icbp, y_test_icbp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_113 (LSTM)             (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500\n",
      "Trainable params: 500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 5s 45ms/step - loss: 4614.8340 - mae: 4614.8340 - val_loss: 4610.2661 - val_mae: 4610.2661\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4598.1274 - mae: 4598.1274 - val_loss: 4593.5146 - val_mae: 4593.5146\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 4581.3755 - mae: 4581.3755 - val_loss: 4576.7622 - val_mae: 4576.7622\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4564.6240 - mae: 4564.6240 - val_loss: 4560.0107 - val_mae: 4560.0107\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4547.8716 - mae: 4547.8716 - val_loss: 4543.2578 - val_mae: 4543.2578\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 4531.1191 - mae: 4531.1191 - val_loss: 4526.5054 - val_mae: 4526.5054\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 4514.3667 - mae: 4514.3667 - val_loss: 4509.7534 - val_mae: 4509.7534\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 4497.6138 - mae: 4497.6138 - val_loss: 4493.0015 - val_mae: 4493.0015\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 1s 28ms/step - loss: 4480.8628 - mae: 4480.8628 - val_loss: 4476.2485 - val_mae: 4476.2485\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 4464.1104 - mae: 4464.1104 - val_loss: 4459.4966 - val_mae: 4459.4966\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4447.3584 - mae: 4447.3584 - val_loss: 4442.7451 - val_mae: 4442.7451\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4430.6055 - mae: 4430.6055 - val_loss: 4425.9922 - val_mae: 4425.9922\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4413.8535 - mae: 4413.8535 - val_loss: 4409.2412 - val_mae: 4409.2412\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 4397.1021 - mae: 4397.1021 - val_loss: 4392.4883 - val_mae: 4392.4883\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4380.3501 - mae: 4380.3501 - val_loss: 4375.7363 - val_mae: 4375.7363\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4363.5972 - mae: 4363.5972 - val_loss: 4358.9839 - val_mae: 4358.9839\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - ETA: 0s - loss: 4348.1890 - mae: 4348.189 - 1s 24ms/step - loss: 4346.8447 - mae: 4346.8447 - val_loss: 4342.2319 - val_mae: 4342.2319\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4330.0928 - mae: 4330.0928 - val_loss: 4325.4800 - val_mae: 4325.4800\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 1s 27ms/step - loss: 4313.3408 - mae: 4313.3408 - val_loss: 4308.7275 - val_mae: 4308.7275\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 4296.5884 - mae: 4296.5884 - val_loss: 4291.9751 - val_mae: 4291.9751\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_one_jsmr = Sequential([\n",
    "  LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features)),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_one_jsmr.summary()\n",
    "\n",
    "simple_model_one_jsmr.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_one_jsmr = simple_model_one_jsmr.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_one_jsmr = simple_model_one_jsmr.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_114 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_115 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,044\n",
      "Trainable params: 1,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 12s 87ms/step - loss: 4607.5991 - mae: 4607.5991 - mape: 99.6536 - mse: 22332920.0000 - val_loss: 4595.4917 - val_mae: 4595.4917 - val_mape: 99.2723 - val_mse: 22365930.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 4576.4346 - mae: 4576.4346 - mape: 98.9289 - mse: 22046756.0000 - val_loss: 4564.5049 - val_mae: 4564.5049 - val_mape: 98.5464 - val_mse: 22082092.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 4545.5435 - mae: 4545.5435 - mape: 98.2139 - mse: 21764890.0000 - val_loss: 4533.6836 - val_mae: 4533.6836 - val_mape: 97.8244 - val_mse: 21801674.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 4514.7588 - mae: 4514.7588 - mape: 97.5042 - mse: 21484784.0000 - val_loss: 4502.9312 - val_mae: 4502.9312 - val_mape: 97.1041 - val_mse: 21523778.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 3s 52ms/step - loss: 4484.0264 - mae: 4484.0264 - mape: 96.7873 - mse: 21209170.0000 - val_loss: 4472.2168 - val_mae: 4472.2168 - val_mape: 96.3846 - val_mse: 21248106.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 3s 58ms/step - loss: 4453.3232 - mae: 4453.3232 - mape: 96.0778 - mse: 20934098.0000 - val_loss: 4441.5249 - val_mae: 4441.5249 - val_mape: 95.6656 - val_mse: 20974532.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 3s 55ms/step - loss: 4422.6401 - mae: 4422.6401 - mape: 95.3627 - mse: 20662638.0000 - val_loss: 4410.8501 - val_mae: 4410.8501 - val_mape: 94.9471 - val_mse: 20702984.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 3s 62ms/step - loss: 4391.9722 - mae: 4391.9722 - mape: 94.6509 - mse: 20392438.0000 - val_loss: 4380.1870 - val_mae: 4380.1870 - val_mape: 94.2288 - val_mse: 20433424.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 4361.3135 - mae: 4361.3135 - mape: 93.9406 - mse: 20124064.0000 - val_loss: 4349.5327 - val_mae: 4349.5327 - val_mape: 93.5107 - val_mse: 20165820.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 3s 52ms/step - loss: 4330.6616 - mae: 4330.6616 - mape: 93.2296 - mse: 19857486.0000 - val_loss: 4318.8857 - val_mae: 4318.8857 - val_mape: 92.7929 - val_mse: 19900158.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 4300.0181 - mae: 4300.0181 - mape: 92.5204 - mse: 19592612.0000 - val_loss: 4288.2441 - val_mae: 4288.2441 - val_mape: 92.0751 - val_mse: 19636420.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 4269.3784 - mae: 4269.3784 - mape: 91.8107 - mse: 19329580.0000 - val_loss: 4257.6069 - val_mae: 4257.6069 - val_mape: 91.3574 - val_mse: 19374604.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 4238.7437 - mae: 4238.7437 - mape: 91.0981 - mse: 19069564.0000 - val_loss: 4226.9741 - val_mae: 4226.9741 - val_mape: 90.6399 - val_mse: 19114698.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 4208.1133 - mae: 4208.1133 - mape: 90.3868 - mse: 18811008.0000 - val_loss: 4196.3447 - val_mae: 4196.3447 - val_mape: 89.9224 - val_mse: 18856696.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 3s 52ms/step - loss: 4177.4844 - mae: 4177.4844 - mape: 89.6756 - mse: 18554662.0000 - val_loss: 4165.7183 - val_mae: 4165.7183 - val_mape: 89.2050 - val_mse: 18600592.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 4146.8589 - mae: 4146.8589 - mape: 88.9640 - mse: 18299944.0000 - val_loss: 4135.0938 - val_mae: 4135.0938 - val_mape: 88.4876 - val_mse: 18346384.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 3s 51ms/step - loss: 4116.2358 - mae: 4116.2358 - mape: 88.2580 - mse: 18045664.0000 - val_loss: 4104.4717 - val_mae: 4104.4717 - val_mape: 87.7703 - val_mse: 18094072.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 4085.6150 - mae: 4085.6150 - mape: 87.5466 - mse: 17794914.0000 - val_loss: 4073.8516 - val_mae: 4073.8516 - val_mape: 87.0530 - val_mse: 17843652.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 4054.9954 - mae: 4054.9954 - mape: 86.8352 - mse: 17545564.0000 - val_loss: 4043.2334 - val_mae: 4043.2334 - val_mape: 86.3358 - val_mse: 17595116.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 3s 52ms/step - loss: 4024.3767 - mae: 4024.3767 - mape: 86.1249 - mse: 17298296.0000 - val_loss: 4012.6160 - val_mae: 4012.6160 - val_mape: 85.6186 - val_mse: 17348470.0000\n",
      "-286059389005544.94\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_two_jsmr = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_two_jsmr.summary()\n",
    "\n",
    "simple_model_two_jsmr.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_two_jsmr = simple_model_two_jsmr.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_two_jsmr = simple_model_two_jsmr.predict(X_test_rs_jsmr)\n",
    "\n",
    "print(r2_score(preds_two_jsmr, y_test_jsmr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_116 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_117 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_118 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 23s 161ms/step - loss: 4602.5352 - mae: 4602.5352 - mape: 99.5356 - mse: 22286404.0000 - val_loss: 4581.9194 - val_mae: 4581.9194 - val_mape: 98.9543 - val_mse: 22241378.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 4554.6689 - mae: 4554.6689 - mape: 98.4286 - mse: 21847092.0000 - val_loss: 4534.2046 - val_mae: 4534.2046 - val_mape: 97.8366 - val_mse: 21806400.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 4507.4248 - mae: 4507.4248 - mape: 97.3322 - mse: 21418416.0000 - val_loss: 4487.3081 - val_mae: 4487.3081 - val_mape: 96.7381 - val_mse: 21383322.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 4460.7041 - mae: 4460.7041 - mape: 96.2444 - mse: 21001240.0000 - val_loss: 4440.7344 - val_mae: 4440.7344 - val_mape: 95.6471 - val_mse: 20967512.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 4414.2217 - mae: 4414.2217 - mape: 95.1668 - mse: 20588140.0000 - val_loss: 4394.3315 - val_mae: 4394.3315 - val_mape: 94.5602 - val_mse: 20557536.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 4367.8730 - mae: 4367.8730 - mape: 94.0887 - mse: 20181712.0000 - val_loss: 4348.0342 - val_mae: 4348.0342 - val_mape: 93.4756 - val_mse: 20152786.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 4321.6118 - mae: 4321.6118 - mape: 93.0205 - mse: 19779428.0000 - val_loss: 4301.8081 - val_mae: 4301.8081 - val_mape: 92.3928 - val_mse: 19752944.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 4275.4131 - mae: 4275.4131 - mape: 91.9490 - mse: 19382000.0000 - val_loss: 4255.6348 - val_mae: 4255.6348 - val_mape: 91.3112 - val_mse: 19357816.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 4229.2593 - mae: 4229.2593 - mape: 90.8858 - mse: 18987446.0000 - val_loss: 4209.5005 - val_mae: 4209.5005 - val_mape: 90.2305 - val_mse: 18967284.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 4183.1411 - mae: 4183.1411 - mape: 89.8064 - mse: 18601486.0000 - val_loss: 4163.3975 - val_mae: 4163.3975 - val_mape: 89.1506 - val_mse: 18581266.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 4137.0503 - mae: 4137.0503 - mape: 88.7350 - mse: 18219108.0000 - val_loss: 4117.3188 - val_mae: 4117.3188 - val_mape: 88.0712 - val_mse: 18199702.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 4090.9814 - mae: 4090.9814 - mape: 87.6697 - mse: 17839018.0000 - val_loss: 4071.2605 - val_mae: 4071.2605 - val_mape: 86.9923 - val_mse: 17822550.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 4044.9319 - mae: 4044.9319 - mape: 86.6061 - mse: 17463278.0000 - val_loss: 4025.2188 - val_mae: 4025.2188 - val_mape: 85.9138 - val_mse: 17449778.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 3998.8977 - mae: 3998.8977 - mape: 85.5344 - mse: 17094076.0000 - val_loss: 3979.1914 - val_mae: 3979.1914 - val_mape: 84.8356 - val_mse: 17081356.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 3952.8767 - mae: 3952.8767 - mape: 84.4665 - mse: 16727839.0000 - val_loss: 3933.1770 - val_mae: 3933.1770 - val_mape: 83.7577 - val_mse: 16717270.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 3906.8665 - mae: 3906.8665 - mape: 83.4039 - mse: 16365268.0000 - val_loss: 3887.1721 - val_mae: 3887.1721 - val_mape: 82.6801 - val_mse: 16357500.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 3860.8669 - mae: 3860.8669 - mape: 82.3334 - mse: 16008836.0000 - val_loss: 3841.1775 - val_mae: 3841.1775 - val_mape: 81.6027 - val_mse: 16002033.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 3814.8757 - mae: 3814.8757 - mape: 81.2654 - mse: 15656684.0000 - val_loss: 3795.1902 - val_mae: 3795.1902 - val_mape: 80.5255 - val_mse: 15650859.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 3768.8923 - mae: 3768.8923 - mape: 80.1966 - mse: 15307891.0000 - val_loss: 3749.2102 - val_mae: 3749.2102 - val_mape: 79.4484 - val_mse: 15303966.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 3722.9153 - mae: 3722.9153 - mape: 79.1301 - mse: 14963676.0000 - val_loss: 3703.2368 - val_mae: 3703.2368 - val_mape: 78.3715 - val_mse: 14961352.0000\n",
      "-673945668716.6776\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_three_jsmr = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr.summary()\n",
    "\n",
    "simple_model_three_jsmr.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr = simple_model_three_jsmr.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr = simple_model_three_jsmr.predict(X_test_rs_jsmr)\n",
    "\n",
    "print(r2_score(preds_three_jsmr, y_test_jsmr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_119 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_120 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_121 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_122 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,132\n",
      "Trainable params: 2,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 35s 383ms/step - loss: 4607.4258 - mae: 4607.4258 - mape: 99.6499 - mse: 22331288.0000 - val_loss: 4594.9785 - val_mae: 4594.9785 - val_mape: 99.2602 - val_mse: 22361218.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 4568.2612 - mae: 4568.2612 - mape: 98.7426 - mse: 21971620.0000 - val_loss: 4547.6704 - val_mae: 4547.6704 - val_mape: 98.1520 - val_mse: 21928692.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 4521.8315 - mae: 4521.8315 - mape: 97.6634 - mse: 21550220.0000 - val_loss: 4503.0688 - val_mae: 4503.0688 - val_mape: 97.1073 - val_mse: 21525018.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4478.1157 - mae: 4478.1157 - mape: 96.6507 - mse: 21156412.0000 - val_loss: 4460.0229 - val_mae: 4460.0229 - val_mape: 96.0989 - val_mse: 21139192.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 4435.4302 - mae: 4435.4302 - mape: 95.6627 - mse: 20775104.0000 - val_loss: 4417.6450 - val_mae: 4417.6450 - val_mape: 95.1063 - val_mse: 20762980.0000 4404.0806 - mae: 4404.0806 - mape: 95 - ETA: 2s - loss: 4422.7339 - mae: \n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 4393.2500 - mae: 4393.2500 - mape: 94.6812 - mse: 20403676.0000 - val_loss: 4375.6421 - val_mae: 4375.6421 - val_mape: 94.1224 - val_mse: 20393634.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4351.3706 - mae: 4351.3706 - mape: 93.7112 - mse: 20037148.0000 - val_loss: 4333.8784 - val_mae: 4333.8784 - val_mape: 93.1440 - val_mse: 20029892.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4309.6924 - mae: 4309.6924 - mape: 92.7471 - mse: 19675302.0000 - val_loss: 4292.2817 - val_mae: 4292.2817 - val_mape: 92.1697 - val_mse: 19671072.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 4268.1582 - mae: 4268.1582 - mape: 91.7792 - mse: 19320436.0000 - val_loss: 4250.8076 - val_mae: 4250.8076 - val_mape: 91.1981 - val_mse: 19316754.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4226.7314 - mae: 4226.7314 - mape: 90.8180 - mse: 18968582.0000 - val_loss: 4209.4268 - val_mae: 4209.4268 - val_mape: 90.2288 - val_mse: 18966666.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 4185.3887 - mae: 4185.3887 - mape: 89.8564 - mse: 18621258.0000 - val_loss: 4168.1206 - val_mae: 4168.1206 - val_mape: 89.2612 - val_mse: 18620622.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 4144.1123 - mae: 4144.1123 - mape: 88.8976 - mse: 18277312.0000 - val_loss: 4126.8745 - val_mae: 4126.8745 - val_mape: 88.2950 - val_mse: 18278484.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 4102.8901 - mae: 4102.8901 - mape: 87.9464 - mse: 17936842.0000 - val_loss: 4085.6780 - val_mae: 4085.6780 - val_mape: 87.3300 - val_mse: 17940154.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 4061.7146 - mae: 4061.7146 - mape: 86.9899 - mse: 17601210.0000 - val_loss: 4044.5229 - val_mae: 4044.5229 - val_mape: 86.3660 - val_mse: 17605552.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4020.5779 - mae: 4020.5779 - mape: 86.0342 - mse: 17268882.0000 - val_loss: 4003.4026 - val_mae: 4003.4026 - val_mape: 85.4027 - val_mse: 17274622.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 3979.4727 - mae: 3979.4727 - mape: 85.0875 - mse: 16937930.0000 - val_loss: 3962.3125 - val_mae: 3962.3125 - val_mape: 84.4402 - val_mse: 16947312.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 3938.3955 - mae: 3938.3955 - mape: 84.1285 - mse: 16614086.0000 - val_loss: 3921.2488 - val_mae: 3921.2488 - val_mape: 83.4783 - val_mse: 16623584.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 3897.3425 - mae: 3897.3425 - mape: 83.1761 - mse: 16293277.0000 - val_loss: 3880.2083 - val_mae: 3880.2083 - val_mape: 82.5170 - val_mse: 16303406.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 3856.3113 - mae: 3856.3113 - mape: 82.2267 - mse: 15973968.0000 - val_loss: 3839.1875 - val_mae: 3839.1875 - val_mape: 81.5561 - val_mse: 15986753.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 3815.2998 - mae: 3815.2998 - mape: 81.2770 - mse: 15658890.0000 - val_loss: 3798.1851 - val_mae: 3798.1851 - val_mape: 80.5956 - val_mse: 15673597.0000\n",
      "-53758832754979.58\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_four_jsmr = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_four_jsmr.summary()\n",
    "\n",
    "simple_model_four_jsmr.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_four_jsmr = simple_model_four_jsmr.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_four_jsmr = simple_model_four_jsmr.predict(X_test_rs_jsmr)\n",
    "\n",
    "print(r2_score(preds_four_jsmr, y_test_jsmr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_123 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_124 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_125 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_126 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_127 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,676\n",
      "Trainable params: 2,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 25s 230ms/step - loss: 4600.7607 - mae: 4600.7607 - mape: 99.4946 - mse: 22269640.0000 - val_loss: 4580.0322 - val_mae: 4580.0322 - val_mape: 98.9101 - val_mse: 22224082.0000\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 7s 138ms/step - loss: 4553.0566 - mae: 4553.0566 - mape: 98.3897 - mse: 21833118.0000 - val_loss: 4532.8154 - val_mae: 4532.8154 - val_mape: 97.8041 - val_mse: 21793798.0000\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 4506.1680 - mae: 4506.1680 - mape: 97.3025 - mse: 21408240.0000 - val_loss: 4486.1714 - val_mae: 4486.1714 - val_mape: 96.7115 - val_mse: 21373118.0000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 4459.6523 - mae: 4459.6523 - mape: 96.2197 - mse: 20992120.0000 - val_loss: 4439.7617 - val_mae: 4439.7617 - val_mape: 95.6243 - val_mse: 20958870.0000\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 4413.3096 - mae: 4413.3096 - mape: 95.1454 - mse: 20580332.0000 - val_loss: 4393.4795 - val_mae: 4393.4795 - val_mape: 94.5402 - val_mse: 20550044.0000\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 8s 150ms/step - loss: 4367.0674 - mae: 4367.0674 - mape: 94.0739 - mse: 20174234.0000 - val_loss: 4347.2754 - val_mae: 4347.2754 - val_mape: 93.4579 - val_mse: 20146188.0000\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 7s 140ms/step - loss: 4320.8916 - mae: 4320.8916 - mape: 93.0025 - mse: 19773258.0000 - val_loss: 4301.1255 - val_mae: 4301.1255 - val_mape: 92.3768 - val_mse: 19747066.0000\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 6s 123ms/step - loss: 4274.7627 - mae: 4274.7627 - mape: 91.9348 - mse: 19376070.0000 - val_loss: 4255.0156 - val_mae: 4255.0156 - val_mape: 91.2967 - val_mse: 19352544.0000\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 6s 126ms/step - loss: 4228.6675 - mae: 4228.6675 - mape: 90.8644 - mse: 18984454.0000 - val_loss: 4208.9360 - val_mae: 4208.9360 - val_mape: 90.2173 - val_mse: 18962528.0000\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 4182.5996 - mae: 4182.5996 - mape: 89.7986 - mse: 18596648.0000 - val_loss: 4162.8794 - val_mae: 4162.8794 - val_mape: 89.1385 - val_mse: 18576952.0000\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 6s 126ms/step - loss: 4136.5537 - mae: 4136.5537 - mape: 88.7257 - mse: 18214664.0000 - val_loss: 4116.8418 - val_mae: 4116.8418 - val_mape: 88.0600 - val_mse: 18195772.0000\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 6s 123ms/step - loss: 4090.5227 - mae: 4090.5227 - mape: 87.6588 - mse: 17835790.0000 - val_loss: 4070.8198 - val_mae: 4070.8198 - val_mape: 86.9820 - val_mse: 17818958.0000\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 7s 132ms/step - loss: 4044.5073 - mae: 4044.5073 - mape: 86.5918 - mse: 17461290.0000 - val_loss: 4024.8105 - val_mae: 4024.8105 - val_mape: 85.9043 - val_mse: 17446486.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 3998.5032 - mae: 3998.5032 - mape: 85.5221 - mse: 17091782.0000 - val_loss: 3978.8125 - val_mae: 3978.8125 - val_mape: 84.8268 - val_mse: 17078332.0000\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 6s 125ms/step - loss: 3952.5103 - mae: 3952.5103 - mape: 84.4586 - mse: 16724974.0000 - val_loss: 3932.8240 - val_mae: 3932.8240 - val_mape: 83.7495 - val_mse: 16714488.0000\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 7s 133ms/step - loss: 3906.5261 - mae: 3906.5261 - mape: 83.3898 - mse: 16364827.0000 - val_loss: 3886.8435 - val_mae: 3886.8435 - val_mape: 82.6724 - val_mse: 16354935.0000\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 7s 139ms/step - loss: 3860.5483 - mae: 3860.5483 - mape: 82.3286 - mse: 16005825.0000 - val_loss: 3840.8694 - val_mae: 3840.8694 - val_mape: 81.5955 - val_mse: 15999664.0000\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 3814.5781 - mae: 3814.5781 - mape: 81.2595 - mse: 15654155.0000 - val_loss: 3794.9026 - val_mae: 3794.9026 - val_mape: 80.5187 - val_mse: 15648670.0000\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 7s 137ms/step - loss: 3768.6138 - mae: 3768.6138 - mape: 80.1961 - mse: 15304422.0000 - val_loss: 3748.9409 - val_mae: 3748.9409 - val_mape: 79.4421 - val_mse: 15301940.0000\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 7s 135ms/step - loss: 3722.6541 - mae: 3722.6541 - mape: 79.1254 - mse: 14960907.0000 - val_loss: 3702.9841 - val_mae: 3702.9841 - val_mape: 78.3656 - val_mse: 14959473.0000\n",
      "-721231362191.8337\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "simple_model_five_jsmr = Sequential([\n",
    "   LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features), return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh', return_sequences=True),\n",
    "    LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_five_jsmr.summary()\n",
    "\n",
    "simple_model_five_jsmr.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    " metrics=['mae','mape','mse'],\n",
    ")\n",
    "\n",
    "smod_history_five_jsmr = simple_model_five_jsmr.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_five_jsmr = simple_model_five_jsmr.predict(X_test_rs_jsmr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIKS EVALUASI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 layer\n",
      "mae score antm: 923.03\n",
      "mae score asii: 5523.32\n",
      "mae score icbp: 6091.78\n",
      "mae score jsmr: 4256.87\n",
      "2 layer\n",
      "mae score antm: 478.19\n",
      "mae score asii: 4801.8\n",
      "mae score icbp: 5547.64\n",
      "mae score jsmr: 3977.51\n",
      "3 layer\n",
      "mae score antm: 420.88\n",
      "mae score asii: 4713.58\n",
      "mae score icbp: 5554.57\n",
      "mae score jsmr: 3668.13\n",
      "4 layer\n",
      "mae score antm: 441.47\n",
      "mae score asii: 4806.41\n",
      "mae score icbp: 5656.07\n",
      "mae score jsmr: 3763.08\n",
      "5 layer\n",
      "mae score antm: 442.58\n",
      "mae score asii: 4704.14\n",
      "mae score icbp: 5445.67\n",
      "mae score jsmr: 3667.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Forecast\n",
    "# mae score\n",
    "print('1 layer')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_one_antm, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_one_asii, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_one_icbp, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_one_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('2 layer')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_two_antm, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_two_asii, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_two_icbp, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_two_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('3 layer')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('4 layer')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_four_antm, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_four_asii, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_four_icbp, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_four_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('5 layer')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_five_antm, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_five_asii, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_five_icbp, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_five_jsmr, y_test_jsmr).round(2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 layer\n",
      "mape score antm: 5.14\n",
      "mape score asii: 54.15\n",
      "mape score icbp: 33.9\n",
      "mape score jsmr: 12.72\n",
      "2 layer\n",
      "mape score antm: 0.71\n",
      "mape score asii: 5.83\n",
      "mape score icbp: 7.66\n",
      "mape score jsmr: 6.48\n",
      "3 layer\n",
      "mape score antm: 0.53\n",
      "mape score asii: 5.17\n",
      "mape score icbp: 7.75\n",
      "mape score jsmr: 3.97\n",
      "4 layer\n",
      "mape score antm: 0.6\n",
      "mape score asii: 5.87\n",
      "mape score icbp: 9.19\n",
      "mape score jsmr: 4.54\n",
      "5 layer\n",
      "mape score antm: 0.6\n",
      "mape score asii: 5.11\n",
      "mape score icbp: 6.59\n",
      "mape score jsmr: 3.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "# Forecast\n",
    "# mape score\n",
    "print('1 layer')\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_one_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_one_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_one_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_one_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('2 layer')\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_two_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_two_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_two_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_two_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('3 layer')\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_three_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_three_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('4 layer')\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_four_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_four_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_four_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_four_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('5 layer')\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_five_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_five_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_five_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_five_jsmr, y_test_jsmr).round(2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 layer\n",
      "mape score antm: -4155615855676.74\n",
      "mape score asii: -71765318041729.22\n",
      "mape score icbp: -9998158765638230.0\n",
      "mape score jsmr: -495837858575104.75\n",
      "2 layer\n",
      "mape score antm: -326172289768.84\n",
      "mape score asii: -2610888312568.86\n",
      "mape score icbp: -16852658550471.13\n",
      "mape score jsmr: -286059389005544.94\n",
      "3 layer\n",
      "mape score antm: -22539986560.85\n",
      "mape score asii: -316915073704335.9\n",
      "mape score icbp: -4191618131683.0\n",
      "mape score jsmr: -673945668716.68\n",
      "4 layer\n",
      "mape score antm: -6465379666379.04\n",
      "mape score asii: -4146636568567.22\n",
      "mape score icbp: -542864071097658.8\n",
      "mape score jsmr: -53758832754979.58\n",
      "5 layer\n",
      "mape score antm: -118875513455.75\n",
      "mape score asii: -21412351604304.24\n",
      "mape score icbp: -524611357850307.8\n",
      "mape score jsmr: -721231362191.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# Forecast\n",
    "# mape score\n",
    "print('1 layer')\n",
    "print(\"mape score antm: \"+str(r2_score(preds_one_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(r2_score(preds_one_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(r2_score(preds_one_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(r2_score(preds_one_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('2 layer')\n",
    "print(\"mape score antm: \"+str(r2_score(preds_two_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(r2_score(preds_two_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(r2_score(preds_two_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(r2_score(preds_two_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('3 layer')\n",
    "print(\"mape score antm: \"+str(r2_score(preds_three_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(r2_score(preds_three_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(r2_score(preds_three_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(r2_score(preds_three_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('4 layer')\n",
    "print(\"mape score antm: \"+str(r2_score(preds_four_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(r2_score(preds_four_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(r2_score(preds_four_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(r2_score(preds_four_jsmr, y_test_jsmr).round(2)))\n",
    "\n",
    "print('5 layer')\n",
    "print(\"mape score antm: \"+str(r2_score(preds_five_antm, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(r2_score(preds_five_asii, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(r2_score(preds_five_icbp, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(r2_score(preds_five_jsmr, y_test_jsmr).round(2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_131 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_132 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_133 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 24s 219ms/step - loss: 1060.2881 - mae: 1060.2881 - val_loss: 1021.1514 - val_mae: 1021.1514\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 1023.9376 - mae: 1023.9376 - val_loss: 985.0095 - val_mae: 985.0095\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 6s 115ms/step - loss: 987.9043 - mae: 987.9043 - val_loss: 949.0569 - val_mae: 949.0569\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 951.9941 - mae: 951.9941 - val_loss: 913.1829 - val_mae: 913.1829\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 916.1428 - mae: 916.1428 - val_loss: 877.3518 - val_mae: 877.3518\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 880.3254 - mae: 880.3254 - val_loss: 841.5475 - val_mae: 841.5475\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 844.5309 - mae: 844.5309 - val_loss: 805.7618 - val_mae: 805.7618\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 808.7594 - mae: 808.7594 - val_loss: 770.0119 - val_mae: 770.0119\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 773.5138 - mae: 773.5138 - val_loss: 735.5352 - val_mae: 735.5352\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 739.7767 - mae: 739.7767 - val_loss: 702.5678 - val_mae: 702.5678\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 707.4625 - mae: 707.4625 - val_loss: 671.0542 - val_mae: 671.0542\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 676.6603 - mae: 676.6603 - val_loss: 641.8573 - val_mae: 641.8573\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 647.5294 - mae: 647.5294 - val_loss: 613.6227 - val_mae: 613.6227\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 619.0890 - mae: 619.0890 - val_loss: 585.7874 - val_mae: 585.7874\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 591.3602 - mae: 591.3602 - val_loss: 558.9119 - val_mae: 558.9119\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 564.6416 - mae: 564.6416 - val_loss: 532.3544 - val_mae: 532.3544- ETA: 0s - loss: 563.1884 - mae: 56\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 538.4770 - mae: 538.4770 - val_loss: 506.1169 - val_mae: 506.1169\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 513.1591 - mae: 513.1591 - val_loss: 482.1234 - val_mae: 482.1234\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 490.1787 - mae: 490.1787 - val_loss: 461.0040 - val_mae: 461.0040\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 470.0851 - mae: 470.0851 - val_loss: 443.5192 - val_mae: 443.5192\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit8 = Sequential([\n",
    "  LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='tanh',return_sequences=True),\n",
    "  LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit8.summary()\n",
    "\n",
    "simple_model_three_antm_unit8.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit8 = simple_model_three_antm_unit8.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit8 = simple_model_three_antm_unit8.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_134 (LSTM)             (None, 60, 16)            1152      \n",
      "                                                                 \n",
      " lstm_135 (LSTM)             (None, 60, 16)            2112      \n",
      "                                                                 \n",
      " lstm_136 (LSTM)             (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 20)                340       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,716\n",
      "Trainable params: 5,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 25s 191ms/step - loss: 1057.9419 - mae: 1057.9419 - val_loss: 1016.3122 - val_mae: 1016.3122\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 1016.6903 - mae: 1016.6903 - val_loss: 975.1846 - val_mae: 975.1846 - \n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 975.6423 - mae: 975.6423 - val_loss: 934.1965 - val_mae: 934.1965\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 934.6857 - mae: 934.6857 - val_loss: 893.2668 - val_mae: 893.2668\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 893.7729 - mae: 893.7729 - val_loss: 852.3689 - val_mae: 852.3689\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 852.8854 - mae: 852.8854 - val_loss: 811.4910 - val_mae: 811.4910\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 812.0192 - mae: 812.0192 - val_loss: 770.6449 - val_mae: 770.6449\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 771.8067 - mae: 771.8067 - val_loss: 731.3362 - val_mae: 731.3362\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 733.4706 - mae: 733.4706 - val_loss: 694.0759 - val_mae: 694.0759\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 696.9469 - mae: 696.9469 - val_loss: 658.8880 - val_mae: 658.8880\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 662.5168 - mae: 662.5168 - val_loss: 626.1354 - val_mae: 626.1354\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 629.7048 - mae: 629.7048 - val_loss: 594.2120 - val_mae: 594.2120\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 597.8587 - mae: 597.8587 - val_loss: 563.0790 - val_mae: 563.0790\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 567.1349 - mae: 567.1349 - val_loss: 533.0128 - val_mae: 533.0128e: 565.556 - ETA: 1s - loss: 566.53\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 537.2985 - mae: 537.2985 - val_loss: 503.3307 - val_mae: 503.3307 m\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 508.4660 - mae: 508.4660 - val_loss: 476.1591 - val_mae: 476.1591\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 483.0078 - mae: 483.0078 - val_loss: 453.3782 - val_mae: 453.3782\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 461.4323 - mae: 461.4323 - val_loss: 435.3218 - val_mae: 435.3218\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 444.3030 - mae: 444.3030 - val_loss: 421.5886 - val_mae: 421.5886\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 430.5712 - mae: 430.5712 - val_loss: 410.3658 - val_mae: 410.3658\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit16 = Sequential([\n",
    "  LSTM(16, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(16, activation='tanh',return_sequences=True),\n",
    "  LSTM(16, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit16.summary()\n",
    "\n",
    "simple_model_three_antm_unit16.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit16 = simple_model_three_antm_unit16.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit16 = simple_model_three_antm_unit16.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_137 (LSTM)             (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_138 (LSTM)             (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_139 (LSTM)             (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 40s 506ms/step - loss: 1001.2787 - mae: 1001.2787 - val_loss: 898.7371 - val_mae: 898.7371\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 22s 426ms/step - loss: 842.0906 - mae: 842.0906 - val_loss: 740.5894 - val_mae: 740.5894\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 21s 410ms/step - loss: 692.0582 - mae: 692.0582 - val_loss: 604.3146 - val_mae: 604.3146\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 21s 415ms/step - loss: 565.1126 - mae: 565.1126 - val_loss: 486.6951 - val_mae: 486.6951\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 21s 414ms/step - loss: 463.2418 - mae: 463.2418 - val_loss: 414.8334 - val_mae: 414.8334\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 21s 410ms/step - loss: 410.7730 - mae: 410.7730 - val_loss: 386.3815 - val_mae: 386.3815\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 21s 412ms/step - loss: 394.1379 - mae: 394.1379 - val_loss: 378.3345 - val_mae: 378.3345\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 21s 413ms/step - loss: 390.3334 - mae: 390.3334 - val_loss: 376.6450 - val_mae: 376.6450\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 21s 419ms/step - loss: 389.5491 - mae: 389.5491 - val_loss: 376.3578 - val_mae: 376.3578\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 21s 422ms/step - loss: 389.4110 - mae: 389.4110 - val_loss: 376.2886 - val_mae: 376.2886\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 26s 507ms/step - loss: 389.2432 - mae: 389.2432 - val_loss: 376.2901 - val_mae: 376.2901\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 24s 470ms/step - loss: 389.2588 - mae: 389.2588 - val_loss: 376.3049 - val_mae: 376.3049\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 21s 421ms/step - loss: 389.1707 - mae: 389.1707 - val_loss: 376.3264 - val_mae: 376.3264\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 22s 440ms/step - loss: 389.2100 - mae: 389.2100 - val_loss: 376.3399 - val_mae: 376.3399\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 21s 407ms/step - loss: 389.1318 - mae: 389.1318 - val_loss: 376.3499 - val_mae: 376.3499\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 20s 395ms/step - loss: 389.1311 - mae: 389.1311 - val_loss: 376.3364 - val_mae: 376.3364\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 21s 405ms/step - loss: 389.1925 - mae: 389.1925 - val_loss: 376.3724 - val_mae: 376.3724\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 21s 415ms/step - loss: 389.2610 - mae: 389.2610 - val_loss: 376.4102 - val_mae: 376.4102\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 21s 418ms/step - loss: 389.1618 - mae: 389.1618 - val_loss: 376.3977 - val_mae: 376.3977\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 23s 451ms/step - loss: 389.1573 - mae: 389.1573 - val_loss: 376.3756 - val_mae: 376.3756\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit64 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit64.summary()\n",
    "\n",
    "simple_model_three_antm_unit64.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit64 = simple_model_three_antm_unit64.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit64 = simple_model_three_antm_unit64.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_140 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_141 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_142 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 18s 133ms/step - loss: 5640.9663 - mae: 5640.9663 - val_loss: 5579.6582 - val_mae: 5579.6582\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 5608.8628 - mae: 5608.8628 - val_loss: 5547.5078 - val_mae: 5547.5078\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 5572.5562 - mae: 5572.5562 - val_loss: 5506.2100 - val_mae: 5506.2100\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 5531.9624 - mae: 5531.9624 - val_loss: 5467.0679 - val_mae: 5467.0679\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 5493.4248 - mae: 5493.4248 - val_loss: 5427.0317 - val_mae: 5427.0317\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 5446.5176 - mae: 5446.5176 - val_loss: 5375.7402 - val_mae: 5375.74025438.0562 - mae:\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 5397.7769 - mae: 5397.7769 - val_loss: 5329.0435 - val_mae: 5329.0435\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 5352.0767 - mae: 5352.0767 - val_loss: 5284.1611 - val_mae: 5284.1611\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 5307.6992 - mae: 5307.6992 - val_loss: 5240.2329 - val_mae: 5240.2329\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 5264.0830 - mae: 5264.0830 - val_loss: 5196.9067 - val_mae: 5196.9067\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 5220.9702 - mae: 5220.9702 - val_loss: 5154.0005 - val_mae: 5154.0005\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5178.2222 - mae: 5178.2222 - val_loss: 5111.4048 - val_mae: 5111.4048\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 5135.7485 - mae: 5135.7485 - val_loss: 5069.0498 - val_mae: 5069.0498\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 5093.4897 - mae: 5093.4897 - val_loss: 5026.8857 - val_mae: 5026.8857\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 88ms/step - loss: 5051.4028 - mae: 5051.4028 - val_loss: 4984.8770 - val_mae: 4984.8770\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 5009.4595 - mae: 5009.4595 - val_loss: 4942.9971 - val_mae: 4942.9971\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4967.6338 - mae: 4967.6338 - val_loss: 4901.2275 - val_mae: 4901.2275\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 4925.9102 - mae: 4925.9102 - val_loss: 4859.5503 - val_mae: 4859.5503\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 4884.2739 - mae: 4884.2739 - val_loss: 4817.9541 - val_mae: 4817.9541\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 4842.7119 - mae: 4842.7119 - val_loss: 4776.4268 - val_mae: 4776.4268\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit8 = Sequential([\n",
    "  LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='tanh',return_sequences=True),\n",
    "  LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit8.summary()\n",
    "\n",
    "simple_model_three_asii_unit8.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit8 = simple_model_three_asii_unit8.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit8 = simple_model_three_asii_unit8.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_143 (LSTM)             (None, 60, 16)            1152      \n",
      "                                                                 \n",
      " lstm_144 (LSTM)             (None, 60, 16)            2112      \n",
      "                                                                 \n",
      " lstm_145 (LSTM)             (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 20)                340       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,716\n",
      "Trainable params: 5,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 49s 122ms/step - loss: 5632.1602 - mae: 5632.1602 - val_loss: 5563.2822 - val_mae: 5563.2822- loss: 5625.9956 - mae: 5625.\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 68ms/step - loss: 5585.7119 - mae: 5585.7119 - val_loss: 5516.9883 - val_mae: 5516.9883\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 5539.5156 - mae: 5539.5156 - val_loss: 5470.8633 - val_mae: 5470.8633\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 5493.4272 - mae: 5493.4272 - val_loss: 5424.8076 - val_mae: 5424.8076\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 5447.3931 - mae: 5447.3931 - val_loss: 5378.7900 - val_mae: 5378.7900\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 3s 67ms/step - loss: 5401.3877 - mae: 5401.3877 - val_loss: 5332.7969 - val_mae: 5332.7969\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 5355.4019 - mae: 5355.4019 - val_loss: 5286.8193 - val_mae: 5286.8193\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 5309.4316 - mae: 5309.4316 - val_loss: 5240.8550 - val_mae: 5240.8550ss: 5319.1772 - m\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 5263.4722 - mae: 5263.4722 - val_loss: 5194.8989 - val_mae: 5194.8989\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 5217.5195 - mae: 5217.5195 - val_loss: 5148.9517 - val_mae: 5148.9517\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 5171.5752 - mae: 5171.5752 - val_loss: 5103.0088 - val_mae: 5103.0088\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 5125.6348 - mae: 5125.6348 - val_loss: 5057.0713 - val_mae: 5057.0713\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 5079.6992 - mae: 5079.6992 - val_loss: 5011.1377 - val_mae: 5011.1377\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 3s 69ms/step - loss: 5033.7671 - mae: 5033.7671 - val_loss: 4965.2075 - val_mae: 4965.2075\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 4987.8379 - mae: 4987.8379 - val_loss: 4919.2798 - val_mae: 4919.2798\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 3s 68ms/step - loss: 4941.9111 - mae: 4941.9111 - val_loss: 4873.3550 - val_mae: 4873.3550\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 4895.9878 - mae: 4895.9878 - val_loss: 4827.4326 - val_mae: 4827.4326\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 69ms/step - loss: 4850.0659 - mae: 4850.0659 - val_loss: 4781.5117 - val_mae: 4781.5117\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 4804.1465 - mae: 4804.1465 - val_loss: 4735.5933 - val_mae: 4735.5933\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 4758.2290 - mae: 4758.2290 - val_loss: 4689.6748 - val_mae: 4689.6748\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit16 = Sequential([\n",
    "  LSTM(16, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(16, activation='tanh',return_sequences=True),\n",
    "  LSTM(16, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit16.summary()\n",
    "\n",
    "simple_model_three_asii_unit16.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit16 = simple_model_three_asii_unit16.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit16 = simple_model_three_asii_unit16.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_146 (LSTM)             (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_147 (LSTM)             (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_148 (LSTM)             (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 31s 468ms/step - loss: 5590.3823 - mae: 5590.3823 - val_loss: 5476.5317 - val_mae: 5476.5317\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 22s 439ms/step - loss: 5456.7310 - mae: 5456.7310 - val_loss: 5343.1089 - val_mae: 5343.1089\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 22s 432ms/step - loss: 5323.5073 - mae: 5323.5073 - val_loss: 5210.0342 - val_mae: 5210.0342\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 22s 432ms/step - loss: 5190.5122 - mae: 5190.5122 - val_loss: 5077.1074 - val_mae: 5077.1074\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 23s 444ms/step - loss: 5057.6270 - mae: 5057.6270 - val_loss: 4944.2598 - val_mae: 4944.2598\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 22s 436ms/step - loss: 4924.8076 - mae: 4924.8076 - val_loss: 4811.4639 - val_mae: 4811.4639\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 22s 433ms/step - loss: 4792.0278 - mae: 4792.0278 - val_loss: 4678.7021 - val_mae: 4678.7021\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 22s 435ms/step - loss: 4659.2793 - mae: 4659.2793 - val_loss: 4545.9658 - val_mae: 4545.9658\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 25s 491ms/step - loss: 4526.5537 - mae: 4526.5537 - val_loss: 4413.2495 - val_mae: 4413.2495\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 31s 605ms/step - loss: 4393.8442 - mae: 4393.8442 - val_loss: 4280.5479 - val_mae: 4280.5479\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 35s 696ms/step - loss: 4261.1489 - mae: 4261.1489 - val_loss: 4147.8584 - val_mae: 4147.8584\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 36s 707ms/step - loss: 4128.4639 - mae: 4128.4639 - val_loss: 4015.1790 - val_mae: 4015.1790\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 32s 625ms/step - loss: 3995.7893 - mae: 3995.7893 - val_loss: 3882.5093 - val_mae: 3882.5093\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 31s 605ms/step - loss: 3863.1221 - mae: 3863.1221 - val_loss: 3749.8447 - val_mae: 3749.8447\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 35s 685ms/step - loss: 3730.4617 - mae: 3730.4617 - val_loss: 3617.1875 - val_mae: 3617.1875\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 32s 625ms/step - loss: 3597.8059 - mae: 3597.8059 - val_loss: 3484.5347 - val_mae: 3484.5347\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 31s 614ms/step - loss: 3465.1572 - mae: 3465.1572 - val_loss: 3351.8879 - val_mae: 3351.8879\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 31s 599ms/step - loss: 3332.5095 - mae: 3332.5095 - val_loss: 3219.2422 - val_mae: 3219.2422\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 31s 619ms/step - loss: 3199.8682 - mae: 3199.8682 - val_loss: 3086.6040 - val_mae: 3086.6040\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 26s 514ms/step - loss: 3067.2849 - mae: 3067.2849 - val_loss: 2954.1792 - val_mae: 2954.1792\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit64 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit64.summary()\n",
    "\n",
    "simple_model_three_asii_unit64.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit64 = simple_model_three_asii_unit64.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit64 = simple_model_three_asii_unit64.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_149 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_150 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_151 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 19s 147ms/step - loss: 6215.6421 - mae: 6215.6421 - val_loss: 6081.2319 - val_mae: 6081.2319\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 6210.4683 - mae: 6210.4683 - val_loss: 6076.2646 - val_mae: 6076.2646\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 6205.5977 - mae: 6205.5977 - val_loss: 6071.4658 - val_mae: 6071.4658\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 6200.8369 - mae: 6200.8369 - val_loss: 6066.7354 - val_mae: 6066.7354\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6196.1245 - mae: 6196.1245 - val_loss: 6062.0410 - val_mae: 6062.0410\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 6191.4395 - mae: 6191.4395 - val_loss: 6057.3677 - val_mae: 6057.3677\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 6186.7754 - mae: 6186.7754 - val_loss: 6052.7085 - val_mae: 6052.7085\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 6182.1240 - mae: 6182.1240 - val_loss: 6048.0625 - val_mae: 6048.0625\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 6177.4805 - mae: 6177.4805 - val_loss: 6043.4233 - val_mae: 6043.4233\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 6172.8442 - mae: 6172.8442 - val_loss: 6038.7910 - val_mae: 6038.7910\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 6168.2144 - mae: 6168.2144 - val_loss: 6034.1646 - val_mae: 6034.1646\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 6163.5903 - mae: 6163.5903 - val_loss: 6029.5410 - val_mae: 6029.5410\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 6158.9692 - mae: 6158.9692 - val_loss: 6024.9214 - val_mae: 6024.9214\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 6154.3501 - mae: 6154.3501 - val_loss: 6020.3052 - val_mae: 6020.3052\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 6149.7349 - mae: 6149.7349 - val_loss: 6015.6904 - val_mae: 6015.6904\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6145.1221 - mae: 6145.1221 - val_loss: 6011.0791 - val_mae: 6011.0791\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6140.5107 - mae: 6140.5107 - val_loss: 6006.4697 - val_mae: 6006.4697- loss: 6212\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 6135.9028 - mae: 6135.9028 - val_loss: 6001.8608 - val_mae: 6001.8608\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6131.2944 - mae: 6131.2944 - val_loss: 5997.2549 - val_mae: 5997.2549\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 6126.6890 - mae: 6126.6890 - val_loss: 5992.6489 - val_mae: 5992.6489\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit8 = Sequential([\n",
    "  LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='tanh',return_sequences=True),\n",
    "  LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit8.summary()\n",
    "\n",
    "simple_model_three_icbp_unit8.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit8 = simple_model_three_icbp_unit8.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit8 = simple_model_three_icbp_unit8.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_152 (LSTM)             (None, 60, 16)            1152      \n",
      "                                                                 \n",
      " lstm_153 (LSTM)             (None, 60, 16)            2112      \n",
      "                                                                 \n",
      " lstm_154 (LSTM)             (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 20)                340       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,716\n",
      "Trainable params: 5,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 17s 132ms/step - loss: 6213.7671 - mae: 6213.7671 - val_loss: 6077.0630 - val_mae: 6077.0640\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 6204.1040 - mae: 6204.1040 - val_loss: 6067.6196 - val_mae: 6067.6196\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 6194.8691 - mae: 6194.8691 - val_loss: 6058.5371 - val_mae: 6058.5371\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 6185.8628 - mae: 6185.8628 - val_loss: 6049.5933 - val_mae: 6049.5933\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 6176.9556 - mae: 6176.9556 - val_loss: 6040.7197 - val_mae: 6040.7197\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 6168.1040 - mae: 6168.1040 - val_loss: 6031.8896 - val_mae: 6031.8896\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6159.2896 - mae: 6159.2896 - val_loss: 6023.0889 - val_mae: 6023.0889\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 6150.4985 - mae: 6150.4985 - val_loss: 6014.3086 - val_mae: 6014.3086\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 6141.7271 - mae: 6141.7271 - val_loss: 6005.5444 - val_mae: 6005.5444\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 6132.9702 - mae: 6132.9702 - val_loss: 5996.7939 - val_mae: 5996.7939\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6124.2246 - mae: 6124.2246 - val_loss: 5988.0527 - val_mae: 5988.0527\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 6115.4854 - mae: 6115.4854 - val_loss: 5979.3193 - val_mae: 5979.3193\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 6106.7583 - mae: 6106.7583 - val_loss: 5970.5928 - val_mae: 5970.5928\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 6098.0327 - mae: 6098.0327 - val_loss: 5961.8721 - val_mae: 5961.8721\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 6089.3149 - mae: 6089.3149 - val_loss: 5953.1567 - val_mae: 5953.1567\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 6080.6006 - mae: 6080.6006 - val_loss: 5944.4443 - val_mae: 5944.4443\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 6071.8911 - mae: 6071.8911 - val_loss: 5935.7358 - val_mae: 5935.7358\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 6063.1846 - mae: 6063.1846 - val_loss: 5927.0317 - val_mae: 5927.0317\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 6054.4810 - mae: 6054.4810 - val_loss: 5918.3296 - val_mae: 5918.3296\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 6045.7812 - mae: 6045.7812 - val_loss: 5909.6299 - val_mae: 5909.6299\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit16 = Sequential([\n",
    "  LSTM(16, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(16, activation='tanh',return_sequences=True),\n",
    "  LSTM(16, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit16.summary()\n",
    "\n",
    "simple_model_three_icbp_unit16.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit16 = simple_model_three_icbp_unit16.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit16 = simple_model_three_icbp_unit16.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_155 (LSTM)             (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_156 (LSTM)             (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_157 (LSTM)             (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 42s 597ms/step - loss: 6202.2441 - mae: 6202.2441 - val_loss: 6053.9585 - val_mae: 6053.9585\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 25s 489ms/step - loss: 6170.3008 - mae: 6170.3008 - val_loss: 6022.4395 - val_mae: 6022.4395\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 24s 480ms/step - loss: 6139.0117 - mae: 6139.0117 - val_loss: 5991.3203 - val_mae: 5991.3203\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 25s 488ms/step - loss: 6107.9814 - mae: 6107.9814 - val_loss: 5960.3652 - val_mae: 5960.3652\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 26s 511ms/step - loss: 6077.0728 - mae: 6077.0728 - val_loss: 5929.4976 - val_mae: 5929.4976\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 25s 490ms/step - loss: 6046.2339 - mae: 6046.2339 - val_loss: 5898.6855 - val_mae: 5898.6855\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 25s 492ms/step - loss: 6015.4419 - mae: 6015.4419 - val_loss: 5867.9116 - val_mae: 5867.9116\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 26s 502ms/step - loss: 5984.6812 - mae: 5984.6812 - val_loss: 5837.1650 - val_mae: 5837.1650\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 27s 534ms/step - loss: 5953.9448 - mae: 5953.9448 - val_loss: 5806.4399 - val_mae: 5806.4399\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 25s 487ms/step - loss: 5923.2275 - mae: 5923.2275 - val_loss: 5775.7310 - val_mae: 5775.7310\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 24s 477ms/step - loss: 5892.5259 - mae: 5892.5259 - val_loss: 5745.0342 - val_mae: 5745.0342\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 24s 480ms/step - loss: 5861.8340 - mae: 5861.8340 - val_loss: 5714.3491 - val_mae: 5714.3491\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 24s 477ms/step - loss: 5831.1533 - mae: 5831.1533 - val_loss: 5683.6729 - val_mae: 5683.6729\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 25s 486ms/step - loss: 5800.4819 - mae: 5800.4819 - val_loss: 5653.0049 - val_mae: 5653.0049\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 24s 481ms/step - loss: 5769.8164 - mae: 5769.8164 - val_loss: 5622.3428 - val_mae: 5622.3428\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 24s 463ms/step - loss: 5739.1582 - mae: 5739.1582 - val_loss: 5591.6860 - val_mae: 5591.6860\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 24s 477ms/step - loss: 5708.5020 - mae: 5708.5020 - val_loss: 5561.0347 - val_mae: 5561.0347\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 24s 478ms/step - loss: 5677.8535 - mae: 5677.8535 - val_loss: 5530.3872 - val_mae: 5530.3872\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 26s 513ms/step - loss: 5647.2090 - mae: 5647.2090 - val_loss: 5499.7451 - val_mae: 5499.7451\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 24s 478ms/step - loss: 5616.5684 - mae: 5616.5684 - val_loss: 5469.1045 - val_mae: 5469.1045\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit64 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit64.summary()\n",
    "\n",
    "simple_model_three_icbp_unit64.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit64 = simple_model_three_icbp_unit64.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit64 = simple_model_three_icbp_unit64.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_158 (LSTM)             (None, 60, 8)             320       \n",
      "                                                                 \n",
      " lstm_159 (LSTM)             (None, 60, 8)             544       \n",
      "                                                                 \n",
      " lstm_160 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 20)                180       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 15s 125ms/step - loss: 4620.4800 - mae: 4620.4800 - val_loss: 4621.6914 - val_mae: 4621.6914\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 4615.0537 - mae: 4615.0537 - val_loss: 4616.3999 - val_mae: 4616.3999\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 4609.9658 - mae: 4609.9658 - val_loss: 4611.4551 - val_mae: 4611.4551\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 4605.0879 - mae: 4605.0879 - val_loss: 4606.6328 - val_mae: 4606.6328\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 4600.2993 - mae: 4600.2993 - val_loss: 4601.8716 - val_mae: 4601.8716\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 4595.5566 - mae: 4595.5566 - val_loss: 4597.1484 - val_mae: 4597.1484\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 4590.8462 - mae: 4590.8462 - val_loss: 4592.4492 - val_mae: 4592.4492\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 4586.1572 - mae: 4586.1572 - val_loss: 4587.7690 - val_mae: 4587.7690\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 4581.4829 - mae: 4581.4829 - val_loss: 4583.1011 - val_mae: 4583.1011\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 4576.8208 - mae: 4576.8208 - val_loss: 4578.4438 - val_mae: 4578.4438\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 4572.1675 - mae: 4572.1675 - val_loss: 4573.7954 - val_mae: 4573.7954\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 4567.5225 - mae: 4567.5225 - val_loss: 4569.1523 - val_mae: 4569.1523\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 4562.8833 - mae: 4562.8833 - val_loss: 4564.5161 - val_mae: 4564.5161\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 4558.2485 - mae: 4558.2485 - val_loss: 4559.8848 - val_mae: 4559.8848\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 4553.6191 - mae: 4553.6191 - val_loss: 4555.2563 - val_mae: 4555.2563\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 4548.9927 - mae: 4548.9927 - val_loss: 4550.6323 - val_mae: 4550.6323\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 4544.3696 - mae: 4544.3696 - val_loss: 4546.0112 - val_mae: 4546.0112\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 4539.7510 - mae: 4539.7510 - val_loss: 4541.3931 - val_mae: 4541.3931\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 4535.1328 - mae: 4535.1328 - val_loss: 4536.7769 - val_mae: 4536.7769\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4530.5176 - mae: 4530.5176 - val_loss: 4532.1626 - val_mae: 4532.1626\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit8 = Sequential([\n",
    "  LSTM(8, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(8, activation='tanh',return_sequences=True),\n",
    "  LSTM(8, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit8.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit8.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit8 = simple_model_three_jsmr_unit8.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit8 = simple_model_three_jsmr_unit8.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_161 (LSTM)             (None, 60, 16)            1152      \n",
      "                                                                 \n",
      " lstm_162 (LSTM)             (None, 60, 16)            2112      \n",
      "                                                                 \n",
      " lstm_163 (LSTM)             (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 20)                340       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,716\n",
      "Trainable params: 5,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 15s 130ms/step - loss: 4618.1743 - mae: 4618.1743 - val_loss: 4617.1616 - val_mae: 4617.1616\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4608.5278 - mae: 4608.5278 - val_loss: 4607.7441 - val_mae: 4607.7441\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 4599.3110 - mae: 4599.3110 - val_loss: 4598.6743 - val_mae: 4598.6743\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 4590.3135 - mae: 4590.3135 - val_loss: 4589.7368 - val_mae: 4589.7368\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 4581.4131 - mae: 4581.4131 - val_loss: 4580.8687 - val_mae: 4580.8687\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4572.5664 - mae: 4572.5664 - val_loss: 4572.0425 - val_mae: 4572.0425\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4563.7544 - mae: 4563.7544 - val_loss: 4563.2451 - val_mae: 4563.2451\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 4554.9688 - mae: 4554.9688 - val_loss: 4554.4683 - val_mae: 4554.4683\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 4546.1987 - mae: 4546.1987 - val_loss: 4545.7065 - val_mae: 4545.7065\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 4537.4429 - mae: 4537.4429 - val_loss: 4536.9565 - val_mae: 4536.9565\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 4528.6992 - mae: 4528.6992 - val_loss: 4528.2173 - val_mae: 4528.2173\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 4519.9624 - mae: 4519.9624 - val_loss: 4519.4854 - val_mae: 4519.4854\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 4511.2349 - mae: 4511.2349 - val_loss: 4510.7607 - val_mae: 4510.7607\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 4502.5122 - mae: 4502.5122 - val_loss: 4502.0410 - val_mae: 4502.0410\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 4493.7949 - mae: 4493.7949 - val_loss: 4493.3262 - val_mae: 4493.3262\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4485.0830 - mae: 4485.0830 - val_loss: 4484.6152 - val_mae: 4484.6152\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 4476.3735 - mae: 4476.3735 - val_loss: 4475.9082 - val_mae: 4475.9082\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 4467.6675 - mae: 4467.6675 - val_loss: 4467.2041 - val_mae: 4467.2041\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 4458.9653 - mae: 4458.9653 - val_loss: 4458.5029 - val_mae: 4458.5029\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 4450.2651 - mae: 4450.2651 - val_loss: 4449.8042 - val_mae: 4449.8042\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit16 = Sequential([\n",
    "  LSTM(16, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(16, activation='tanh',return_sequences=True),\n",
    "  LSTM(16, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit16.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit16.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit16 = simple_model_three_jsmr_unit16.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit16 = simple_model_three_jsmr_unit16.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_164 (LSTM)             (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_165 (LSTM)             (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_166 (LSTM)             (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 55s 613ms/step - loss: 4606.3682 - mae: 4606.3682 - val_loss: 4593.2461 - val_mae: 4593.2461\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 31s 613ms/step - loss: 4573.3926 - mae: 4573.3926 - val_loss: 4560.6846 - val_mae: 4560.6846\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 26s 511ms/step - loss: 4541.0664 - mae: 4541.0664 - val_loss: 4528.5332 - val_mae: 4528.5332\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 26s 508ms/step - loss: 4509.0059 - mae: 4509.0059 - val_loss: 4496.5493 - val_mae: 4496.5493\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 26s 504ms/step - loss: 4477.0703 - mae: 4477.0703 - val_loss: 4464.6558 - val_mae: 4464.6558\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 27s 532ms/step - loss: 4445.2051 - mae: 4445.2051 - val_loss: 4432.8188 - val_mae: 4432.8188\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 27s 526ms/step - loss: 4413.3877 - mae: 4413.3877 - val_loss: 4401.0205 - val_mae: 4401.0205\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 28s 542ms/step - loss: 4381.6035 - mae: 4381.6035 - val_loss: 4369.2500 - val_mae: 4369.2500\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 28s 548ms/step - loss: 4349.8457 - mae: 4349.8457 - val_loss: 4337.5020 - val_mae: 4337.5020\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 26s 509ms/step - loss: 4318.1055 - mae: 4318.1055 - val_loss: 4305.7700 - val_mae: 4305.7700\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 25s 496ms/step - loss: 4286.3799 - mae: 4286.3799 - val_loss: 4274.0513 - val_mae: 4274.0513\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 26s 502ms/step - loss: 4254.6670 - mae: 4254.6670 - val_loss: 4242.3442 - val_mae: 4242.3442\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 26s 512ms/step - loss: 4222.9648 - mae: 4222.9648 - val_loss: 4210.6465 - val_mae: 4210.6465\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 26s 507ms/step - loss: 4191.2715 - mae: 4191.2715 - val_loss: 4178.9565 - val_mae: 4178.9565\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 25s 499ms/step - loss: 4159.5845 - mae: 4159.5845 - val_loss: 4147.2729 - val_mae: 4147.2729\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 26s 506ms/step - loss: 4127.9033 - mae: 4127.9033 - val_loss: 4115.5947 - val_mae: 4115.5947\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 26s 517ms/step - loss: 4096.2280 - mae: 4096.2280 - val_loss: 4083.9224 - val_mae: 4083.9224\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 26s 512ms/step - loss: 4064.5576 - mae: 4064.5576 - val_loss: 4052.2539 - val_mae: 4052.2539\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 25s 496ms/step - loss: 4032.8921 - mae: 4032.8921 - val_loss: 4020.5901 - val_mae: 4020.5901\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 26s 503ms/step - loss: 4001.2295 - mae: 4001.2295 - val_loss: 3988.9294 - val_mae: 3988.9294\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit64 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit64.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit64.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit64 = simple_model_three_jsmr_unit64.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit64 = simple_model_three_jsmr_unit64.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIKS EVALUASI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 node\n",
      "mae score antm: 479.43\n",
      "mae score asii: 4792.09\n",
      "mae score icbp: 6177.78\n",
      "mae score jsmr: 4497.06\n",
      "16 node\n",
      "mae score antm: 443.0\n",
      "mae score asii: 4705.34\n",
      "mae score icbp: 6094.76\n",
      "mae score jsmr: 4414.7\n",
      "64 node\n",
      "mae score antm: 405.61\n",
      "mae score asii: 2969.8\n",
      "mae score icbp: 5654.24\n",
      "mae score jsmr: 3953.82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Forecast\n",
    "# mae score\n",
    "print('8 node')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit8, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit8, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit8, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit8, y_test_jsmr).round(2)))\n",
    "\n",
    "print('16 node')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit16, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit16, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit16, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit16, y_test_jsmr).round(2)))\n",
    "\n",
    "print('64 node')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit64, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit64, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit64, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit64, y_test_jsmr).round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 node\n",
      "mae score antm: 0.71\n",
      "mae score asii: 5.75\n",
      "mae score icbp: 65.94\n",
      "mae score jsmr: 47.64\n",
      "16 node\n",
      "mae score antm: 0.6\n",
      "mae score asii: 5.11\n",
      "mae score icbp: 34.49\n",
      "mae score jsmr: 24.98\n",
      "64 node\n",
      "mae score antm: 0.45\n",
      "mae score asii: 1.12\n",
      "mae score icbp: 9.16\n",
      "mae score jsmr: 6.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "# Forecast\n",
    "# mae score\n",
    "print('8 node')\n",
    "print(\"mae score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit8, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit8, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit8, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit8, y_test_jsmr).round(2)))\n",
    "\n",
    "print('16 node')\n",
    "print(\"mae score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit16, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit16, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit16, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit16, y_test_jsmr).round(2)))\n",
    "\n",
    "print('64 node')\n",
    "print(\"mae score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit64, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit64, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit64, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit64, y_test_jsmr).round(2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 node\n",
      "mae score antm: -2002656147065.29\n",
      "mae score asii: -4870050289994.1\n",
      "mae score icbp: -6.30694189603795e+17\n",
      "mae score jsmr: -493086524102807.8\n",
      "16 node\n",
      "mae score antm: -2388337758647.83\n",
      "mae score asii: -1477295304297.62\n",
      "mae score icbp: -306685270903447.44\n",
      "mae score jsmr: -152447903917046.06\n",
      "64 node\n",
      "mae score antm: -52825997034.46\n",
      "mae score asii: -731499928228.89\n",
      "mae score icbp: -68004796324191.09\n",
      "mae score jsmr: -260921490556348.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# Forecast\n",
    "# mae score\n",
    "print('8 node')\n",
    "print(\"mae score antm: \"+str(r2_score(preds_three_antm_unit8, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(r2_score(preds_three_asii_unit8, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(r2_score(preds_three_icbp_unit8, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(r2_score(preds_three_jsmr_unit8, y_test_jsmr).round(2)))\n",
    "\n",
    "print('16 node')\n",
    "print(\"mae score antm: \"+str(r2_score(preds_three_antm_unit16, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(r2_score(preds_three_asii_unit16, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(r2_score(preds_three_icbp_unit16, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(r2_score(preds_three_jsmr_unit16, y_test_jsmr).round(2)))\n",
    "\n",
    "print('64 node')\n",
    "print(\"mae score antm: \"+str(r2_score(preds_three_antm_unit64, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(r2_score(preds_three_asii_unit64, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(r2_score(preds_three_icbp_unit64, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(r2_score(preds_three_jsmr_unit64, y_test_jsmr).round(2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEARNING RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 17s 152ms/step - loss: 993.7996 - mae: 993.7996 - val_loss: 883.2815 - val_mae: 883.2815\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 819.3403 - mae: 819.3403 - val_loss: 711.3039 - val_mae: 711.3039\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 659.4118 - mae: 659.4118 - val_loss: 568.4719 - val_mae: 568.4719\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 526.2028 - mae: 526.2028 - val_loss: 450.9825 - val_mae: 450.9825\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 6s 109ms/step - loss: 434.8246 - mae: 434.8246 - val_loss: 396.4875 - val_mae: 396.4875\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 399.4442 - mae: 399.4442 - val_loss: 380.2338 - val_mae: 380.2338\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 391.2149 - mae: 391.2149 - val_loss: 376.8708 - val_mae: 376.8708\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 389.5970 - mae: 389.5970 - val_loss: 376.3600 - val_mae: 376.3600\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 389.3432 - mae: 389.3432 - val_loss: 376.2919 - val_mae: 376.2919\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 389.2653 - mae: 389.2653 - val_loss: 376.2937 - val_mae: 376.2937\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 389.1932 - mae: 389.1932 - val_loss: 376.3079 - val_mae: 376.3079\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 389.2034 - mae: 389.2034 - val_loss: 376.3486 - val_mae: 376.3486\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 389.1349 - mae: 389.1349 - val_loss: 376.3216 - val_mae: 376.3216\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 389.1476 - mae: 389.1476 - val_loss: 376.3689 - val_mae: 376.3689\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 389.1391 - mae: 389.1391 - val_loss: 376.3489 - val_mae: 376.3489\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 6s 109ms/step - loss: 389.1489 - mae: 389.1489 - val_loss: 376.3472 - val_mae: 376.3472\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 389.1339 - mae: 389.1339 - val_loss: 376.3528 - val_mae: 376.3528\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 389.1769 - mae: 389.1769 - val_loss: 376.4313 - val_mae: 376.4313\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 389.1931 - mae: 389.1931 - val_loss: 376.3778 - val_mae: 376.3778\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 389.1531 - mae: 389.1531 - val_loss: 376.3910 - val_mae: 376.3910\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit64_lr1 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit64_lr1.summary()\n",
    "\n",
    "simple_model_three_antm_unit64_lr1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit64_lr1 = simple_model_three_antm_unit64_lr1.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit64_lr1 = simple_model_three_antm_unit64_lr1.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 18s 156ms/step - loss: 1061.9766 - mae: 1061.9766 - val_loss: 1024.2603 - val_mae: 1024.2603\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 1028.3770 - mae: 1028.3770 - val_loss: 990.9596 - val_mae: 990.9596\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 995.3774 - mae: 995.3774 - val_loss: 958.1829 - val_mae: 958.1829\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 962.7142 - mae: 962.7142 - val_loss: 925.6144 - val_mae: 925.6144\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 930.2040 - mae: 930.2040 - val_loss: 893.1562 - val_mae: 893.1562\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 897.7816 - mae: 897.7816 - val_loss: 860.7668 - val_mae: 860.7668\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 865.4159 - mae: 865.4159 - val_loss: 828.4240 - val_mae: 828.4240\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 833.0903 - mae: 833.0903 - val_loss: 796.1152 - val_mae: 796.1152\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 800.8229 - mae: 800.8229 - val_loss: 763.9197 - val_mae: 763.9197\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 769.2699 - mae: 769.2699 - val_loss: 733.0551 - val_mae: 733.0551\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 738.9315 - mae: 738.9315 - val_loss: 703.4286 - val_mae: 703.4286\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 709.7767 - mae: 709.7767 - val_loss: 674.9641 - val_mae: 674.9641\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 681.8265 - mae: 681.8265 - val_loss: 648.1691 - val_mae: 648.1691\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 655.2302 - mae: 655.2302 - val_loss: 622.6912 - val_mae: 622.6912\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 629.4733 - mae: 629.4733 - val_loss: 597.4073 - val_mae: 597.4073\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 604.1304 - mae: 604.1304 - val_loss: 572.5464 - val_mae: 572.5464\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 579.7214 - mae: 579.7214 - val_loss: 548.6666 - val_mae: 548.6666\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 555.8387 - mae: 555.8387 - val_loss: 524.9333 - val_mae: 524.9333\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 532.3102 - mae: 532.3102 - val_loss: 501.6050 - val_mae: 501.6050\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 509.7405 - mae: 509.7405 - val_loss: 479.8587 - val_mae: 479.8587\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit64_lr2 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit64_lr2.summary()\n",
    "\n",
    "simple_model_three_antm_unit64_lr2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit64_lr2 = simple_model_three_antm_unit64_lr2.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit64_lr2 = simple_model_three_antm_unit64_lr2.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 17s 143ms/step - loss: 1075.3306 - mae: 1075.3306 - val_loss: 1052.4879 - val_mae: 1052.4879\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 1070.8926 - mae: 1070.8926 - val_loss: 1048.6156 - val_mae: 1048.6156\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 1067.1775 - mae: 1067.1775 - val_loss: 1045.0107 - val_mae: 1045.0107\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 107ms/step - loss: 1063.6261 - mae: 1063.6261 - val_loss: 1041.5035 - val_mae: 1041.5035\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 6s 109ms/step - loss: 1060.1460 - mae: 1060.1460 - val_loss: 1038.0465 - val_mae: 1038.0465\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 1056.7045 - mae: 1056.7045 - val_loss: 1034.6199 - val_mae: 1034.6199\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 4s 86ms/step - loss: 1053.2885 - mae: 1053.2885 - val_loss: 1031.2140 - val_mae: 1031.2140\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 1049.8904 - mae: 1049.8904 - val_loss: 1027.8229 - val_mae: 1027.8229\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 1046.5048 - mae: 1046.5048 - val_loss: 1024.4427 - val_mae: 1024.4427\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 1043.1289 - mae: 1043.1289 - val_loss: 1021.0714 - val_mae: 1021.0714\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 1039.7611 - mae: 1039.7611 - val_loss: 1017.7070 - val_mae: 1017.7070\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 6s 109ms/step - loss: 1036.3998 - mae: 1036.3998 - val_loss: 1014.3483 - val_mae: 1014.3483\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 6s 119ms/step - loss: 1033.0433 - mae: 1033.0433 - val_loss: 1010.9941 - val_mae: 1010.9941\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 6s 118ms/step - loss: 1029.6910 - mae: 1029.6910 - val_loss: 1007.6440 - val_mae: 1007.6440\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 6s 115ms/step - loss: 1026.3427 - mae: 1026.3427 - val_loss: 1004.2974 - val_mae: 1004.2974\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 7s 132ms/step - loss: 1022.9975 - mae: 1022.9975 - val_loss: 1000.9536 - val_mae: 1000.9536\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 1019.6550 - mae: 1019.6550 - val_loss: 997.6124 - val_mae: 997.6124\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 6s 122ms/step - loss: 1016.3146 - mae: 1016.3146 - val_loss: 994.2733 - val_mae: 994.2733\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 6s 120ms/step - loss: 1012.9765 - mae: 1012.9765 - val_loss: 990.9363 - val_mae: 990.9363\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 7s 130ms/step - loss: 1009.6404 - mae: 1009.6404 - val_loss: 987.6011 - val_mae: 987.6011\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_antm_unit64_lr3 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_antm.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_antm_unit64_lr3.summary()\n",
    "\n",
    "simple_model_three_antm_unit64_lr3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_antm_unit64_lr3 = simple_model_three_antm_unit64_lr3.fit(X_train_rs_antm, y_train_antm,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_antm_unit64_lr3 = simple_model_three_antm_unit64_lr3.predict(X_test_rs_antm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 17s 161ms/step - loss: 5598.0547 - mae: 5598.0547 - val_loss: 5492.1455 - val_mae: 5492.1455\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 108ms/step - loss: 5479.7886 - mae: 5479.7886 - val_loss: 5374.0830 - val_mae: 5374.0830\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 5361.9121 - mae: 5361.9121 - val_loss: 5256.3447 - val_mae: 5256.3447\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 5244.2476 - mae: 5244.2476 - val_loss: 5138.7422 - val_mae: 5138.7422\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 5126.6836 - mae: 5126.6836 - val_loss: 5021.2139 - val_mae: 5021.2139\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 5009.1792 - mae: 5009.1792 - val_loss: 4903.7319 - val_mae: 4903.7319\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 4891.7144 - mae: 4891.7144 - val_loss: 4786.2822 - val_mae: 4786.2822\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 4774.2764 - mae: 4774.2764 - val_loss: 4668.8564 - val_mae: 4668.8564\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4656.8604 - mae: 4656.8604 - val_loss: 4551.4487 - val_mae: 4551.4487\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 4539.4590 - mae: 4539.4590 - val_loss: 4434.0547 - val_mae: 4434.0547\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 4422.0708 - mae: 4422.0708 - val_loss: 4316.6719 - val_mae: 4316.6719\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 6s 109ms/step - loss: 4304.6929 - mae: 4304.6929 - val_loss: 4199.2988 - val_mae: 4199.2988\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 4187.3232 - mae: 4187.3232 - val_loss: 4081.9338 - val_mae: 4081.9338\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 108ms/step - loss: 4069.9619 - mae: 4069.9619 - val_loss: 3964.5742 - val_mae: 3964.5742\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 3952.6057 - mae: 3952.6057 - val_loss: 3847.2219 - val_mae: 3847.2219\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 107ms/step - loss: 3835.2544 - mae: 3835.2544 - val_loss: 3729.8726 - val_mae: 3729.8726\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 3717.9082 - mae: 3717.9082 - val_loss: 3612.5293 - val_mae: 3612.5293\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 3600.5657 - mae: 3600.5657 - val_loss: 3495.1877 - val_mae: 3495.1877\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 3483.2261 - mae: 3483.2261 - val_loss: 3377.8516 - val_mae: 3377.8516\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 3365.8918 - mae: 3365.8918 - val_loss: 3260.5186 - val_mae: 3260.5186\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit64_lr1 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit64_lr1.summary()\n",
    "\n",
    "simple_model_three_asii_unit64_lr1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit64_lr1 = simple_model_three_asii_unit64_lr1.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit64_lr1 = simple_model_three_asii_unit64_lr1.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 18s 152ms/step - loss: 5639.0762 - mae: 5639.0762 - val_loss: 5577.5029 - val_mae: 5577.5029\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 5606.9917 - mae: 5606.9917 - val_loss: 5545.8618 - val_mae: 5545.8618\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 5575.6143 - mae: 5575.6143 - val_loss: 5514.6768 - val_mae: 5514.6768\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5544.5283 - mae: 5544.5283 - val_loss: 5483.6768 - val_mae: 5483.6768\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 107ms/step - loss: 5513.5811 - mae: 5513.5811 - val_loss: 5452.7759 - val_mae: 5452.7759\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5482.7124 - mae: 5482.7124 - val_loss: 5421.9375 - val_mae: 5421.9375\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 5451.8950 - mae: 5451.8950 - val_loss: 5391.1421 - val_mae: 5391.1421\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 6s 113ms/step - loss: 5421.1157 - mae: 5421.1157 - val_loss: 5360.3779 - val_mae: 5360.3779\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 5390.3638 - mae: 5390.3638 - val_loss: 5329.6362 - val_mae: 5329.6362\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 5359.6318 - mae: 5359.6318 - val_loss: 5298.9141 - val_mae: 5298.9141\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5328.9165 - mae: 5328.9165 - val_loss: 5268.2056 - val_mae: 5268.2056\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5298.2139 - mae: 5298.2139 - val_loss: 5237.5098 - val_mae: 5237.5098\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 6s 110ms/step - loss: 5267.5234 - mae: 5267.5234 - val_loss: 5206.8242 - val_mae: 5206.8242\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 6s 109ms/step - loss: 5236.8433 - mae: 5236.8433 - val_loss: 5176.1475 - val_mae: 5176.1475\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 5206.1685 - mae: 5206.1685 - val_loss: 5145.4775 - val_mae: 5145.4775\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 5175.5020 - mae: 5175.5020 - val_loss: 5114.8145 - val_mae: 5114.8145\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 5144.8428 - mae: 5144.8428 - val_loss: 5084.1572 - val_mae: 5084.1572\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 5114.1865 - mae: 5114.1865 - val_loss: 5053.5039 - val_mae: 5053.5039\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 5083.5356 - mae: 5083.5356 - val_loss: 5022.8560 - val_mae: 5022.8560\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 5052.8892 - mae: 5052.8892 - val_loss: 4992.2109 - val_mae: 4992.2109\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit64_lr2 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit64_lr2.summary()\n",
    "\n",
    "simple_model_three_asii_unit64_lr2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit64_lr2 = simple_model_three_asii_unit64_lr2.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit64_lr2 = simple_model_three_asii_unit64_lr2.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 15s 134ms/step - loss: 5651.9912 - mae: 5651.9912 - val_loss: 5604.5620 - val_mae: 5604.5620\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 5647.4902 - mae: 5647.4902 - val_loss: 5600.6289 - val_mae: 5600.6289\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 5643.7354 - mae: 5643.7354 - val_loss: 5596.9971 - val_mae: 5596.9971\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 5640.1641 - mae: 5640.1641 - val_loss: 5593.4736 - val_mae: 5593.4736\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 5636.6689 - mae: 5636.6689 - val_loss: 5590.0049 - val_mae: 5590.0049\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 5633.2183 - mae: 5633.2183 - val_loss: 5586.5698 - val_mae: 5586.5698\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 5629.7949 - mae: 5629.7949 - val_loss: 5583.1567 - val_mae: 5583.1567\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 5626.3901 - mae: 5626.3901 - val_loss: 5579.7588 - val_mae: 5579.7588\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 5622.9980 - mae: 5622.9980 - val_loss: 5576.3745 - val_mae: 5576.3745\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 5619.6182 - mae: 5619.6182 - val_loss: 5572.9985 - val_mae: 5572.9985 mae:\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 5616.2451 - mae: 5616.2451 - val_loss: 5569.6304 - val_mae: 5569.6304\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 5612.8804 - mae: 5612.8804 - val_loss: 5566.2686 - val_mae: 5566.2686\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 5609.5220 - mae: 5609.5220 - val_loss: 5562.9111 - val_mae: 5562.9111\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 5606.1660 - mae: 5606.1660 - val_loss: 5559.5586 - val_mae: 5559.5586\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 5602.8159 - mae: 5602.8159 - val_loss: 5556.2100 - val_mae: 5556.2100\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5599.4692 - mae: 5599.4692 - val_loss: 5552.8633 - val_mae: 5552.8633\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 5596.1226 - mae: 5596.1226 - val_loss: 5549.5205 - val_mae: 5549.5205\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 5592.7817 - mae: 5592.7817 - val_loss: 5546.1802 - val_mae: 5546.1802\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 5589.4419 - mae: 5589.4419 - val_loss: 5542.8408 - val_mae: 5542.8408\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 5586.1040 - mae: 5586.1040 - val_loss: 5539.5044 - val_mae: 5539.5044\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_asii_unit64_lr3 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_asii.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_asii_unit64_lr3.summary()\n",
    "\n",
    "simple_model_three_asii_unit64_lr3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_asii_unit64_lr3 = simple_model_three_asii_unit64_lr3.fit(X_train_rs_asii, y_train_asii,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_asii_unit64_lr3 = simple_model_three_asii_unit64_lr3.predict(X_test_rs_asii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 14s 138ms/step - loss: 6126.7456 - mae: 6126.7456 - val_loss: 5896.9404 - val_mae: 5896.9404\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 5936.5581 - mae: 5936.5581 - val_loss: 5707.0620 - val_mae: 5707.0620\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 5746.9634 - mae: 5746.9634 - val_loss: 5517.6836 - val_mae: 5517.6836\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 5557.7012 - mae: 5557.7012 - val_loss: 5328.5156 - val_mae: 5328.5156\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 5368.5913 - mae: 5368.5913 - val_loss: 5139.4609 - val_mae: 5139.4609\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 5179.5762 - mae: 5179.5762 - val_loss: 4950.4805 - val_mae: 4950.4805\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 4990.6196 - mae: 4990.6196 - val_loss: 4761.5635 - val_mae: 4761.5635\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 4802.5146 - mae: 4802.5146 - val_loss: 4575.9746 - val_mae: 4575.9746\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 4620.2954 - mae: 4620.2954 - val_loss: 4398.1328 - val_mae: 4398.1328\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4447.2798 - mae: 4447.2798 - val_loss: 4236.6704 - val_mae: 4236.6704\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 4288.3887 - mae: 4288.3887 - val_loss: 4091.7117 - val_mae: 4091.7117\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 4150.9634 - mae: 4150.9634 - val_loss: 3982.3198 - val_mae: 3982.3198\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 4043.9070 - mae: 4043.9070 - val_loss: 3894.1667 - val_mae: 3894.1667\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 6s 119ms/step - loss: 3953.3491 - mae: 3953.3491 - val_loss: 3814.8123 - val_mae: 3814.8123\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 6s 119ms/step - loss: 3866.9146 - mae: 3866.9146 - val_loss: 3733.5889 - val_mae: 3733.5889\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 3780.3889 - mae: 3780.3889 - val_loss: 3654.8591 - val_mae: 3654.8591\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 3698.3384 - mae: 3698.3384 - val_loss: 3579.7949 - val_mae: 3579.7949\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 3617.7229 - mae: 3617.7229 - val_loss: 3505.9587 - val_mae: 3505.9587\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 3538.9573 - mae: 3538.9573 - val_loss: 3433.4934 - val_mae: 3433.4934\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 3461.9319 - mae: 3461.9319 - val_loss: 3362.4846 - val_mae: 3362.4846\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit64_lr1 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit64_lr1.summary()\n",
    "\n",
    "simple_model_three_icbp_unit64_lr1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit64_lr1 = simple_model_three_icbp_unit64_lr1.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit64_lr1 = simple_model_three_icbp_unit64_lr1.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 14s 129ms/step - loss: 6202.1787 - mae: 6202.1787 - val_loss: 6053.6128 - val_mae: 6053.6128\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 6169.4785 - mae: 6169.4785 - val_loss: 6020.9150 - val_mae: 6020.9150\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 6136.8530 - mae: 6136.8530 - val_loss: 5988.5205 - val_mae: 5988.5205\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 6104.2188 - mae: 6104.2188 - val_loss: 5955.3936 - val_mae: 5955.3936\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 6071.0806 - mae: 6071.0806 - val_loss: 5922.4717 - val_mae: 5922.4717\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 6038.2949 - mae: 6038.2949 - val_loss: 5889.7969 - val_mae: 5889.7969\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 6005.6880 - mae: 6005.6880 - val_loss: 5857.2500 - val_mae: 5857.2505\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 5973.1812 - mae: 5973.1812 - val_loss: 5824.7827 - val_mae: 5824.7827\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 5940.7432 - mae: 5940.7432 - val_loss: 5792.3721 - val_mae: 5792.3721\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 5908.3540 - mae: 5908.3540 - val_loss: 5760.0020 - val_mae: 5760.0020\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 5875.9995 - mae: 5875.9995 - val_loss: 5727.6646 - val_mae: 5727.6646\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 5843.6743 - mae: 5843.6743 - val_loss: 5695.3521 - val_mae: 5695.3521\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 5811.3721 - mae: 5811.3721 - val_loss: 5663.0601 - val_mae: 5663.0601\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 5778.8813 - mae: 5778.8813 - val_loss: 5629.7529 - val_mae: 5629.7529\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 5744.8774 - mae: 5744.8774 - val_loss: 5595.7520 - val_mae: 5595.7520\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 5711.1709 - mae: 5711.1709 - val_loss: 5562.2646 - val_mae: 5562.2646\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 5677.7998 - mae: 5677.7998 - val_loss: 5528.9927 - val_mae: 5528.9927\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 5644.5933 - mae: 5644.5933 - val_loss: 5495.8447 - val_mae: 5495.8447\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 5611.4868 - mae: 5611.4868 - val_loss: 5462.7798 - val_mae: 5462.7798\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 5578.4526 - mae: 5578.4526 - val_loss: 5429.7759 - val_mae: 5429.7759\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit64_lr2 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit64_lr2.summary()\n",
    "\n",
    "simple_model_three_icbp_unit64_lr2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit64_lr2 = simple_model_three_icbp_unit64_lr2.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit64_lr2 = simple_model_three_icbp_unit64_lr2.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 14s 135ms/step - loss: 6215.7388 - mae: 6215.7388 - val_loss: 6081.5942 - val_mae: 6081.5942\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 6211.2969 - mae: 6211.2969 - val_loss: 6077.6367 - val_mae: 6077.6367\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 6207.5239 - mae: 6207.5239 - val_loss: 6073.9956 - val_mae: 6073.9956\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 6203.9448 - mae: 6203.9448 - val_loss: 6070.4658 - val_mae: 6070.4658\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 6200.4453 - mae: 6200.4453 - val_loss: 6066.9932 - val_mae: 6066.9932\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 6196.9907 - mae: 6196.9907 - val_loss: 6063.5537 - val_mae: 6063.5537\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 6193.5649 - mae: 6193.5649 - val_loss: 6060.1382 - val_mae: 6060.1382\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 106ms/step - loss: 6190.1562 - mae: 6190.1562 - val_loss: 6056.7393 - val_mae: 6056.7393\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 6186.7627 - mae: 6186.7627 - val_loss: 6053.3521 - val_mae: 6053.3521\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 6183.3813 - mae: 6183.3813 - val_loss: 6049.9741 - val_mae: 6049.9741\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 89ms/step - loss: 6180.0054 - mae: 6180.0054 - val_loss: 6046.6050 - val_mae: 6046.6050\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 6176.6416 - mae: 6176.6416 - val_loss: 6043.2422 - val_mae: 6043.2422\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 6173.2803 - mae: 6173.2803 - val_loss: 6039.8838 - val_mae: 6039.8838\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 6169.9243 - mae: 6169.9243 - val_loss: 6036.5298 - val_mae: 6036.5298\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 6166.5723 - mae: 6166.5723 - val_loss: 6033.1802 - val_mae: 6033.1802\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 6163.2251 - mae: 6163.2251 - val_loss: 6029.8330 - val_mae: 6029.8330\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 6159.8784 - mae: 6159.8784 - val_loss: 6026.4893 - val_mae: 6026.4893\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 6156.5356 - mae: 6156.5356 - val_loss: 6023.1475 - val_mae: 6023.1475\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 6153.1953 - mae: 6153.1953 - val_loss: 6019.8086 - val_mae: 6019.8086\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 6149.8569 - mae: 6149.8569 - val_loss: 6016.4717 - val_mae: 6016.4717\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_icbp_unit64_lr3 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_icbp.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_icbp_unit64_lr3.summary()\n",
    "\n",
    "simple_model_three_icbp_unit64_lr3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_icbp_unit64_lr3 = simple_model_three_icbp_unit64_lr3.fit(X_train_rs_icbp, y_train_icbp,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_icbp_unit64_lr3 = simple_model_three_icbp_unit64_lr3.predict(X_test_rs_icbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_27 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 15s 135ms/step - loss: 4538.8789 - mae: 4538.8789 - val_loss: 4452.6982 - val_mae: 4452.6982\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4364.0659 - mae: 4364.0659 - val_loss: 4278.1729 - val_mae: 4278.1729\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 4189.8145 - mae: 4189.8145 - val_loss: 4104.1255 - val_mae: 4104.1255\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4015.8750 - mae: 4015.8750 - val_loss: 3930.2788 - val_mae: 3930.2788\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 3842.0864 - mae: 3842.0864 - val_loss: 3756.5413 - val_mae: 3756.5413\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 3668.3840 - mae: 3668.3840 - val_loss: 3582.8730 - val_mae: 3582.8730\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 3494.7400 - mae: 3494.7400 - val_loss: 3409.2524 - val_mae: 3409.2524\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 3321.1377 - mae: 3321.1377 - val_loss: 3235.6663 - val_mae: 3235.6663\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 3147.5908 - mae: 3147.5908 - val_loss: 3062.3923 - val_mae: 3062.3923\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 2975.3438 - mae: 2975.3438 - val_loss: 2893.3635 - val_mae: 2893.3635\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 2809.2197 - mae: 2809.2197 - val_loss: 2730.5327 - val_mae: 2730.5327\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 2648.5774 - mae: 2648.5774 - val_loss: 2572.2742 - val_mae: 2572.2742\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 2489.0513 - mae: 2489.0513 - val_loss: 2413.4771 - val_mae: 2413.4771\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 2329.5505 - mae: 2329.5505 - val_loss: 2258.2913 - val_mae: 2258.2913\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 2171.6355 - mae: 2171.6355 - val_loss: 2106.7217 - val_mae: 2106.7217\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 2017.2861 - mae: 2017.2861 - val_loss: 1959.1926 - val_mae: 1959.1926\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 1870.5226 - mae: 1870.5226 - val_loss: 1822.0996 - val_mae: 1822.0996\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 1734.3713 - mae: 1734.3713 - val_loss: 1699.1990 - val_mae: 1699.1990\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 1609.9144 - mae: 1609.9144 - val_loss: 1588.6453 - val_mae: 1588.6453\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 1493.0479 - mae: 1493.0479 - val_loss: 1482.1338 - val_mae: 1482.1338\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit64_lr1 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr1.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr1.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit64_lr1 = simple_model_three_jsmr_unit64_lr1.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit64_lr1 = simple_model_three_jsmr_unit64_lr1.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 14s 134ms/step - loss: 4606.2549 - mae: 4606.2549 - val_loss: 4592.5044 - val_mae: 4592.5044\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4572.0327 - mae: 4572.0327 - val_loss: 4558.4922 - val_mae: 4558.4922\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 4537.8472 - mae: 4537.8472 - val_loss: 4524.2856 - val_mae: 4524.2856\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4503.8696 - mae: 4503.8696 - val_loss: 4490.4917 - val_mae: 4490.4917\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 4470.1753 - mae: 4470.1753 - val_loss: 4456.8813 - val_mae: 4456.8813\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 4436.6201 - mae: 4436.6201 - val_loss: 4423.3750 - val_mae: 4423.3750\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4403.1489 - mae: 4403.1489 - val_loss: 4389.9370 - val_mae: 4389.9370\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 4369.7354 - mae: 4369.7354 - val_loss: 4356.5464 - val_mae: 4356.5464\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 4336.3628 - mae: 4336.3628 - val_loss: 4323.1914 - val_mae: 4323.1914\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4303.0215 - mae: 4303.0215 - val_loss: 4289.8643 - val_mae: 4289.8643\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 4269.7056 - mae: 4269.7056 - val_loss: 4256.5591 - val_mae: 4256.5591\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 4236.4097 - mae: 4236.4097 - val_loss: 4223.2725 - val_mae: 4223.2725\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 104ms/step - loss: 4203.1289 - mae: 4203.1289 - val_loss: 4190.0000 - val_mae: 4190.0000\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 4169.8638 - mae: 4169.8638 - val_loss: 4156.7412 - val_mae: 4156.7412\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4136.6089 - mae: 4136.6089 - val_loss: 4123.4912 - val_mae: 4123.4912\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4103.3652 - mae: 4103.3652 - val_loss: 4090.2520 - val_mae: 4090.2520\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4070.1284 - mae: 4070.1284 - val_loss: 4057.0198 - val_mae: 4057.0198\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 4036.9004 - mae: 4036.9004 - val_loss: 4023.7952 - val_mae: 4023.7952\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4003.6785 - mae: 4003.6785 - val_loss: 3990.5762 - val_mae: 3990.5762\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 3970.4629 - mae: 3970.4629 - val_loss: 3957.3625 - val_mae: 3957.3625\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit64_lr2 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr2.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr2.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit64_lr2 = simple_model_three_jsmr_unit64_lr2.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit64_lr2 = simple_model_three_jsmr_unit64_lr2.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 60, 64)            16896     \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 60, 64)            33024     \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,244\n",
      "Trainable params: 84,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 17s 145ms/step - loss: 4620.1279 - mae: 4620.1279 - val_loss: 4621.7363 - val_mae: 4621.7363\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4615.8120 - mae: 4615.8120 - val_loss: 4617.8804 - val_mae: 4617.8804\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4612.0996 - mae: 4612.0996 - val_loss: 4614.2773 - val_mae: 4614.2773\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 4608.5513 - mae: 4608.5513 - val_loss: 4610.7734 - val_mae: 4610.7734\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4605.0732 - mae: 4605.0732 - val_loss: 4607.3184 - val_mae: 4607.3184\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 4601.6333 - mae: 4601.6333 - val_loss: 4603.8940 - val_mae: 4603.8940\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4598.2197 - mae: 4598.2197 - val_loss: 4600.4893 - val_mae: 4600.4893\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4594.8232 - mae: 4594.8232 - val_loss: 4597.0996 - val_mae: 4597.0996\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4591.4385 - mae: 4591.4385 - val_loss: 4593.7207 - val_mae: 4593.7207\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4588.0640 - mae: 4588.0640 - val_loss: 4590.3501 - val_mae: 4590.3501\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 6s 111ms/step - loss: 4584.6973 - mae: 4584.6973 - val_loss: 4586.9868 - val_mae: 4586.9868\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 4581.3364 - mae: 4581.3364 - val_loss: 4583.6289 - val_mae: 4583.6289\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 4577.9805 - mae: 4577.9805 - val_loss: 4580.2754 - val_mae: 4580.2754\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 4574.6294 - mae: 4574.6294 - val_loss: 4576.9258 - val_mae: 4576.9258\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 4571.2812 - mae: 4571.2812 - val_loss: 4573.5796 - val_mae: 4573.5796\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4567.9365 - mae: 4567.9365 - val_loss: 4570.2368 - val_mae: 4570.2368\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 4564.5947 - mae: 4564.5947 - val_loss: 4566.8955 - val_mae: 4566.8955\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 4561.2554 - mae: 4561.2554 - val_loss: 4563.5576 - val_mae: 4563.5576\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 4557.9170 - mae: 4557.9170 - val_loss: 4560.2207 - val_mae: 4560.2207\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 4554.5811 - mae: 4554.5811 - val_loss: 4556.8857 - val_mae: 4556.8857\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "simple_model_three_jsmr_unit64_lr3 = Sequential([\n",
    "  LSTM(64, activation='tanh',input_shape=(n_timesteps, n_features),return_sequences=True),\n",
    "  LSTM(64, activation='tanh',return_sequences=True),\n",
    "  LSTM(64, activation='tanh'),\n",
    "  Dense(y_train_jsmr.shape[1]),\n",
    "])\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr3.summary()\n",
    "\n",
    "simple_model_three_jsmr_unit64_lr3.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  loss='mean_absolute_error',\n",
    "  metrics=[\n",
    "           'mae',\n",
    "           ],\n",
    ")\n",
    "\n",
    "smod_history_three_jsmr_unit64_lr3 = simple_model_three_jsmr_unit64_lr3.fit(X_train_rs_jsmr, y_train_jsmr,\n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          shuffle = True\n",
    ")\n",
    "\n",
    "preds_three_jsmr_unit64_lr3 = simple_model_three_jsmr_unit64_lr3.predict(X_test_rs_jsmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIKS EVALUASI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrate 0.1\n",
      "mae score antm: 405.62\n",
      "mae score asii: 3276.18\n",
      "mae score icbp: 3505.95\n",
      "mae score jsmr: 1422.42\n",
      "lrate 0.01\n",
      "mae score antm: 517.81\n",
      "mae score asii: 5007.88\n",
      "mae score icbp: 5614.91\n",
      "mae score jsmr: 3922.26\n",
      "lrate 0.001\n",
      "mae score antm: 1032.75\n",
      "mae score asii: 5555.17\n",
      "mae score icbp: 6201.6\n",
      "mae score jsmr: 4521.78\n"
     ]
    }
   ],
   "source": [
    "print('lrate 0.1')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit64_lr1, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit64_lr1, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit64_lr1, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit64_lr1, y_test_jsmr).round(2)))\n",
    "print('lrate 0.01')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit64_lr2, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit64_lr2, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit64_lr2, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit64_lr2, y_test_jsmr).round(2)))\n",
    "print('lrate 0.001')\n",
    "print(\"mae score antm: \"+str(mean_absolute_error(preds_three_antm_unit64_lr3, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(mean_absolute_error(preds_three_asii_unit64_lr3, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(mean_absolute_error(preds_three_icbp_unit64_lr3, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(mean_absolute_error(preds_three_jsmr_unit64_lr3, y_test_jsmr).round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrate 0.1\n",
      "mape score antm: 0.45\n",
      "mape score asii: 1.39\n",
      "mape score icbp: 1.07\n",
      "mape score jsmr: 0.43\n",
      "lrate 0.01\n",
      "mape score antm: 0.84\n",
      "mape score asii: 8.11\n",
      "mape score icbp: 8.55\n",
      "mape score jsmr: 5.86\n",
      "lrate 0.001\n",
      "mape score antm: 14.76\n",
      "mape score asii: 79.22\n",
      "mape score icbp: 88.8\n",
      "mape score jsmr: 64.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "print('lrate 0.1')\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit64_lr1, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit64_lr1, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit64_lr1, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit64_lr1, y_test_jsmr).round(2)))\n",
    "print('lrate 0.01')\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit64_lr2, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit64_lr2, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit64_lr2, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit64_lr2, y_test_jsmr).round(2)))\n",
    "print('lrate 0.001')\n",
    "print(\"mape score antm: \"+str(mean_absolute_percentage_error(preds_three_antm_unit64_lr3, y_test_antm).round(2)))\n",
    "print(\"mape score asii: \"+str(mean_absolute_percentage_error(preds_three_asii_unit64_lr3, y_test_asii).round(2)))\n",
    "print(\"mape score icbp: \"+str(mean_absolute_percentage_error(preds_three_icbp_unit64_lr3, y_test_icbp).round(2)))\n",
    "print(\"mape score jsmr: \"+str(mean_absolute_percentage_error(preds_three_jsmr_unit64_lr3, y_test_jsmr).round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrate 0.1\n",
      "mae score antm: -580909980602.15\n",
      "mae score asii: -5124913624098.13\n",
      "mae score icbp: -3973430169326.98\n",
      "mae score jsmr: -100232445686.31\n",
      "lrate 0.01\n",
      "mae score antm: -1021399312016.93\n",
      "mae score asii: -15359541608621.65\n",
      "mae score icbp: -546243635937247.8\n",
      "mae score jsmr: -3174817612811.9\n",
      "lrate 0.001\n",
      "mae score antm: -328291604551660.2\n",
      "mae score asii: -1588881395750651.2\n",
      "mae score icbp: -5335910796446037.0\n",
      "mae score jsmr: -199424585576489.4\n"
     ]
    }
   ],
   "source": [
    "print('lrate 0.1')\n",
    "print(\"mae score antm: \"+str(r2_score(preds_three_antm_unit64_lr1, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(r2_score(preds_three_asii_unit64_lr1, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(r2_score(preds_three_icbp_unit64_lr1, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(r2_score(preds_three_jsmr_unit64_lr1, y_test_jsmr).round(2)))\n",
    "print('lrate 0.01')\n",
    "print(\"mae score antm: \"+str(r2_score(preds_three_antm_unit64_lr2, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(r2_score(preds_three_asii_unit64_lr2, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(r2_score(preds_three_icbp_unit64_lr2, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(r2_score(preds_three_jsmr_unit64_lr2, y_test_jsmr).round(2)))\n",
    "print('lrate 0.001')\n",
    "print(\"mae score antm: \"+str(r2_score(preds_three_antm_unit64_lr3, y_test_antm).round(2)))\n",
    "print(\"mae score asii: \"+str(r2_score(preds_three_asii_unit64_lr3, y_test_asii).round(2)))\n",
    "print(\"mae score icbp: \"+str(r2_score(preds_three_icbp_unit64_lr3, y_test_icbp).round(2)))\n",
    "print(\"mae score jsmr: \"+str(r2_score(preds_three_jsmr_unit64_lr3, y_test_jsmr).round(2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3816365fdcd687a07caedfe721e5894fb1dd0a24482efb967fc5a605423a1021"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
